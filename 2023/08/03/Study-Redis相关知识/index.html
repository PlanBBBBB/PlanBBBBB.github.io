<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>Redis相关知识 | PlanB's Blog</title><meta name="author" content="PlanB,2741718884@qq.com"><meta name="copyright" content="PlanB"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="用于学习Redis相关知识">
<meta property="og:type" content="article">
<meta property="og:title" content="Redis相关知识">
<meta property="og:url" content="https://planbbbbb.github.io/2023/08/03/Study-Redis%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86/index.html">
<meta property="og:site_name" content="PlanB&#39;s Blog">
<meta property="og:description" content="用于学习Redis相关知识">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://planbbbbb.github.io/img/redis.png">
<meta property="article:published_time" content="2023-08-03T13:12:30.793Z">
<meta property="article:modified_time" content="2024-05-28T03:01:50.975Z">
<meta property="article:author" content="PlanB">
<meta property="article:tag" content="Redis">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://planbbbbb.github.io/img/redis.png"><link rel="shortcut icon" href="/./img/%E9%A5%AE%E6%96%99.png"><link rel="canonical" href="https://planbbbbb.github.io/2023/08/03/Study-Redis%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":false,"languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"简"},
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: true,
    post: true
  },
  runtime: '',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'Redis相关知识',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2024-05-28 11:01:50'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><link rel="stylesheet" href="/css/custom.css" media="defer" onload="this.media='all'"><!-- hexo injector head_end start --><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-categories-card@1.0.0/lib/categorybar.css"><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiperstyle.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-wowjs/lib/animate.min.css" media="print" onload="this.media='screen'"><!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.3.0"></head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/./img/%E5%A4%B4%E5%83%8F.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">45</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">16</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">5</div></a></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 文章</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 链接</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友情链接</span></a></li><li><a class="site-page child" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></li></ul></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('/../img/redis.png')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">PlanB's Blog</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 文章</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 链接</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友情链接</span></a></li><li><a class="site-page child" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></li></ul></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">Redis相关知识</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2023-08-03T13:12:30.793Z" title="发表于 2023-08-03 21:12:30">2023-08-03</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2024-05-28T03:01:50.975Z" title="更新于 2024-05-28 11:01:50">2024-05-28</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/Study/">Study</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="Redis相关知识"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><p>[TOC]</p>
<h1 id="写在前面"><a href="#写在前面" class="headerlink" title="写在前面"></a>写在前面</h1><p>文章参考自：</p>
<p><a target="_blank" rel="noopener" href="https://xiaolincoding.com/redis/">小林coding</a></p>
<p><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1Rv41177Af">尚硅谷Redis6教程</a></p>
<p><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1cr4y1671t">黑马程序员Redis入门到实战教程</a></p>
<p><a target="_blank" rel="noopener" href="https://zhangc233.github.io/2021/05/02/Redis/">https://zhangc233.github.io/2021/05/02/Redis/</a></p>
<h1 id="Redis基础知识"><a href="#Redis基础知识" class="headerlink" title="Redis基础知识"></a>Redis基础知识</h1><h2 id="为什么使用Redis"><a href="#为什么使用Redis" class="headerlink" title="为什么使用Redis"></a>为什么使用Redis</h2><p>当过多用户同时访问数据库时压力会很大，这样会导致在访问数据的时候速度很慢，使得用户在体验的时候响应很慢从而降低了用户体验，而<code>Redis</code>这种无关系型数据库是基于内存的，可以较快去进行访问数据，但毕竟内存是有限的，所以并不是因为它访问快而全部使用这种<code>NoSQL</code>数据库，它与<code>MySQL</code><mark>这种关系型数据库之间是相互合作的</mark>，共同完成任务的。</p>
<h2 id="Redis-和-Memcached-有什么区别？"><a href="#Redis-和-Memcached-有什么区别？" class="headerlink" title="Redis 和 Memcached 有什么区别？"></a>Redis 和 Memcached 有什么区别？</h2><p>很多人都说用 Redis 作为缓存，但是 Memcached 也是基于内存的数据库，为什么不选择它作为缓存呢？要解答这个问题，我们就要弄清楚 Redis 和 Memcached 的区别。 Redis 与 Memcached <strong>共同点</strong>：</p>
<ol>
<li>都是基于内存的数据库，一般都用来当做缓存使用。</li>
<li>都有过期策略。</li>
<li>两者的性能都非常高。</li>
</ol>
<p>Redis 与 Memcached <strong>区别</strong>：</p>
<ul>
<li>Redis 支持的数据类型更丰富（String、Hash、List、Set、ZSet），而 Memcached 只支持最简单的 key-value 数据类型；</li>
<li>Redis 支持数据的持久化，可以将内存中的数据保持在磁盘中，重启的时候可以再次加载进行使用，而 Memcached 没有持久化功能，数据全部存在内存之中，Memcached 重启或者挂掉后，数据就没了；</li>
<li>Redis 原生支持集群模式，Memcached 没有原生的集群模式，需要依靠客户端来实现往集群中分片写入数据；</li>
<li>Redis 支持发布订阅模型、Lua 脚本、事务等功能，而 Memcached 不支持；</li>
</ul>
<hr>
<h2 id="为什么用Redis做MySQL的缓存？"><a href="#为什么用Redis做MySQL的缓存？" class="headerlink" title="为什么用Redis做MySQL的缓存？"></a>为什么用Redis做MySQL的缓存？</h2><p>Redis 具备「<strong>高性能</strong>」和「<strong>高并发</strong>」两种特性</p>
<h1 id="Redis网络模型"><a href="#Redis网络模型" class="headerlink" title="Redis网络模型"></a>Redis网络模型</h1><h2 id="五种IO模型"><a href="#五种IO模型" class="headerlink" title="五种IO模型"></a>五种IO模型</h2><h3 id="阻塞IO"><a href="#阻塞IO" class="headerlink" title="阻塞IO"></a>阻塞IO</h3><p>应用程序想要去读取数据，他是无法直接去读取磁盘数据的，他需要先到内核里边去等待内核操作硬件拿到数据，这个过程就是1，是需要等待的，等到内核从磁盘上把数据加载出来之后，再把这个数据写给用户的缓存区，这个过程是2，如果是阻塞IO，那么整个过程中，用户从发起读请求开始，一直到读取到数据，都是一个阻塞状态。</p>
<p><img src="/../assets/Redis%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86/1653897115346.png" alt="1653897115346"></p>
<p>具体流程如下图：</p>
<p>用户去读取数据时，会去先发起recvform一个命令，去尝试从内核上加载数据，如果内核没有数据，那么用户就会等待，此时内核会去从硬件上读取数据，内核读取数据之后，会把数据拷贝到用户态，并且返回ok，整个过程，都是阻塞等待的，这就是阻塞IO</p>
<p>总结如下：</p>
<p>顾名思义，阻塞IO就是两个阶段都必须阻塞等待：</p>
<p><strong>阶段一：</strong></p>
<ul>
<li>用户进程尝试读取数据（比如网卡数据）</li>
<li>此时数据尚未到达，内核需要等待数据</li>
<li>此时用户进程也处于阻塞状态</li>
</ul>
<p>阶段二：</p>
<ul>
<li>数据到达并拷贝到内核缓冲区，代表已就绪</li>
<li>将内核数据拷贝到用户缓冲区</li>
<li>拷贝过程中，用户进程依然阻塞等待</li>
<li>拷贝完成，用户进程解除阻塞，处理数据</li>
</ul>
<p>可以看到，阻塞IO模型中，用户进程在两个阶段都是阻塞状态。</p>
<p><img src="/../assets/Redis%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86/1653897270074.png" alt="1653897270074"></p>
<h3 id="非阻塞IO"><a href="#非阻塞IO" class="headerlink" title="非阻塞IO"></a>非阻塞IO</h3><p>可以看到，非阻塞IO模型中，用户进程在第一个阶段是非阻塞，第二个阶段是阻塞状态。虽然是非阻塞，但性能并没有得到提高。而且忙等机制会导致CPU空转，CPU使用率暴增。</p>
<blockquote>
<p>跟阻塞IO相比，就是第一阶段尝试读数据时，前者是等待，后者是<mark>一直询问</mark></p>
</blockquote>
<p><img src="/../assets/Redis%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86/1653897490116.png" alt="1653897490116"></p>
<h3 id="⭐⭐⭐多路IO复用"><a href="#⭐⭐⭐多路IO复用" class="headerlink" title="⭐⭐⭐多路IO复用"></a>⭐⭐⭐多路IO复用</h3><p>解决多路复用模型是<mark>如何知道内核数据是否就绪</mark>的问题了</p>
<p>这个问题的解决依赖于提出的：</p>
<p><strong>文件描述符（File Descriptor）</strong>：简称FD，是一个从0 开始的无符号整数，用来关联Linux中的一个文件。在Linux中，一切皆文件，例如常规文件、视频、硬件设备等，当然也包括网络套接字（Socket）。</p>
<p>通过FD，我们的网络模型可以利用一个线程监听多个FD，并在某个FD可读、可写时得到通知，从而避免无效的等待，充分利用CPU资源。</p>
<p>阶段一：</p>
<ul>
<li>用户进程调用select，指定要监听的FD集合</li>
<li>核监听FD对应的多个socket</li>
<li>任意一个或多个socket数据就绪则返回readable</li>
<li>此过程中用户进程阻塞</li>
</ul>
<p>阶段二：</p>
<ul>
<li>用户进程找到就绪的socket</li>
<li>依次调用recvfrom读取数据</li>
<li>内核将数据拷贝到用户空间</li>
<li>用户进程处理数据</li>
</ul>
<p>当用户去读取数据的时候，不再去直接调用recvfrom了，而是调用select的函数，select函数会将需要监听的数据交给内核，由内核去检查这些数据是否就绪了，如果说这个数据就绪了，就会通知应用程序数据就绪，然后来读取数据，再从内核中把数据拷贝给用户态，完成数据处理，如果N多个FD一个都没处理完，此时就进行等待。</p>
<p>用IO复用模式，可以确保去读数据的时候，数据是一定存在的，他的效率比原来的阻塞IO和非阻塞IO性能都要高</p>
<p><img src="/../assets/Redis%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86/1653898691736.png" alt="1653898691736"></p>
<p>IO多路复用是利用单个线程来同时监听多个FD，并在某个FD可读、可写时得到通知，从而避免无效的等待，充分利用CPU资源。不过监听FD的方式、通知的方式又有多种实现，常见的有：</p>
<ul>
<li>select</li>
<li>poll</li>
<li>epoll</li>
</ul>
<p>其中select和poll相当于是当被监听的数据准备好之后，他会把你监听的FD整个数据都发给你，你需要到整个FD中去找，哪些是处理好了的，需要通过遍历的方式，所以性能也并不是那么好</p>
<p>而epoll，则相当于内核准备好了之后，他会把准备好的数据，直接发给你，咱们就省去了遍历的动作。</p>
<h4 id="select"><a href="#select" class="headerlink" title="select"></a>select</h4><p>具体流程：</p>
<p>简单说，就是我们把需要处理的<mark>数据封装成FD</mark>，然后<mark>在用户态时创建一个fd的集合</mark>（这个集合的大小是要监听的那个FD的最大值+1，但是大小整体是有限制的 ），这个集合的长度大小是有限制的，同时在这个集合中，标明出来我们要控制哪些数据，</p>
<p>比如要监听的数据，是1,2,5三个数据，此时会执行select函数，然后<mark>将整个fd发给内核态</mark>，内核态会去遍历用户态传递过来的数据，如果发现这里边都数据都没有就绪，就休眠，直到有数据准备好时，就会被唤醒，唤醒之后，再次遍历一遍，看看谁准备好了，然后再将处理掉没有准备好的数据，最后再<mark>将这个FD集合写回到用户态</mark>中去，此时用户态就知道了，奥，有人准备好了，但是对于用户态而言，并不知道谁处理好了，所以<mark>用户态也需要去进行遍历</mark>，然后找到对应准备好数据的节点，再去发起读请求</p>
<p><img src="/../assets/Redis%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86/image-20231106173311672.png" alt="select模式"></p>
<p>select模式存在三个问题：</p>
<ol>
<li><p>需要将<mark>整个</mark>fd_set从用户空间拷贝到内核空间，select结束还要再次拷贝回用户空间</p>
</li>
<li><p>select无法得知具体是哪个fd就绪，需要<mark>遍历整个</mark>fd_set</p>
</li>
<li><p>fd_set监听的fd<mark>数量不能超过</mark>1024</p>
</li>
</ol>
<h4 id="poll"><a href="#poll" class="headerlink" title="poll"></a>poll</h4><p><strong>与select对比：</strong></p>
<ul>
<li>select模式中的fd_set大小固定为1024，而pollfd在内核中<mark>采用链表</mark>，理论上无上限</li>
<li>监听FD越多，每次遍历消耗时间也越久，性能反而会下降，所以其实是有上限的</li>
</ul>
<h4 id="epoll"><a href="#epoll" class="headerlink" title="epoll"></a>epoll</h4><p>epoll模式是对select和poll的改进，它提供了三个函数：</p>
<p>第一个是：<code>eventpoll</code>的函数，他内部包含两个结构：</p>
<ol>
<li><p>红黑树（rb_root）-&gt; 记录的事要监听的FD</p>
</li>
<li><p>链表（list_head）-&gt;一个链表，记录的是就绪的FD</p>
</li>
</ol>
<p>第二个是：紧接着调用<code>epoll_ctl</code>操作，将要监听的数据添加到红黑树上去，并且给每个fd设置一个监听函数，这个函数会在fd数据就绪时触发，就是准备好了，现在就把fd把数据添加到list_head中去</p>
<p>第三个是：调用<code>epoll_wait</code>函数（监听函数）</p>
<p>就去等待，在用户态创建一个空的events数组，当就绪之后，我们的回调函数会把数据添加到list_head中去，当调用这个函数的时候，会去检查list_head，当然这个过程需要参考配置的等待时间，可以等一定时间，也可以一直等， 如果在此过程中，检查到了list_head中有数据会将数据添加到链表中，此时将数据放入到events数组中，并且返回对应的操作的数量，用户态的此时收到响应后，从events中拿到对应准备好的数据的节点，再去调用方法去拿数据。</p>
<p><img src="/../assets/Redis%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86/image-20231106174435434.png" alt="epoll模式"></p>
<p>优势：<em>（对应的是select的三个缺点）</em></p>
<ol>
<li><p>减少了FD的拷贝，select和poll都是每次都要重新把全部的FD再拷贝到内核态，而epoll每次只需要拷贝新来的FD到内核态中</p>
</li>
<li><p>从内核态拷贝FD到用户态时，不再是把全部的FD拷贝到用户态，而是只把就绪链表上的FD拷贝回内核态</p>
</li>
<li><p>可以尽可能多地监听FD的数量，因为红黑树增加再多结点也不会影响其性能</p>
</li>
</ol>
<h4 id="三种模式的对比与总结"><a href="#三种模式的对比与总结" class="headerlink" title="三种模式的对比与总结"></a>三种模式的对比与总结</h4><p>select模式存在的三个问题：</p>
<ul>
<li><p>能监听的FD最大不超过1024</p>
</li>
<li><p>每次select都需要把所有要监听的FD都拷贝到内核空间</p>
</li>
<li><p>每次都要遍历所有FD来判断就绪状态</p>
</li>
</ul>
<p>poll模式的问题：</p>
<ul>
<li>poll利用链表解决了select中监听FD上限的问题，但依然要遍历所有FD，如果监听较多，性能会下降</li>
</ul>
<p>epoll模式中如何解决这些问题的？</p>
<ul>
<li><p>基于epoll实例中的红黑树保存要监听的FD，理论上无上限，而且增删改查效率都非常高</p>
</li>
<li><p>每个FD只需要执行一次epoll_ctl添加到红黑树，以后每次epol_wait无需传递任何参数，无需重复拷贝FD到内核空间</p>
</li>
<li><p>利用ep_poll_callback机制来监听FD状态，无需遍历所有FD，因此性能不会随监听的FD数量增多而下降</p>
</li>
</ul>
<h4 id="事件通知机制"><a href="#事件通知机制" class="headerlink" title="事件通知机制"></a>事件通知机制</h4><p>当FD有数据可读时，我们调用epoll_wait（或者select、poll）可以得到通知。但是事件通知的模式有两种：</p>
<ul>
<li>LevelTriggered：简称LT，也叫做水平触发。只要某个FD中有数据可读，每次调用epoll_wait都会得到通知。</li>
<li>EdgeTriggered：简称ET，也叫做边沿触发。只有在某个FD有状态变化时，调用epoll_wait才会被通知。</li>
</ul>
<p>🔴🟢🟡结论：</p>
<ul>
<li><p>LT：事件通知频率较高，会有<mark>重复通知</mark>，影响性能</p>
</li>
<li><p>ET：<mark>仅通知一次</mark>，效率高。可以基于非阻塞IO循环读取解决数据读取不完整问题</p>
</li>
</ul>
<p>select和poll仅支持LT模式，epoll可以自由选择LT和ET两种模式</p>
<h4 id="基于epoll的服务器端流程"><a href="#基于epoll的服务器端流程" class="headerlink" title="基于epoll的服务器端流程"></a>基于epoll的服务器端流程</h4><p>我们来梳理一下这张图</p>
<p>服务器启动以后，服务端会去调用epoll_create，创建一个epoll实例，epoll实例中包含两个数据</p>
<p>1、红黑树（为空）：rb_root 用来去记录需要被监听的FD</p>
<p>2、链表（为空）：list_head，用来存放已经就绪的FD</p>
<p>创建好了之后，会去调用epoll_ctl函数，此函数会将需要监听的数据添加到rb_root中去，并且对当前这些存在于红黑树的节点设置回调函数，当这些被监听的数据一旦准备完成，就会被调用，而调用的结果就是将红黑树的fd添加到list_head中去(但是此时并没有完成)</p>
<p>3、当第二步完成后，就会调用epoll_wait函数，这个函数会去校验是否有数据准备完毕（因为数据一旦准备就绪，就会被回调函数添加到list_head中），在等待了一段时间后(可以进行配置)，如果等够了超时时间，则返回没有数据，如果有，则进一步判断当前是什么事件，如果是建立连接时间，则调用accept() 接受客户端socket，拿到建立连接的socket，然后建立起来连接，如果是其他事件，则把数据进行写出</p>
<p><img src="/../assets/Redis%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86/image-20231106145531092.png" alt="image-20231106145531092"></p>
<p>⭐⭐⭐此处回看第171集：<a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1cr4y1671t?p=171&vd_source=fa7ba4ae353f08f1d08d1bb24528e96c">https://www.bilibili.com/video/BV1cr4y1671t?p=171&amp;vd_source=fa7ba4ae353f08f1d08d1bb24528e96c</a></p>
<h3 id="信号驱动IO"><a href="#信号驱动IO" class="headerlink" title="信号驱动IO"></a>信号驱动IO</h3><p>信号驱动IO是与内核建立SIGIO的信号关联并设置回调，<mark>当内核有FD就绪时，会发出SIGIO信号通知用户</mark>，期间用户应用可以执行其它业务，无需阻塞等待。</p>
<p>阶段一：</p>
<ul>
<li>用户进程调用sigaction，注册信号处理函数</li>
<li>内核返回成功，开始监听FD</li>
<li>用户进程不阻塞等待，可以执行其它业务</li>
<li>当内核数据就绪后，回调用户进程的SIGIO处理函数</li>
</ul>
<p>阶段二：</p>
<ul>
<li>收到SIGIO回调信号</li>
<li>调用recvfrom，读取</li>
<li>内核将数据拷贝到用户空间</li>
<li>用户进程处理数据</li>
</ul>
<p><img src="/../assets/Redis%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86/1653911776583.png" alt="1653911776583"></p>
<p>当有<mark>大量IO操作</mark>时，信号较多，SIGIO处理函数<mark>不能及时处理</mark>可能导致信号队列溢出，而且内核空间与用户空间的频繁信号交互性能也较低。</p>
<h3 id="异步IO"><a href="#异步IO" class="headerlink" title="异步IO"></a>异步IO</h3><p>这种方式，不仅仅是用户态在试图读取数据后，不阻塞，而且当内核的数据准备完成后，也不会阻塞</p>
<p>他会由内核将所有数据处理完成后，由内核将数据写入到用户态中，然后才算完成，所以性能极高，不会有任何阻塞，全部都由内核完成，可以看到，异步IO模型中，用户进程在两个阶段都是非阻塞状态。</p>
<p><img src="/../assets/Redis%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86/1653911877542.png" alt="1653911877542"></p>
<h3 id="对比"><a href="#对比" class="headerlink" title="对比"></a>对比</h3><p>最后用一幅图，来说明他们之间的区别</p>
<p><img src="/../assets/Redis%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86/1653912219712.png" alt="1653912219712"></p>
<h2 id="小林coding面试题"><a href="#小林coding面试题" class="headerlink" title="小林coding面试题"></a>小林coding面试题</h2><h3 id="Redis-是单线程吗？"><a href="#Redis-是单线程吗？" class="headerlink" title="Redis 是单线程吗？"></a>Redis 是单线程吗？</h3><p>如果仅仅聊Redis的核心业务部分（命令处理），答案是单线程</p>
<p>如果是聊整个Redis，那么答案就是多线程</p>
<p><strong>Redis 单线程指的是「接收客户端请求-&gt;解析请求 -&gt;进行数据读写等操作-&gt;发送数据给客户端」这个过程是由一个线程（主线程）来完成的</strong>，这也是我们常说 Redis 是单线程的原因。</p>
<p>但是，<strong>Redis 程序并不是单线程的</strong>，Redis 在启动的时候，是会<strong>启动后台线程</strong>（BIO）的：</p>
<ul>
<li><strong>Redis 在 2.6 版本</strong>，会启动 2 个后台线程，分别处理<mark>关闭文件、AOF 刷盘</mark>这两个任务；</li>
<li><strong>Redis 在 4.0 版本之后</strong>，新增了一个新的后台线程，用来<mark>异步释放 Redis 内存</mark>，也就是 lazyfree 线程。例如执行 unlink key &#x2F; flushdb async &#x2F; flushall async 等命令，会把这些删除操作交给后台线程来执行，好处是不会导致 Redis 主线程卡顿。因此，当我们要删除一个大 key 的时候，不要使用 del 命令删除，因为 del 是在主线程处理的，这样会导致 Redis 主线程卡顿，因此我们应该使用 unlink 命令来异步删除大key。</li>
</ul>
<p>之所以 Redis 为「关闭文件、AOF 刷盘、释放内存」这些任务创建单独的线程来处理，是因为这些任务的操作都是很<mark>耗时</mark>的，如果把这些任务都放在主线程来处理，那么 Redis 主线程就很容易发生阻塞，这样就无法处理后续的请求了。</p>
<p>后台线程相当于一个消费者，生产者把耗时任务丢到任务队列中，消费者（BIO）不停轮询这个队列，拿出任务就去执行对应的方法即可。</p>
<p><img src="/../assets/Redis%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86/%E5%90%8E%E5%8F%B0%E7%BA%BF%E7%A8%8B.jpg" alt="img"></p>
<h3 id="Redis-单线程模式是怎样的？"><a href="#Redis-单线程模式是怎样的？" class="headerlink" title="Redis 单线程模式是怎样的？"></a>Redis 单线程模式是怎样的？</h3><p>IO多路复用+事件派发</p>
<p>Redis 6.0 版本之前的单线模式如下图：</p>
<p><img src="/../assets/Redis%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86/redis%E5%8D%95%E7%BA%BF%E7%A8%8B%E6%A8%A1%E5%9E%8B.drawio.png" alt="img"></p>
<p>图中的蓝色部分是一个事件循环，是由主线程负责的，可以看到网络 I&#x2F;O 和命令处理都是单线程。 Redis <mark>初始化</mark>的时候，会做下面这几件事情：</p>
<ul>
<li>首先，调用 epoll_create() <mark>创建一个 epoll 对象</mark>和调用 socket() <mark>创建一个服务端 socket</mark></li>
<li>然后，调用 bind() <mark>绑定端口</mark>和调用 listen() <mark>监听该 socket</mark>；</li>
<li>然后，将<mark>调用 epoll_ctl()</mark> 将 listen socket 加入到 epoll，<mark>同时注册「连接事件」处理函数</mark>。</li>
</ul>
<p>初始化完后，主线程就进入到一个<strong>事件循环函数</strong>，主要会做以下事情：</p>
<ul>
<li>首先，先调用<strong>处理发送队列函数</strong>，看是发送队列里是否有任务，如果有发送任务，则通过 write 函数将客户端发送缓存区里的数据发送出去，如果这一轮数据没有发送完，就会注册写事件处理函数，等待 epoll_wait 发现可写后再处理 。</li>
<li>接着，调用 epoll_wait 函数等待事件的到来：<ul>
<li>如果是<strong>连接事件</strong>到来，则会调用<strong>连接事件处理函数</strong>，该函数会做这些事情：调用 accpet 获取已连接的 socket -&gt; 调用 epoll_ctl 将已连接的 socket 加入到 epoll -&gt; 注册「读事件」处理函数；</li>
<li>如果是<strong>读事件</strong>到来，则会调用<strong>读事件处理函数</strong>，该函数会做这些事情：调用 read 获取客户端发送的数据 -&gt; 解析命令 -&gt; 处理命令 -&gt; 将客户端对象添加到发送队列 -&gt; 将执行结果写到发送缓存区等待发送；</li>
<li>如果是<strong>写事件</strong>到来，则会调用<strong>写事件处理函数</strong>，该函数会做这些事情：通过 write 函数将客户端发送缓存区里的数据发送出去，如果这一轮数据没有发送完，就会继续注册写事件处理函数，等待 epoll_wait 发现可写后再处理 。</li>
</ul>
</li>
</ul>
<h3 id="Redis-采用单线程为什么还这么快？"><a href="#Redis-采用单线程为什么还这么快？" class="headerlink" title="Redis 采用单线程为什么还这么快？"></a>Redis 采用单线程为什么还这么快？</h3><ul>
<li><p>大部分操作<strong>都在内存中完成</strong>，并且采用了高效的数据结构（例如epoll中的红黑树）</p>
</li>
<li><p><strong>避免了多线程之间的竞争</strong>，省去了多线程切换带来的时间和性能上的开销，而且也不会导致死锁问题。</p>
</li>
<li><p>采用了 <strong>I&#x2F;O 多路复用机制</strong>处理大量的客户端 Socket 请求：简单来说，在 Redis 只运行单线程的情况下，该机制允许内核中，同时存在多个监听 Socket 和已连接 Socket。内核会一直监听这些 Socket 上的连接请求或数据请求。一旦有请求到达，就会交给 Redis 线程处理</p>
</li>
</ul>
<h3 id="Redis-6-0-之前为什么使用单线程？"><a href="#Redis-6-0-之前为什么使用单线程？" class="headerlink" title="Redis 6.0 之前为什么使用单线程？"></a>Redis 6.0 之前为什么使用单线程？</h3><p><strong>CPU 并不是制约 Redis 性能表现的瓶颈所在</strong>，更多情况下是受到<mark>内存大小和网络I&#x2F;O的限制</mark>。</p>
<p>使用多线程可能带来的后果：<strong>增加了系统复杂度、同时可能存在线程切换、甚至加锁解锁、死锁造成的性能损耗</strong>。</p>
<h3 id="Redis-6-0-之后为什么引入了多线程？"><a href="#Redis-6-0-之后为什么引入了多线程？" class="headerlink" title="Redis 6.0 之后为什么引入了多线程？"></a>Redis 6.0 之后为什么引入了多线程？</h3><p>虽然 Redis 的主要工作（网络 I&#x2F;O 和执行命令）一直是单线程模型，但是<strong>在 Redis 6.0 版本之后，也采用了多个 I&#x2F;O 线程来处理网络请求</strong>，<strong>这是因为随着网络硬件的性能提升，Redis 的<mark>性能瓶颈有时会出现在网络 I&#x2F;O 的处理上</strong></mark>。</p>
<p>所以为了提高网络 I&#x2F;O 的并行度，Redis 6.0 对于网络 I&#x2F;O 采用多线程来处理。但是对于命令的执行，Redis 仍然使用单线程来处理，所以<mark>不要误解Redis 有多线程同时执行命令</mark>。</p>
<hr>
<p>因此， Redis 6.0 版本之后，Redis 在启动的时候，默认情况下会<strong>额外创建 6 个线程</strong>（<em>这里的线程数不包括主线程</em>）：</p>
<ul>
<li>Redis-server ： Redis的<strong>主线程，主要负责执行命令</strong>；</li>
<li>bio_close_file、bio_aof_fsync、bio_lazy_free：三个后台线程，分别<mark>异步处理**</mark>关闭文件任务、AOF刷盘任务、释放内存任务**；</li>
<li>io_thd_1、io_thd_2、io_thd_3：三个 I&#x2F;O 线程，io-threads 默认是 4 ，所以会启动 3（4-1）个 I&#x2F;O 多线程，用来<strong>分担 Redis 网络 I&#x2F;O 的压力</strong>。</li>
</ul>
<h1 id="Redis数据类型"><a href="#Redis数据类型" class="headerlink" title="Redis数据类型"></a>Redis数据类型</h1><p><img src="/../assets/Redis%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86/%E4%BA%94%E7%A7%8D%E7%B1%BB%E5%9E%8B%E6%95%B0%E6%8D%AE%E5%9B%BE.png" alt="五种数据类型图"></p>
<h2 id="String"><a href="#String" class="headerlink" title="String"></a>String</h2><h3 id="数据结构"><a href="#数据结构" class="headerlink" title="数据结构"></a>数据结构</h3><p>String 的数据结构为<code>int</code>和<mark>简单动态字符串 (Simple Dynamic String, 缩写 SDS)</mark>，是<strong>可以修改的字符串</strong>，内部结构实现上<strong>类似于 Java 的 ArrayList</strong>，采用预分配冗余空间的方式来减少内存的频繁分配。</p>
<p><img src="/../assets/Redis%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86/image-20231023212252966.png" alt="image-20231023212252966"></p>
<p>如图中所示，内部为当前字符串实际分配的空间 capacity 一般要高于实际字符串长度 len。当字符串长度小于 1M 时，扩容都是加倍现有的空间，如果超过 1M，扩容时一次只会多扩 1M 的空间。需要注意的是字符串最大长度为 512M。</p>
<h3 id="编码类型"><a href="#编码类型" class="headerlink" title="编码类型"></a>编码类型</h3><ol>
<li><p>其基本编码方式是<mark>RAW</mark>，基于简单动态字符串(SDS)实现，存储上限为512mb.</p>
</li>
<li><p>如果存储的SDS长度小于44字节，则会采用<mark>EMBSTR</mark>编码，此时object head与SDS是一段<strong>连续空间</strong>。申请内存时只需要调用一次内存分配函数，效率更高。</p>
</li>
</ol>
<blockquote>
<p>不超过44的原因是，加上Redisobject的头信息刚好不会超过64，而Redis中的申请内存又是以2的几次方来申请的，这样能刚好避免内存碎片的问题。</p>
</blockquote>
<ol start="3">
<li>如果存储的字符串是整数值，并且大小在LONG MAX范围内，则会采用<mark>INT</mark>编码:直接将数据保存在RedisObiect的ptr指针位置(刚好8字节)，不再需要SDS了。</li>
</ol>
<p>三种编码类型的<strong>图示</strong>：</p>
<p><img src="/../assets/Redis%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86/image-20231105115851754.png" alt="三种编码类型的图示"></p>
<h3 id="常用命令"><a href="#常用命令" class="headerlink" title="常用命令"></a>常用命令</h3><ul>
<li>SET key value<br>设置指定key的值</li>
<li>GET key<br>获取指定key的值</li>
<li>SETEX key seconds value<br>设置指定key的值，并将key的过期时间设为seconds秒</li>
<li>SETNX key value<br>只有在key不存在时设置key的值</li>
</ul>
<h3 id="应用场景"><a href="#应用场景" class="headerlink" title="应用场景"></a>应用场景</h3><ol>
<li>缓存对象<ul>
<li>直接缓存整个对象的 JSON，命令例子： <code>SET user:1 &#39;&#123;&quot;name&quot;:&quot;xiaolin&quot;, &quot;age&quot;:18&#125;&#39;</code>。</li>
<li>采用将 key 进行分离为 user:ID:属性，采用 MSET 存储，用 MGET 获取各属性值，命令例子： <code>MSET user:1:name xiaolin user:1:age 18 user:2:name xiaomei user:2:age 20</code>。</li>
</ul>
</li>
<li>常规计数：计算访问次数、点赞、转发、库存数量等等</li>
<li>分布式锁</li>
<li>共享session信息：将session保存在redis来保存用户的会话(登录)状态</li>
</ol>
<h2 id="List"><a href="#List" class="headerlink" title="List"></a>List</h2><h3 id="数据结构-编码类型"><a href="#数据结构-编码类型" class="headerlink" title="数据结构&amp;&amp;编码类型"></a>数据结构&amp;&amp;编码类型</h3><p>List 类型的底层数据结构是由<strong>双向链表<mark>或</mark>压缩列表</strong>实现的：</p>
<ul>
<li>如果列表的元素个数小于 <code>512</code> 个（默认值，可由 <code>list-max-ziplist-entries</code> 配置），列表每个元素的值都小于 <code>64</code> 字节（默认值，可由 <code>list-max-ziplist-value</code> 配置），Redis 会使用<strong>压缩列表</strong>作为 List 类型的底层数据结构；</li>
<li>如果列表的元素不满足上面的条件，Redis 会使用<strong>双向链表</strong>作为 List 类型的底层数据结构；</li>
</ul>
<p><strong>在 Redis 3.2 版本之后，List 数据类型底层数据结构就只由 quicklist 实现了，替代了双向链表和压缩列表</strong>。</p>
<h3 id="常用命令-1"><a href="#常用命令-1" class="headerlink" title="常用命令"></a>常用命令</h3><p>Redis列表是简单的字符串列表，按照插入顺序排序，常用命令:</p>
<ul>
<li>LPUSH key value1 [value2]<br>将一个或多个值插入到列表头部</li>
<li>LRANGE key start stop<br>获取列表指定范围内的元素</li>
<li>RPOP key<br>移除并获取列表最后一个元素</li>
<li>LLEN key<br>获取列表长度</li>
<li>BRPOP key1 [key2 ] timeout<br>移出并获取列表的最后一个元素，如果列表没有元素会阻塞列表直到等待超时或发现可弹出元素为止</li>
</ul>
<h3 id="应用场景-1"><a href="#应用场景-1" class="headerlink" title="应用场景"></a>应用场景</h3><p>消息队列</p>
<p>消息队列在存取消息时，必须要满足三个需求，分别是<strong>消息保序、处理重复的消息和保证消息可靠性</strong>。</p>
<p>Redis 的 List 和 Stream 两种数据类型，就可以满足消息队列的这三个需求。我们先来了解下基于 List 的消息队列实现方法，后面在介绍 Stream 数据类型时候，在详细说说 Stream。</p>
<ol>
<li>如何满足消息保序需求？</li>
</ol>
<p>List 本身就是按先进先出的顺序对数据进行存取的，所以，如果使用 List 作为消息队列保存消息的话，就已经能满足消息保序的需求了。</p>
<p>List 可以使用 LPUSH + RPOP （或者反过来，RPUSH+LPOP）命令实现消息队列。</p>
<p><img src="/../assets/Redis%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86/list%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97.png" alt="img"></p>
<ul>
<li>生产者使用 <code>LPUSH key value[value...]</code> 将消息插入到队列的头部，如果 key 不存在则会创建一个空的队列再插入消息。</li>
<li>消费者使用 <code>RPOP key</code> 依次读取队列的消息，先进先出。</li>
</ul>
<p>不过，在消费者读取数据时，有一个潜在的性能风险点。</p>
<p>在生产者往 List 中写入数据时，List 并不会主动地通知消费者有新消息写入，如果消费者想要及时处理消息，就需要在程序中不停地调用 <code>RPOP</code> 命令（比如使用一个while(1)循环）。如果有新消息写入，RPOP命令就会返回结果，否则，RPOP命令返回空值，再继续循环。</p>
<p>所以，即使没有新消息写入List，消费者也要不停地调用 RPOP 命令，这就会导致消费者程序的 CPU 一直消耗在执行 RPOP 命令上，带来不必要的性能损失。</p>
<p>为了解决这个问题，Redis提供了 BRPOP 命令。<strong>BRPOP命令也称为阻塞式读取，客户端在没有读到队列数据时，自动阻塞，直到有新的数据写入队列，再开始读取新数据</strong>。和消费者程序自己不停地调用RPOP命令相比，这种方式能节省CPU开销。</p>
<p><img src="/../assets/Redis%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97.png" alt="img"></p>
<ol start="2">
<li>如何处理重复的消息？</li>
</ol>
<p>消费者要实现重复消息的判断，需要 2 个方面的要求：</p>
<ul>
<li>每个消息都有一个全局的 ID。</li>
<li>消费者要记录已经处理过的消息的 ID。当收到一条消息后，消费者程序就可以对比收到的消息 ID 和记录的已处理过的消息 ID，来判断当前收到的消息有没有经过处理。如果已经处理过，那么，消费者程序就不再进行处理了。</li>
</ul>
<p>但是 <strong>List 并不会为每个消息生成 ID 号，所以我们需要自行为每个消息生成一个全局唯一ID</strong>，生成之后，我们在用 LPUSH 命令把消息插入 List 时，需要在消息中包含这个全局唯一 ID。</p>
<p>例如，我们执行以下命令，就把一条全局 ID 为 111000102、库存量为 99 的消息插入了消息队列：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash">LPUSH mq <span class="string">&quot;111000102:stock:99&quot;</span></span></span><br><span class="line">(integer) 1</span><br></pre></td></tr></table></figure>

<ol start="3">
<li>如何保证消息可靠性？</li>
</ol>
<p>当消费者程序从 List 中读取一条消息后，List 就不会再留存这条消息了。所以，如果消费者程序在处理消息的过程出现了故障或宕机，就会导致消息没有处理完成，那么，消费者程序再次启动后，就没法再次从 List 中读取消息了。</p>
<p>为了留存消息，List 类型提供了 <code>BRPOPLPUSH</code> 命令，这个命令的<strong>作用是让消费者程序从一个 List 中读取消息，同时，Redis 会把这个消息再插入到另一个 List（可以叫作备份 List）留存</strong>。</p>
<p>这样一来，如果消费者程序读了消息但没能正常处理，等它重启后，就可以从备份 List 中重新读取消息并进行处理了。</p>
<p>好了，到这里可以知道基于 List 类型的消息队列，满足消息队列的三大需求（消息保序、处理重复的消息和保证消息可靠性）。</p>
<ul>
<li>消息保序：使用 LPUSH + RPOP；</li>
<li>阻塞读取：使用 BRPOP；</li>
<li>重复消息处理：生产者自行实现全局唯一 ID；</li>
<li>消息的可靠性：使用 BRPOPLPUSH</li>
</ul>
<blockquote>
<p>List 作为消息队列有什么缺陷？</p>
</blockquote>
<p><strong>List 不支持多个消费者消费同一条消息</strong>，因为一旦消费者拉取一条消息后，这条消息就从 List 中删除了，无法被其它消费者再次消费。</p>
<p>要实现一条消息可以被多个消费者消费，那么就要将多个消费者组成一个消费组，使得多个消费者可以消费同一条消息，但是 <strong>List 类型并不支持消费组的实现</strong>。</p>
<p>这就要说起 Redis 从 5.0 版本开始提供的 Stream 数据类型了，Stream 同样能够满足消息队列的三大需求，而且它还支持「消费组」形式的消息读取。</p>
<h2 id="Set"><a href="#Set" class="headerlink" title="Set"></a>Set</h2><h3 id="数据结构-编码类型-1"><a href="#数据结构-编码类型-1" class="headerlink" title="数据结构&amp;&amp;编码类型"></a>数据结构&amp;&amp;编码类型</h3><p>Set 类型的底层数据结构是由<strong>哈希表或整数集合</strong>实现的：</p>
<ul>
<li>如果集合中的元素都是整数且元素个数小于 <code>512</code> （默认值，<code>set-maxintset-entries</code>配置）个，Redis 会使用<strong>整数集合</strong>作为 Set 类型的底层数据结构；</li>
<li>如果集合中的元素不满足上面条件，则 Redis 使用<strong>哈希表</strong>作为 Set 类型的底层数据结构。</li>
</ul>
<blockquote>
<p>Java 中 HashSet 的内部实现使用的是 HashMap，只不过所有的 value 都指向同一个对象。Redis 的 set 结构也是一样，它的内部也使用 hash 结构，所有的 value 都指向同一个内部值。</p>
</blockquote>
<h3 id="常用命令-2"><a href="#常用命令-2" class="headerlink" title="常用命令"></a>常用命令</h3><p>Redis set是string类型的无序集合。集合成员是唯一的，这就意味着集合中不能出现重复的数据，常用命令:</p>
<ul>
<li><p>SADD key member1 [member2]</p>
<p>向集合添加一个或多个成员</p>
</li>
<li><p>SMEMBERS key<br>返回集合中的所有成员</p>
</li>
<li><p>SCARD key<br>获取集合的成员数</p>
</li>
<li><p>SINTER key1 [key2]<br>返回给定所有集合的交集</p>
</li>
<li><p>SUNION key1 [key2]<br>返回所有给定集合的并集</p>
</li>
<li><p>SDIFF key1 [key2]<br>返回给定所有集合的差集</p>
</li>
<li><p>SREM key member1 [member2]</p>
<p>移除集合中一个或多个成员</p>
</li>
</ul>
<h3 id="应用场景-2"><a href="#应用场景-2" class="headerlink" title="应用场景"></a>应用场景</h3><ol>
<li>点赞：Set 类型可以保证一个用户只能点一个赞</li>
<li>共同关注：Set 类型支持交集运算，所以可以用来计算共同关注的好友、公众号等</li>
<li>抽奖：存储某活动中中奖的用户名 ，Set 类型因为有去重功能，可以保证同一个用户不会中奖两次</li>
</ol>
<h2 id="Hash"><a href="#Hash" class="headerlink" title="Hash"></a>Hash</h2><h3 id="数据结构-编码类型-2"><a href="#数据结构-编码类型-2" class="headerlink" title="数据结构&amp;&amp;编码类型"></a>数据结构&amp;&amp;编码类型</h3><p>Hash 类型对应的数据结构是两种：<mark>ziplist（压缩列表），hashtable（哈希表）</mark>。当 field-value 长度较短且个数较少时，使用 ziplist，否则使用 hashtable。</p>
<blockquote>
<p>与zset很类似，就是少了一个跳表做排序功能，因为Hash也用不到排序。</p>
<p>具体<mark>为什么ziplist本身不满足键值唯一性判定等条件还能拿来做Hash的底层数据结构的原因</mark>在下面zset处已经说明，往下面看就看到了。</p>
</blockquote>
<h3 id="常用命令-3"><a href="#常用命令-3" class="headerlink" title="常用命令"></a>常用命令</h3><p>Redis hash是一个string类型的field和value的映射表,hash特别适合用于存储对象，常用命令:</p>
<ul>
<li>HSET key field value<br>将哈希表key中的字段field的值设为value</li>
<li>HGET key field<br>获取存储在哈希表中指定字段的值</li>
<li>HDEL key field<br>删除存储在哈希表中的指定字段</li>
<li>HKEYS key<br>获取哈希表中所有字段</li>
<li>HVALS key<br>获取哈希表中所有值</li>
<li>HGETALL key<br>获取在哈希表中指定key的所有字段和值</li>
</ul>
<h3 id="应用场景-3"><a href="#应用场景-3" class="headerlink" title="应用场景"></a>应用场景</h3><ol>
<li>缓存对象</li>
<li>购物车：以用户 id 为 key，商品 id 为 field，商品数量为 value，恰好构成了购物车的3个要素</li>
</ol>
<h2 id="ZSet"><a href="#ZSet" class="headerlink" title="ZSet"></a>ZSet</h2><h3 id="数据结构-编码类型-3"><a href="#数据结构-编码类型-3" class="headerlink" title="数据结构&amp;&amp;编码类型"></a>数据结构&amp;&amp;编码类型</h3><p>Zset 类型的底层数据结构是由<strong>压缩列表<mark>或</mark>跳表（还有hash）</strong>实现的：</p>
<ul>
<li>如果有序集合的元素个数小于 <code>128</code> 个，并且每个元素的值小于 <code>64</code> 字节时，Redis 会使用<strong>压缩列表</strong>作为 Zset 类型的底层数据结构；</li>
<li>如果有序集合的元素不满足上面的条件，Redis 会使用<strong>跳表</strong>作为 Zset 类型的底层数据结构；</li>
</ul>
<p><strong>在 Redis 7.0 中，压缩列表数据结构已经废弃了，交由 listpack 数据结构来实现了</strong></p>
<p>🌈补充1：</p>
<blockquote>
<p>这里说的跳表其实不准确，其实跳表还结合了hash来一起进行操作。</p>
<p>因为跳表可以根据score进行排序地查找score（可范围查询），但是还要结合hash来进行快速地键值的唯一性判断和根据key（member）来找value（score）。但是hash之占了其中的一小部分，且在RedisObject数据结构中的type类型上也只能填一个，故选择了跳表。但是其实<mark>hash也是缺一不可</mark>的。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// zset结构</span></span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">zset</span> &#123;</span></span><br><span class="line">    <span class="comment">// Dict指针</span></span><br><span class="line">    dict *dict;</span><br><span class="line">    <span class="comment">// SkipList指针</span></span><br><span class="line">    zskiplist *zsl;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</blockquote>
<p><img src="/../assets/Redis%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86/image-20231105163630045.png" alt="dict+skiplist"></p>
<p>🌈补充2：ziplist没有上面那些特性，<strong>为什么还能拿来存zset数据？</strong></p>
<p>ziplist本身没有排序功能，而且没有键值对的概念，因此需要有zset通过编码实现</p>
<ul>
<li>ZipList是连续内存，因此score和element是紧挨在一起的两个entry，element在前，score在后</li>
<li>score越小越接近队首，score越大越接近队尾，按照score值升序排列</li>
</ul>
<p><img src="/../assets/Redis%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86/image-20231105165009210.png" alt="ziplist"></p>
<h3 id="常用命令-4"><a href="#常用命令-4" class="headerlink" title="常用命令"></a>常用命令</h3><p>Redis sorted set有序集合是string类型元素的集合，且不允许重复的成员。每个元素都会关联一个double类型的分数(score)。redis正是通过分数来为集合中的成员进行从小到大排序。有序集合的成员是唯一的，但分数却可以重复。常用命令:</p>
<ul>
<li>ZADD key score1 member1 [score2 member2]<br>向有序集合添加一个或多个成员，或者更新已存在成员的分数</li>
<li>ZRANGE key start stop [WITHSCORES]<br>通过索引区间返回有序集合中指定区间内的成员</li>
<li>ZINCRBY key increment member<br>有序集合中对指定成员的分数加上增量increment</li>
<li>ZREM key member [member …]<br>移除有序集合中的一个或多个成员</li>
</ul>
<h3 id="应用场景-4"><a href="#应用场景-4" class="headerlink" title="应用场景"></a>应用场景</h3><ol>
<li>排行榜：有序集合比较典型的使用场景就是排行榜</li>
</ol>
<blockquote>
<p>🌈黑马点评中的点赞排行榜：</p>
</blockquote>
<p>采用zset类型的数据结构原因：</p>
<ol>
<li>可排序</li>
<li>唯一</li>
<li>列表</li>
</ol>
<p>但是SQL语句查询出来的结果并不是按照我们期望的方式进行排，即不按时间排序，因为使用了in来进行查询，最后根据id升序排，但其实应该按时间升序排序，所以可以采用<code>order by field(id, ids[0], ids[1] ...)</code>的方式进行排序</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> Result <span class="title function_">queryBlogLikes</span><span class="params">(Integer id)</span> &#123;</span><br><span class="line">        <span class="type">String</span> <span class="variable">key</span> <span class="operator">=</span> <span class="string">&quot;blog:like:&quot;</span> + id;</span><br><span class="line">        <span class="comment">//zrange key 0 4  查询zset中前5个元素</span></span><br><span class="line">        Set&lt;String&gt; top5 = stringRedisTemplate.opsForZSet().range(key, <span class="number">0</span>, <span class="number">4</span>);</span><br><span class="line">        <span class="comment">//如果是空的(可能没人点赞)，直接返回一个空集合</span></span><br><span class="line">        <span class="keyword">if</span> (top5 == <span class="literal">null</span> || top5.isEmpty()) &#123;</span><br><span class="line">            <span class="keyword">return</span> Result.ok(Collections.emptyList());</span><br><span class="line">        &#125;</span><br><span class="line">        List&lt;Long&gt; ids = top5.stream().map(Long::valueOf).collect(Collectors.toList());</span><br><span class="line">        <span class="comment">//将ids使用`,`拼接，SQL语句查询出来的结果并不是按照我们期望的方式进行排</span></span><br><span class="line">        <span class="comment">//所以我们需要用order by field来指定排序方式，期望的排序方式就是按照查询出来的id进行排序</span></span><br><span class="line">        <span class="type">String</span> <span class="variable">idsStr</span> <span class="operator">=</span> StrUtil.join(<span class="string">&quot;,&quot;</span>, ids);</span><br><span class="line">        <span class="comment">//select * from tb_user where id in (ids[0], ids[1] ...) order by field(id, ids[0], ids[1] ...)</span></span><br><span class="line">        List&lt;UserDTO&gt; userDTOS = userService.query().in(<span class="string">&quot;id&quot;</span>, ids)</span><br><span class="line">                .last(<span class="string">&quot;order by field(id,&quot;</span> + idsStr + <span class="string">&quot;)&quot;</span>)</span><br><span class="line">                .list().stream()</span><br><span class="line">                .map(user -&gt; BeanUtil.copyProperties(user, UserDTO.class))</span><br><span class="line">                .collect(Collectors.toList());</span><br><span class="line">        <span class="keyword">return</span> Result.ok(userDTOS);</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>

<hr>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> tb_user <span class="keyword">where</span> id <span class="keyword">in</span> (ids[<span class="number">0</span>], ids[<span class="number">1</span>] ...) <span class="keyword">order</span> <span class="keyword">by</span> field(id, ids[<span class="number">0</span>], ids[<span class="number">1</span>] ...)</span><br></pre></td></tr></table></figure>



<h2 id="BitMap"><a href="#BitMap" class="headerlink" title="BitMap"></a>BitMap</h2><h3 id="数据结构-1"><a href="#数据结构-1" class="headerlink" title="数据结构"></a>数据结构</h3><p>Bitmap 本身是用 String 类型作为底层数据结构实现的一种统计二值状态的数据类型。</p>
<p>String 类型是会保存为二进制的字节数组，所以，Redis 就把字节数组的每个 bit 位利用起来，用来表示一个元素的二值状态，你可以把 Bitmap 看作是一个 bit 数组。</p>
<p><img src="/../assets/Redis%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86/image-20231024110252548.png" alt="image-20231024110252548"></p>
<h3 id="应用场景-5"><a href="#应用场景-5" class="headerlink" title="应用场景"></a>应用场景</h3><ol>
<li>签到统计</li>
<li>判断用户登录态</li>
<li>连续签到用户总数</li>
</ol>
<h2 id="HyperLogLog"><a href="#HyperLogLog" class="headerlink" title="HyperLogLog"></a>HyperLogLog</h2><h3 id="应用场景-6"><a href="#应用场景-6" class="headerlink" title="应用场景"></a>应用场景</h3><p>UV统计</p>
<h2 id="GEO"><a href="#GEO" class="headerlink" title="GEO"></a>GEO</h2><h3 id="数据结构-2"><a href="#数据结构-2" class="headerlink" title="数据结构"></a>数据结构</h3><p>GEO 本身并没有设计新的底层数据结构，而是直接使用了 Sorted Set 集合类型。</p>
<p>GEO 类型使用 GeoHash 编码方法实现了经纬度到 Sorted Set 中元素权重分数的转换，这其中的两个关键机制就是「对二维地图做区间划分」和「对区间进行编码」。一组经纬度落在某个区间后，就用区间的编码值来表示，并把编码值作为 Sorted Set 元素的权重分数。</p>
<p>这样一来，我们就可以把经纬度保存到 Sorted Set 中，利用 Sorted Set 提供的“按权重进行有序范围查找”的特性，实现 LBS 服务中频繁使用的“搜索附近”的需求。</p>
<h3 id="应用场景-7"><a href="#应用场景-7" class="headerlink" title="应用场景"></a>应用场景</h3><p>附近的人</p>
<h2 id="stream"><a href="#stream" class="headerlink" title="stream"></a>stream</h2><p>Redis Stream 是 Redis 5.0 版本新增加的数据类型，Redis 专门为消息队列设计的数据类型。</p>
<p>在 Redis 5.0 Stream 没出来之前，消息队列的实现方式都有着各自的缺陷，例如：</p>
<ul>
<li>发布订阅模式，不能持久化也就无法可靠的保存消息，并且对于离线重连的客户端不能读取历史消息的缺陷；</li>
<li>List 实现消息队列的方式不能重复消费，一个消息消费完就会被删除，而且生产者需要自行实现全局唯一 ID。</li>
</ul>
<h2 id="通用命令"><a href="#通用命令" class="headerlink" title="通用命令"></a>通用命令</h2><ul>
<li>KEYS pattern<br>查找所有符合给定模式( pattern)的 key</li>
<li>EXISTS key<br>检查给定key是否存在</li>
<li>TYPE key<br>返回key所储存的值的类型</li>
<li>TTL key<br>返回给定 key的剩余生存时间(TTL, time to live)，以秒为单位</li>
<li>DEL key<br>该命令用于在key存在是删除key</li>
</ul>
<h1 id="Redis底层数据结构"><a href="#Redis底层数据结构" class="headerlink" title="Redis底层数据结构"></a>Redis底层数据结构</h1><p> Redis 数据类型（也叫 Redis 对象）和底层数据结构的对应关系图</p>
<p><img src="/../assets/Redis%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86/image-20231105171016673.png" alt="对应关系图"></p>
<h2 id="SDS"><a href="#SDS" class="headerlink" title="SDS"></a>SDS</h2><h3 id="C字符串的缺点"><a href="#C字符串的缺点" class="headerlink" title="C字符串的缺点"></a>C字符串的缺点</h3><p>Redis是用C语言编写的，但是不直接使用C语言的字符串，是因为其本身有几处缺点</p>
<p>C 语言的字符串不足之处以及可以改进的地方：</p>
<ul>
<li>获取字符串长度的时间复杂度为 O（N）；</li>
<li>字符串的结尾是以 “\0” 字符标识，字符串里面不能包含有 “\0” 字符，因此不能保存二进制数据；</li>
<li>字符串操作函数不高效且不安全，比如有缓冲区溢出的风险，有可能会造成程序运行终止；</li>
</ul>
<h3 id="SDS数据结构"><a href="#SDS数据结构" class="headerlink" title="SDS数据结构"></a>SDS数据结构</h3><p>SDS数据结构图：</p>
<p><img src="/../assets/Redis%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86/image-20231031113454318.png" alt="SDS数据结构"></p>
<p>结构中的每个成员变量分别介绍下：</p>
<ul>
<li><strong>len，记录了字符串长度</strong>。这样获取字符串长度的时候，只需要返回这个成员变量值就行，时间复杂度只需要 O（1）。</li>
<li><strong>alloc，分配给字符数组的空间长度</strong>。这样在修改字符串的时候，可以通过 <code>alloc - len</code> 计算出剩余的空间大小，可以用来判断空间是否满足修改需求，如果不满足的话，就会自动将 SDS 的<mark>空间扩展</mark>至执行修改所需的大小，然后才执行实际的修改操作，所以使用 SDS 既不需要手动修改 SDS 的空间大小，也不会出现前面所说的缓冲区溢出的问题。</li>
<li><strong>flags，用来表示不同类型的 SDS</strong>。一共设计了 5 种类型，分别是 sdshdr5、sdshdr8、sdshdr16、sdshdr32 和 sdshdr64，后面在说明区别之处。</li>
<li><strong>buf[]，字符数组，用来保存实际数据</strong>。不仅可以保存字符串，也可以保存二进制数据。</li>
</ul>
<h3 id="自动扩容"><a href="#自动扩容" class="headerlink" title="自动扩容"></a>自动扩容</h3><p>当判断出缓冲区大小不够用时，Redis 会自动将扩大 SDS 的空间大小</p>
<ul>
<li>如果所需的 sds 长度<strong>小于 1 MB</strong>，那么最后的扩容是按照<strong>翻倍扩容</strong>来执行的，即 2 倍的newlen</li>
<li>如果所需的 sds 长度<strong>超过 1 MB</strong>，那么最后的扩容长度应该是 newlen <strong>+ 1MB</strong>。</li>
</ul>
<p>在扩容 SDS 空间之前，SDS API 会优先检查未使用空间是否足够，如果不够的话，API 不仅会为 SDS 分配修改所必须要的空间，还会给 SDS 分配额外的「未使用空间」。</p>
<p>这样的好处是，下次在操作 SDS 时，如果 SDS 空间够的话，API 就会直接使用「未使用空间」，而无须执行内存分配，<mark><strong>有效的减少内存分配次数</strong></mark>。</p>
<h3 id="节省内存空间"><a href="#节省内存空间" class="headerlink" title="节省内存空间"></a>节省内存空间</h3><p>SDS 结构中有个 flags 成员变量，表示的是 SDS 类型。</p>
<p>Redis 一共设计了 5 种类型，分别是 sdshdr5、sdshdr8、sdshdr16、sdshdr32 和 sdshdr64。</p>
<p>这 5 种类型的主要<strong>区别就在于，它们数据结构中的 len 和 alloc 成员变量的数据类型不同</strong>。</p>
<p>比如 sdshdr16 和 sdshdr32 这两个类型，它们的定义分别如下：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> __<span class="title">attribute__</span> ((__<span class="title">packed__</span>)) <span class="title">sdshdr16</span> &#123;</span></span><br><span class="line">    <span class="type">uint16_t</span> len;</span><br><span class="line">    <span class="type">uint16_t</span> alloc; </span><br><span class="line">    <span class="type">unsigned</span> <span class="type">char</span> flags; </span><br><span class="line">    <span class="type">char</span> buf[];</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">struct</span> __<span class="title">attribute__</span> ((__<span class="title">packed__</span>)) <span class="title">sdshdr32</span> &#123;</span></span><br><span class="line">    <span class="type">uint32_t</span> len;</span><br><span class="line">    <span class="type">uint32_t</span> alloc; </span><br><span class="line">    <span class="type">unsigned</span> <span class="type">char</span> flags;</span><br><span class="line">    <span class="type">char</span> buf[];</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<p>可以看到：</p>
<ul>
<li>sdshdr16 类型的 len 和 alloc 的数据类型都是 uint16_t，表示字符数组长度和分配空间大小不能超过 2 的 16 次方。</li>
<li>sdshdr32 则都是 uint32_t，表示表示字符数组长度和分配空间大小不能超过 2 的 32 次方。</li>
</ul>
<p><mark><strong>之所以 SDS 设计不同类型的结构体，是为了能灵活保存不同大小的字符串，从而有效节省内存空间</strong></mark>。比如，在保存小字符串时，结构头占用空间也比较少。</p>
<p>除了设计不同类型的结构体，Redis 在编程上还<strong>使用了专门的编译优化来节省内存空间</strong>，即在 struct 声明了 <code>__attribute__ ((packed))</code> ，它的作用是：<mark><strong>告诉编译器取消结构体在编译过程中的优化对齐，按照实际占用字节数进行对齐</strong></mark>。</p>
<p>比如，sdshdr16 类型的 SDS，默认情况下，编译器会按照 2 字节对齐的方式给变量分配内存，这意味着，即使一个变量的大小不到 2 个字节，编译器也会给它分配 2 个字节。</p>
<p>举个例子，假设下面这个结构体，它有两个成员变量，类型分别是 char 和 int，如下所示：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">test1</span> &#123;</span></span><br><span class="line">    <span class="type">char</span> a;</span><br><span class="line">    <span class="type">int</span> b;</span><br><span class="line"> &#125; test1;</span><br><span class="line"> </span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span> &#123;</span><br><span class="line">     <span class="built_in">printf</span>(<span class="string">&quot;%lu\n&quot;</span>, <span class="keyword">sizeof</span>(test1));</span><br><span class="line">     <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>大家猜猜这个结构体大小是多少？我先直接说答案，这个结构体大小计算出来是 8。</p>
<p><img src="/../assets/Redis%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86/35820959e8cf4376391c427ed7f81495.png" alt="img"></p>
<p>这是因为默认情况下，编译器是使用「字节对齐」的方式分配内存，虽然 char 类型只占一个字节，但是由于成员变量里有 int 类型，它占用了 4 个字节，所以在成员变量为 char 类型分配内存时，会分配 4 个字节，其中这多余的 3 个字节是为了字节对齐而分配的，相当于有 3 个字节被浪费掉了。</p>
<p>如果不想编译器使用字节对齐的方式进行分配内存，可以采用了 <code>__attribute__ ((packed))</code> 属性定义结构体，这样一来，结构体实际占用多少内存空间，编译器就分配多少空间。</p>
<p>比如，我用 <code>__attribute__ ((packed))</code> 属性定义下面的结构体 ，同样包含 char 和 int 两个类型的成员变量，代码如下所示：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">struct</span> __<span class="title">attribute__</span>((<span class="title">packed</span>)) <span class="title">test2</span>  &#123;</span></span><br><span class="line">    <span class="type">char</span> a;</span><br><span class="line">    <span class="type">int</span> b;</span><br><span class="line"> &#125; test2;</span><br><span class="line"> </span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span> &#123;</span><br><span class="line">     <span class="built_in">printf</span>(<span class="string">&quot;%lu\n&quot;</span>, <span class="keyword">sizeof</span>(test2));</span><br><span class="line">     <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>这时打印的结果是 5（1 个字节 char + 4 字节 int）。</p>
<p><img src="/../assets/Redis%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86/47e6c8fbc17fd6c89bdfcb5eedaaacff.png" alt="img"></p>
<p>可以看得出，这是<mark>按照实际占用字节数进行分配内存</mark>的，这样可以节省内存空间。</p>
<h2 id="双向链表"><a href="#双向链表" class="headerlink" title="双向链表"></a>双向链表</h2><p><img src="/../assets/Redis%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86/image-20231031131040258.png" alt="双向链表"></p>
<h3 id="链表的优势与缺陷"><a href="#链表的优势与缺陷" class="headerlink" title="链表的优势与缺陷"></a>链表的优势与缺陷</h3><p>Redis 的链表实现优点如下：</p>
<ul>
<li>listNode 链表节点的结构里带有 prev 和 next 指针，<strong>获取某个节点的前置节点或后置节点的时间复杂度只需O(1)，而且这两个指针都可以指向 NULL，所以链表是无环链表</strong>；</li>
<li>list 结构因为提供了表头指针 head 和表尾节点 tail，所以**获取链表的表头节点和表尾节点的时间复杂度只需O(1)**；</li>
<li>list 结构因为提供了链表节点数量 len，所以**获取链表中的节点数量的时间复杂度只需O(1)**；</li>
<li>listNode 链表节使用 void* 指针保存节点值，并且可以通过 list 结构的 dup、free、match 函数指针为节点设置该节点类型特定的函数，因此<strong>链表节点可以保存各种不同类型的值</strong>；</li>
</ul>
<p>链表的缺陷也是有的：</p>
<ul>
<li>链表每个节点之间的内存都是不连续的，意味着<strong>无法很好利用 CPU 缓存</strong>。能很好利用 CPU 缓存的数据结构就是数组，因为数组的内存是连续的，这样就可以充分利用 CPU 缓存来加速访问。</li>
<li>还有一点，保存一个链表节点的值都需要一个链表节点结构头的分配，<strong>内存开销较大</strong>。</li>
</ul>
<h3 id="对比数组和链表"><a href="#对比数组和链表" class="headerlink" title="对比数组和链表"></a>对比数组和链表</h3><p>对于数组和链表来说，其内存访问模式对CPU缓存的利用有很大影响：</p>
<ol>
<li>数组在内存中是一段连续的存储空间，这使得它具有很好的局部性原则。当CPU访问数组中的元素时，往往会预先加载相邻的数据到缓存中，以满足可能的后续访问需求。这种连续的存储模式有利于CPU缓存的预取和缓存行填充，从而提高访问速度。因为数组元素在内存中是连续排列的，一旦加载了数组的一个元素，接下来的元素也很可能已经在缓存中。</li>
<li>相比之下，链表的节点在内存中是分散存储的，每个节点通常存储在不同的内存位置。这会导致访问非常间断，使得缓存预取和填充效率降低。即使访问链表的一个节点，其后续节点并不一定存储在相邻的内存位置，这就增加了缓存未命中的概率，降低了CPU缓存的利用效率。</li>
</ol>
<h2 id="压缩列表"><a href="#压缩列表" class="headerlink" title="压缩列表"></a>压缩列表</h2><p>压缩列表的最大特点，就是它被设计成一种<strong>内存紧凑型</strong>的数据结构，占用一块连续的内存空间，不仅可以利用 CPU 缓存，而且会针对不同长度的数据，进行相应编码，这种方法可以有效地<mark>节省内存开销</mark>。</p>
<h3 id="结构设计"><a href="#结构设计" class="headerlink" title="结构设计"></a>结构设计</h3><p><img src="/../assets/Redis%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86/image-20231103200343073.png" alt="压缩列表结构图"></p>
<p>各个字段的含义：</p>
<ul>
<li><p><em><strong>zlbytes</strong></em>，记录整个压缩列表占用对内存字节数；</p>
</li>
<li><p><em><strong>zltail</strong></em>，记录压缩列表「尾部」节点距离起始地址由多少字节，也就是列表尾的偏移量；</p>
</li>
<li><p><em><strong>zllen</strong></em>，记录压缩列表包含的节点数量；</p>
</li>
<li><p><em><strong>zlend</strong></em>，标记压缩列表的结束点，固定值 0xFF（十进制255）。</p>
</li>
<li><p><em><strong>prevlen</strong></em>，记录了「前一个节点」的长度，目的是为了实现从后向前遍历；</p>
</li>
<li><p><em><strong>encoding</strong></em>，记录了当前节点实际数据的「类型和长度」，类型主要有两种：字符串和整数。</p>
</li>
<li><p><em><strong>data</strong></em>，记录了当前节点的实际数据，类型和长度都由 <code>encoding</code> 决定；</p>
</li>
</ul>
<p>🔴🟡🟢总结：</p>
<p>这里既不像数组那样有连续的相同的内存大小进行寻址，也不像链表那样有指针进行寻址，</p>
<p>但是压缩列表在<mark><strong>正序时</strong></mark>下一个元素就是该元素的首地址加上自身长度，自身长度包括【1. prelen代表前一个结点的长度，2. encoding记录类型，3. data真实数据】，由这三部分组成，这三个部分的长度都是可以经过计算得出的，故可以通过将地址加上自身长度得到下一个元素。</p>
<p><mark>逆序时</mark>：可以通过本身地址减去prelen，得到前一个元素的地址</p>
<p>所以也可以说这个压缩列表是<strong>双向的</strong>。</p>
<h3 id="连锁更新"><a href="#连锁更新" class="headerlink" title="连锁更新"></a>连锁更新</h3><blockquote>
<p>概率极低的事情</p>
</blockquote>
<p>ZipList的每个Entry都包含previous entry length来记录上一个节点的大小，长度是1个或5个字节:</p>
<ul>
<li>如果前一节点的长度小于254字节，则采用1个字节来保存这个长度值</li>
<li>如果前一节点的长度大于等于254字节，则采用5个字节来保存这个长度值，第一个字节为0xfe，后四个字节才是真实长度数据</li>
</ul>
<p>现在，假设我们有<mark>N个连续的、长度为250~253字节之间的entry</mark>（条件），因此entry的previous entry length属性用1个字节即可表示，如图所示:</p>
<p><img src="/../assets/Redis%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86/image-20231103201052893.png" alt="连锁更新"></p>
<p>ZipList这种特殊情况下产生的连续多次空间扩展操作称之为<mark>连锁更新</mark>(Cascade Update)。新增、删除都可能导致连锁更新的发生。</p>
<h3 id="缺陷"><a href="#缺陷" class="headerlink" title="缺陷"></a>缺陷</h3><ol>
<li><p>连锁更新一旦发生，就会导致压缩列表占用的内存空间要<mark>多次重新分配</mark>，这就会直接影响到压缩列表的访问性能。</p>
</li>
<li><p>不能保存过多的元素，否则查询效率就会降低。</p>
</li>
</ol>
<h2 id="哈希表"><a href="#哈希表" class="headerlink" title="哈希表"></a>哈希表</h2><h3 id="结构"><a href="#结构" class="headerlink" title="结构"></a>结构</h3><p>三个结构：</p>
<p>哈希表结构如下：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">dictht</span> &#123;</span></span><br><span class="line">    <span class="comment">//哈希表数组</span></span><br><span class="line">    dictEntry **table;</span><br><span class="line">    <span class="comment">//哈希表大小</span></span><br><span class="line">    <span class="type">unsigned</span> <span class="type">long</span> size;  </span><br><span class="line">    <span class="comment">//哈希表大小掩码，用于计算索引值</span></span><br><span class="line">    <span class="type">unsigned</span> <span class="type">long</span> sizemask;</span><br><span class="line">    <span class="comment">//该哈希表已有的节点数量</span></span><br><span class="line">    <span class="type">unsigned</span> <span class="type">long</span> used;</span><br><span class="line">&#125; dictht;</span><br></pre></td></tr></table></figure>

<p>哈希表节点的结构如下：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">dictEntry</span> &#123;</span></span><br><span class="line">    <span class="comment">//键值对中的键</span></span><br><span class="line">    <span class="type">void</span> *key;</span><br><span class="line">  </span><br><span class="line">    <span class="comment">//键值对中的值</span></span><br><span class="line">    <span class="class"><span class="keyword">union</span> &#123;</span></span><br><span class="line">        <span class="type">void</span> *val;</span><br><span class="line">        <span class="type">uint64_t</span> u64;</span><br><span class="line">        <span class="type">int64_t</span> s64;</span><br><span class="line">        <span class="type">double</span> d;</span><br><span class="line">    &#125; v;</span><br><span class="line">    <span class="comment">//指向下一个哈希表节点，形成链表</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">dictEntry</span> *<span class="title">next</span>;</span></span><br><span class="line">&#125; dictEntry;</span><br></pre></td></tr></table></figure>

<p>字典的结构如下：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">dict</span>&#123;</span></span><br><span class="line">    dictType *type;  <span class="comment">// dict类型，内置不同的hash函数</span></span><br><span class="line">    <span class="type">void</span> *privdata;  <span class="comment">// 私有数据，在做特殊hash运算时用</span></span><br><span class="line">    dicht ht[<span class="number">2</span>];  <span class="comment">// 一个Dict包含两个哈希表，其中一个时当前数据，另一个一般是空，rehash时使用</span></span><br><span class="line">    <span class="type">long</span> rehashidx;  <span class="comment">// rehash的进度，-1表示未进行</span></span><br><span class="line">    <span class="type">int16_t</span> pauserehash;  <span class="comment">// rehash是否暂停，1则暂停，0则继续</span></span><br><span class="line">&#125; dict;</span><br></pre></td></tr></table></figure>



<p>三种结构组成关系图：</p>
<p><img src="/../assets/Redis%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86/image-20231102203414049.png" alt="三种结构组成关系图"></p>
<p>Dict的结构</p>
<ul>
<li>类似java的HashTable，底层是数组加<mark>单向</mark>链表来解决哈希冲突</li>
<li>Dict包含两个哈希表，ht[0]平常用，ht[1]用来rehash</li>
</ul>
<blockquote>
<p>跟Java中的HashMap原理很像，但又有一点点差别</p>
</blockquote>
<h3 id="哈希冲突"><a href="#哈希冲突" class="headerlink" title="哈希冲突"></a>哈希冲突</h3><p>当出现哈希冲突的时候采用的是<strong>头插法</strong>，原因是方便，不用遍历到链表的末尾进行插入。</p>
<p>Redis是单线程，所以<strong>不会出现</strong>采用头插法时造成<strong>循环链表</strong>的可能。</p>
<blockquote>
<p>补充：当高并发时，<strong>多个线程并发</strong>地尝试在链表头部插入元素，在<strong>发生扩容</strong>且是<strong>头插法</strong>的情况下会导致循环链表，具体导致循环原因可参考本站：<a href="https://planbbbbb.github.io/2023/09/05/Java%E9%9B%86%E5%90%88/">https://planbbbbb.github.io/2023/09/05/Java%E9%9B%86%E5%90%88/</a></p>
</blockquote>
<h3 id="rehash"><a href="#rehash" class="headerlink" title="rehash"></a>rehash</h3><p>Dict的rehash并不是一次性完成的。试想一下，如果Dict中包含数百万的entry，要在一次rehash完成，极有可能导致主线程阳寒。因此Dict的rehash是分多次、渐进式的完成，因此称为渐进式rehash。</p>
<p><strong>流程如下：</strong></p>
<ol>
<li><p>计算新hash表的size，值取决于当前要做的是扩容还是收缩:</p>
<ul>
<li>如果是扩容，则新size为第一个大于等于dict.ht[0].used +1的2的n次方，<mark>即当前元素个数+1后的第一个2^n的数</mark></li>
<li>如果是收缩，则新size为第一个大于等于dict.htlol.used的2^n (不得小于4)，与上面同理，<mark>找到比它大的第一个2的n次方的数</mark></li>
</ul>
</li>
<li><p>按照新的size申请内存空间，创建dictht，并赋值给dict.ht[1]</p>
</li>
<li><p>设置dict.rehashidx&#x3D;0，标示开始rehash（<strong>未进行rehash时值为-1</strong>）</p>
</li>
<li><p><del>将dict.ht[0]中的每一个dictEntry都rehash到dict.ht[1]</del>（不能一次性全部转移，这样在数据量很大的时候可能会导致主进程的阻塞）</p>
</li>
<li><p>每次执行新增、查询、修改、删除操作时，都检查一下dict.rehashidx是否大于-1，如果是则将dict.ht[0].table[rehashidx]的entry链表rehash到dict.ht[1]，并且将rehashidx++。直至dict.ht[0]的所有数据都rehash到dict.ht[1]</p>
</li>
<li><p>将dict.ht[1]赋值给dict.ht[0]，给dict.ht[1]初始化为空哈希表，释放原来的dict.ht[0]的内存</p>
</li>
<li><p>将rehashidx赋值为-1，代表rehash结束</p>
</li>
<li><p>在rehash过程中，<strong>新增操作</strong>，则直接写入ht[1]，<strong>查询、修改和删除</strong>则会在dict.ht[0]和dict.ht[1]依次查找并执行。这样可以确保ht[0]的数据只减不增，随着rehash最终为空</p>
</li>
</ol>
<blockquote>
<p>🌈负载因子 &#x3D; 哈希表已保存节点数量 &#x2F;哈希表大小</p>
</blockquote>
<p>触发 rehash 操作的条件，主要有两个：</p>
<ul>
<li>当负载因子大于等于 1 ，并且 Redis 没有在执行 bgsave 命令或者 bgrewiteaof 命令，也就是没有执行 RDB 快照或没有进行 AOF 重写的时候，就会进行 rehash 操作。</li>
<li>当负载因子大于等于 5 时，此时说明哈希冲突非常严重了，不管有没有有在执行 RDB 快照或 AOF 重写，都会强制进行 rehash 操作。</li>
</ul>
<h2 id="跳表"><a href="#跳表" class="headerlink" title="跳表"></a>跳表</h2><h3 id="结构-1"><a href="#结构-1" class="headerlink" title="结构"></a>结构</h3><ol>
<li>实现原理</li>
</ol>
<p>跳跃表实质上是对一个有序的链表进行<strong>类似于二分查找</strong>的数据结构，其性能与红黑树，AVL树不相上下。</p>
<p>原本要依次遍历从1开始找17，现在从三级索引找到10，再从二级索引找到15，在一级索引就能找到17了。</p>
<p><img src="/../assets/Redis%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86/image-20231023222430354.png" alt="跳跃表"></p>
<ol start="2">
<li>具体结构</li>
</ol>
<p>跳表节点结构：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">zskiplistNode</span> &#123;</span></span><br><span class="line">    <span class="comment">//Zset 对象的元素值</span></span><br><span class="line">    sds ele;</span><br><span class="line">    <span class="comment">//元素权重值</span></span><br><span class="line">    <span class="type">double</span> score;</span><br><span class="line">    <span class="comment">//后向指针</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">zskiplistNode</span> *<span class="title">backward</span>;</span></span><br><span class="line">  </span><br><span class="line">    <span class="comment">//节点的level数组，保存每层上的前向指针和跨度</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">zskiplistLevel</span> &#123;</span></span><br><span class="line">        <span class="class"><span class="keyword">struct</span> <span class="title">zskiplistNode</span> *<span class="title">forward</span>;</span></span><br><span class="line">        <span class="type">unsigned</span> <span class="type">long</span> span;</span><br><span class="line">    &#125; level[];</span><br><span class="line">&#125; zskiplistNode;</span><br></pre></td></tr></table></figure>

<p>跳表结构：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">zskiplist</span> &#123;</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">zskiplistNode</span> *<span class="title">header</span>, *<span class="title">tail</span>;</span></span><br><span class="line">    <span class="type">unsigned</span> <span class="type">long</span> length;</span><br><span class="line">    <span class="type">int</span> level;</span><br><span class="line">&#125; zskiplist;</span><br></pre></td></tr></table></figure>

<hr>
<p>配合上结构体的跳表结构图：</p>
<p><img src="/../assets/Redis%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86/image-20231105102654240.png" alt="配合上结构体的跳表结构图"></p>
<h3 id="为什么用跳表而不是平衡树"><a href="#为什么用跳表而不是平衡树" class="headerlink" title="为什么用跳表而不是平衡树"></a>为什么用跳表而不是平衡树</h3><ul>
<li><strong>从内存占用上来比较，跳表比平衡树更灵活一些</strong>。平衡树每个节点包含 2 个指针（分别指向左右子树），而跳表每个节点包含的指针数目平均为 1&#x2F;(1-p)，具体取决于参数 p 的大小。如果像 Redis里的实现一样，取 p&#x3D;1&#x2F;4，那么平均每个节点包含 1.33 个指针，比平衡树更有优势。</li>
<li><strong>在做范围查找的时候，跳表比平衡树操作要简单</strong>。在平衡树上，我们找到指定范围的小值之后，还需要以中序遍历的顺序继续寻找其它不超过大值的节点。如果不对平衡树进行一定的改造，这里的中序遍历并不容易实现。而在跳表上进行范围查找就非常简单，只需要在找到小值之后，对第 1 层链表进行若干步的遍历就可以实现。</li>
<li><strong>从算法实现难度上来比较，跳表比平衡树要简单得多</strong>。平衡树的插入和删除操作可能引发子树的调整，逻辑复杂，而跳表的插入和删除只需要修改相邻节点的指针，操作简单又快速。</li>
</ul>
<h2 id="整数集合"><a href="#整数集合" class="headerlink" title="整数集合"></a>整数集合</h2><p>整数集合是 Set 对象的底层实现之一。当一个 Set 对象只包含整数值元素，并且元素数量不大时，就会使用整数集这个数据结构作为底层实现。</p>
<h3 id="整数集合结构设计"><a href="#整数集合结构设计" class="headerlink" title="整数集合结构设计"></a>整数集合结构设计</h3><p>整数集合本质上是一块连续内存空间，它的结构定义如下：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">intset</span> &#123;</span></span><br><span class="line">    <span class="comment">//编码方式</span></span><br><span class="line">    <span class="type">uint32_t</span> encoding;</span><br><span class="line">    <span class="comment">//集合包含的元素数量</span></span><br><span class="line">    <span class="type">uint32_t</span> length;</span><br><span class="line">    <span class="comment">//保存元素的数组</span></span><br><span class="line">    <span class="type">int8_t</span> contents[];</span><br><span class="line">&#125; intset;</span><br></pre></td></tr></table></figure>

<p>contents 数组的真正类型取决于 intset 结构体里的 encoding 属性的值，对应的有16，32，64。</p>
<blockquote>
<p>其实就是对应着Java里的short，int，long类型。</p>
</blockquote>
<h3 id="升级机制"><a href="#升级机制" class="headerlink" title="升级机制"></a>升级机制</h3><p><em>目的是<mark>节省内存空间</mark></em></p>
<p>当我们将一个新元素加入到整数集合里面，如果新元素的类型（int32_t）比整数集合现有所有元素的类型（int16_t）都要长时，整数集合需要先进行<mark>升级</mark>，升级要<strong>先将原有的内存空间<mark>扩容到刚好能放的下</mark>加上新元素后，且所有元素都是新的数据类型的内存大小</strong>，再将原有的元素<mark>倒叙排入</mark>对应的位置，最后在将新的元素放在<mark>头或者尾</mark>。</p>
<p>🌈解释：</p>
<blockquote>
<p>其实就是原本的元素类型不够大，存不下新的数，就比如short类型的数据类型存不下新进来的50000，所以要进行元素类型上的升级。</p>
</blockquote>
<blockquote>
<p>这里倒叙的原因是防止覆盖原有的元素，倒叙不会覆盖到原有的元素。</p>
</blockquote>
<blockquote>
<p>新元素放在头或者尾的原因是只有当这个元素比所有元素都大或者比所有元素都小才有可能引发升级，才会使得原有的数据类型放不了该元素。</p>
</blockquote>
<p>扩容图：</p>
<p><img src="/../assets/Redis%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86/image-20231102150034860.png" alt="扩容"></p>
<p>倒叙插入流程图：</p>
<p><img src="/../assets/Redis%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86/image-20231102150003744.png" alt="倒叙插入流程"></p>
<p>整数集合<mark><strong>不支持降级操作</strong></mark>，一旦对数组进行了升级，就会一直保持升级后的状态。比如前面的升级操作的例子，如果删除了 65535 元素，整数集合的数组还是 int32_t 类型的，并不会因此降级为 int16_t 类型。</p>
<p>🍕整数集合升级的<strong>好处</strong>：</p>
<p>当元素全都是int32_t时，那么数组就会采用int32_t的元素类型，不会浪费空间，只有当有元素超过int32_t时才会去升级为int64_t，目的就是节省内存。</p>
<blockquote>
<p>个人思考：说到节省空间，这一点整数集合其实做的没有<strong>SDS或者压缩列表</strong>做的好，SDS废除了字节对齐，让不同类型长度的元素都能放在一起，但是整数集合其实不能这么做，因为他底层是个数组，他是连续的内存空间，要靠第一个值的地址，通过固定的运算去快速得到后面的值。</p>
</blockquote>
<h3 id="查询方式"><a href="#查询方式" class="headerlink" title="查询方式"></a>查询方式</h3><p>底层采用<mark>二分查找</mark>进行查询，所以当数据量很大的时候其实也不建议使用整数集合来进行存储了。</p>
<h2 id="quicklist"><a href="#quicklist" class="headerlink" title="quicklist"></a>quicklist</h2><p>在 Redis 3.0 之前，List 对象的底层数据结构是双向链表或者压缩列表。然后在 Redis 3.2 的时候，List 对象的底层改由 quicklist 数据结构实现。</p>
<p>其实 quicklist 就是<mark>「双向链表 + 压缩列表」组合</mark>，因为一个 quicklist 就是一个链表，而链表中的每个元素又是一个压缩列表。</p>
<p>quicklist 解决办法，<strong>通过控制每个链表节点中的压缩列表的大小或者元素个数，来规避连锁更新的问题。因为压缩列表元素越少或越小，连锁更新带来的影响就越小，从而提供了更好的访问性能。</strong></p>
<h3 id="结构-2"><a href="#结构-2" class="headerlink" title="结构"></a>结构</h3><p>首先在列表元素较少的情况下会使用一块连续的内存存储，这个结构是 ziplist，也即是压缩列表。它将所有的元素紧挨着一起存储，分配的是一块连续的内存。<br>当数据量比较多的时候才会改成 quicklist。因为普通的链表需要的附加指针空间太大，会比较浪费空间。比如这个列表里存的只是 int 类型的数据，结构上还需要两个额外的指针 prev 和 next。</p>
<p><img src="/../assets/Redis%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86/image-20231104102445783.png" alt="结构图"></p>
<p>Redis 将链表和 ziplist 结合起来组成了 quicklist。也就是将多个 ziplist 使用双向指针串起来使用。这样既满足了快速的插入删除性能，又不会出现太大的空间冗余。</p>
<p>在向 quicklist 添加一个元素的时候，不会像普通的链表那样，直接新建一个链表节点。而是会检查插入位置的压缩列表是否能容纳该元素，如果能容纳就直接保存到 quicklistNode 结构里的压缩列表，如果不能容纳，才会新建一个新的 quicklistNode 结构。</p>
<p>quicklist 会控制 quicklistNode 结构里的压缩列表的大小或者元素个数，来规避潜在的连锁更新的风险，但是这并<mark>没有完全解决连锁更新</mark>的问题。</p>
<h2 id="listpack"><a href="#listpack" class="headerlink" title="listpack"></a>listpack</h2><blockquote>
<p>本质上还是压缩列表，只是在版本更迭的时候进行了优化</p>
</blockquote>
<p><mark>最大特点</mark>是 listpack 中每个节点不再包含前一个节点的长度了，压缩列表每个节点正因为需要保存前一个节点的长度字段，就会有连锁更新的隐患。</p>
<h3 id="listpack-结构设计"><a href="#listpack-结构设计" class="headerlink" title="listpack 结构设计"></a>listpack 结构设计</h3><p>listpack 采用了压缩列表的很多优秀的设计，比如还是用一块连续的内存空间来紧凑地保存数据，并且为了节省内存的开销，listpack 节点会采用不同的编码方式保存不同大小的数据。</p>
<p>我们先看看 listpack 结构：</p>
<p><img src="/../assets/Redis%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86/4d2dc376b5fd68dae70d9284ae82b73a.png" alt="img"></p>
<p>listpack 头包含两个属性，分别记录了 listpack 总字节数和元素数量，然后 listpack 末尾也有个结尾标识。图中的 listpack entry 就是 listpack 的节点了。</p>
<p>每个 listpack 节点结构如下：</p>
<p><img src="/../assets/Redis%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86/c5fb0a602d4caaca37ff0357f05b0abf.png" alt="img"></p>
<p>主要包含三个方面内容：</p>
<ul>
<li>encoding，定义该元素的编码类型，会对不同长度的整数和字符串进行编码；</li>
<li>data，实际存放的数据；</li>
<li>len，encoding+data的总长度；</li>
</ul>
<p>可以看到，<strong>listpack 没有压缩列表中记录前一个节点长度的字段了，listpack 只记录当前节点的长度，当我们向 listpack 加入一个新元素的时候，不会影响其他节点的长度字段的变化，从而避免了压缩列表的连锁更新问题</strong>。</p>
<h3 id="修改后不会影响遍历吗"><a href="#修改后不会影响遍历吗" class="headerlink" title="修改后不会影响遍历吗"></a>修改后不会影响遍历吗</h3><p>在listpack中将原来的prelen替换为了len，原有的prelen是为了能从后向前去遍历元素的，现在改为了len，记录的是当前结点的长度。</p>
<p>解决办法是：</p>
<p><strong>lpDecodeBacklen 函数就可以从当前列表项起始位置的指针开始，向左逐个字节解析，得到前一项的 entry-len 值。</strong></p>
<p>这样依然能进行从后往前遍历。</p>
<h2 id="RedisObject"><a href="#RedisObject" class="headerlink" title="RedisObject"></a>RedisObject</h2><ol>
<li>每一个Redis对象最终都会封装为一个RedisObject对象，结构图如下：</li>
</ol>
<p><img src="/../assets/Redis%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86/image-20231105105905430.png" alt="image-20231105105905430"></p>
<p>字段解释：</p>
<ul>
<li>type，标识该对象是什么类型的对象（String 对象、 List 对象、Hash 对象、Set 对象和 Zset 对象）；</li>
<li>encoding，标识该对象使用了哪种底层的数据结构；</li>
<li>lru，用于判断空闲时间太久的key，做内存淘汰处理</li>
<li>refcount，类似于jvm中的引用计数法，无人引用时可被回收</li>
<li>ptr，指向<mark>底层数据结构</mark>的指针。</li>
</ul>
<ol start="2">
<li>encoding的11种类型：</li>
</ol>
<p><img src="/../assets/Redis%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86/image-20231105105930395.png" alt="image-20231105105930395"></p>
<ol start="3">
<li>五种基本数据类型的底层编码方式：</li>
</ol>
<p><img src="/../assets/Redis%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86/image-20231105105954746.png" alt="image-20231105105954746"></p>
<blockquote>
<p>补充：类似于bitmap，hyperloglog底层其实都是String类型，GEO底层其实就是ZSet类型</p>
</blockquote>
<h1 id="Redis应用"><a href="#Redis应用" class="headerlink" title="Redis应用"></a>Redis应用</h1><h2 id="缓存穿透"><a href="#缓存穿透" class="headerlink" title="缓存穿透"></a>缓存穿透</h2><h3 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h3><p><strong>缓存穿透是指客户端请求的数据在缓存中和数据库中都不存在，这样缓存永远不会生效，这些请求都会打到数据库。</strong></p>
<p><img src="/../assets/Redis%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86/image-20230803213519682.png" alt="image-20230803213519682"></p>
<h3 id="常见解决方案"><a href="#常见解决方案" class="headerlink" title="常见解决方案"></a>常见解决方案</h3><ol>
<li>缓存空对象</li>
</ol>
<ul>
<li><p>优点：方便简单</p>
</li>
<li><p>缺点：可能造成额外的内存消耗，可能造成短期的不一致</p>
</li>
</ul>
<blockquote>
<p>若有用户恶意使用多个不同id进行查询，则redis会不断缓存很多没有用的null值造成浪费，但可以通过为key添加过期时间解决。</p>
<p>短期不一致是因为数据库已经更新数据而redis中仍为null值，其实可以通过插入数据的同时手动更改redis的值来解决。</p>
</blockquote>
<p><img src="/../assets/Redis%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86/image-20230803213834986.png" alt="image-20230803213834986"></p>
<ol start="2">
<li>布隆过滤器过滤</li>
</ol>
<p>在查询redis前先经过布隆过滤器，若redis中存在才放行。</p>
<p>布隆过滤器由于是基于哈希函数实现查找的，高效查找的同时<mark><strong>存在哈希冲突的可能性</strong></mark>。</p>
<ul>
<li>优点：内存占用少，没有多余的key</li>
<li>缺点：可能误判，查询布隆过滤器说数据存在，并不一定证明数据库中存在这个数据，但是查询到数据不存在，数据库中一定就不存在这个数据。</li>
</ul>
<p><img src="/../assets/Redis%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86/image-20230803214619650.png" alt="image-20230803214619650"></p>
<h2 id="缓存雪崩"><a href="#缓存雪崩" class="headerlink" title="缓存雪崩"></a>缓存雪崩</h2><h3 id="定义-1"><a href="#定义-1" class="headerlink" title="定义"></a>定义</h3><p><strong>缓存雪崩是指在同一时段大量的缓存key同时失效或者Redis服务宕机，导致大量请求到达数据库，带来巨大压力。</strong></p>
<p><img src="/../assets/Redis%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86/image-20230804102636911.png" alt="image-20230804102636911"></p>
<h3 id="常见解决方案-1"><a href="#常见解决方案-1" class="headerlink" title="常见解决方案"></a>常见解决方案</h3><ol>
<li><p>给不同的Key的TTL添加随机值</p>
</li>
<li><p>后台更新缓存</p>
</li>
</ol>
<blockquote>
<p>将更新缓存的工作交由后台线程定时更新</p>
</blockquote>
<p>解决方式有两种：</p>
<p>第一种方式，后台线程不仅负责定时更新缓存，而且也负责<mark><strong>频繁地检测缓存是否有效</strong></mark>，检测到缓存失效了，原因可能是系统紧张而被淘汰的，于是就要马上从数据库读取数据，并更新到缓存。</p>
<p>这种方式的检测时间间隔不能太长，太长也导致用户获取的数据是一个空值而不是真正的数据，所以检测的间隔最好是毫秒级的，但是总归是有个间隔时间，用户体验一般。</p>
<p>第二种方式，在业务线程发现缓存数据失效后（缓存数据被淘汰），<mark><strong>通过消息队列发送一条消息通知后台线程更新缓存</strong></mark>，后台线程收到消息后，在更新缓存前可以判断缓存是否存在，存在就不执行更新缓存操作；不存在就读取数据库数据，并将数据加载到缓存。这种方式相比第一种方式缓存的更新会更及时，用户体验也比较好。</p>
<p>在业务刚上线的时候，我们最好提前把数据缓起来，而不是等待用户访问才来触发缓存构建，这就是所谓的<mark><strong>缓存预热</strong></mark>，后台更新缓存的机制刚好也适合干这个事情。</p>
<ol start="3">
<li>利用Redis集群提高服务的可用性</li>
</ol>
<p>通过<strong>主从节点的方式构建 Redis 缓存高可靠集群</strong>。</p>
<p>如果 Redis 缓存的主节点故障宕机，<mark>从节点可以切换成为主节点</mark>，继续提供缓存服务，避免了由于 Redis 故障宕机而导致的缓存雪崩问题。</p>
<ol start="4">
<li>服务熔断或请求限流机制</li>
</ol>
<p>因为 Redis 故障宕机而导致缓存雪崩问题时，我们可以启动<mark><strong>服务熔断</strong></mark>机制，<strong>暂停业务应用对缓存服务的访问，直接返回错误</strong>，不用再继续访问数据库，从而降低对数据库的访问压力，保证数据库系统的正常运行，然后等到 Redis 恢复正常后，再允许业务应用访问缓存服务。</p>
<p>服务熔断机制是保护数据库的正常允许，但是暂停了业务应用访问缓存服系统，全部业务都无法正常工作</p>
<p>为了减少对业务的影响，我们可以启用<mark><strong>请求限流</strong></mark>机制，<strong>只将少部分请求发送到数据库进行处理，再多的请求就在入口直接拒绝服务</strong>，等到 Redis 恢复正常并把缓存预热完后，再解除请求限流的机制。</p>
<ol start="5">
<li>给业务添加多级缓存</li>
</ol>
<blockquote>
<p>同一时段大量的缓存key同时失效采用方案1和2和互斥锁方案。</p>
<p>redis宕机采用方案3，4，5，redis集群中主库挂了还要从库数据，用sentinel可以降级限流，多级缓存可用nginx，jvm等进行缓存。</p>
</blockquote>
<h2 id="缓存击穿"><a href="#缓存击穿" class="headerlink" title="缓存击穿"></a>缓存击穿</h2><h3 id="定义-2"><a href="#定义-2" class="headerlink" title="定义"></a>定义</h3><p><strong>缓存击穿问题也叫<code>热点Key问题</code>，就是一个被高并发访问并且缓存重建业务较复杂的key突然失效了，无数的请求访问会在瞬间给数据库带来巨大的冲击。</strong></p>
<h3 id="常见解决方案-2"><a href="#常见解决方案-2" class="headerlink" title="常见解决方案"></a>常见解决方案</h3><ol>
<li>互斥锁</li>
</ol>
<blockquote>
<p>1000个进程来同时访问，一个进程拿到锁，其余999个进程都要等到线程1查询数据库重新写入缓存，释放锁之后才能访问，性能差，但是有强一致性</p>
</blockquote>
<p><img src="/../assets/Redis%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86/image-20230804105357783.png" alt="image-20230804105357783"></p>
<ol start="2">
<li>逻辑过期</li>
</ol>
<blockquote>
<p>就是在redis保存数据的时候多保存一个过期时间字段，通常是在活动开始到结束那一个时间段内都不会过期，也就不会突然失效了。若<strong>失效（这里说的失效指的是逻辑时间过期了）</strong>了也是要通过锁的形式去重新查数据库，存缓存，释放锁。</p>
<p>不过相对于互斥锁而言，这里的锁不一样了。这里线程1获得锁之后交给另外的线程去执行查数据库等操作，而线程1自身则返回旧的数据。其他进程在释放锁之前来访问都是返回的旧数据，只有当释放锁，即完成了查数据库，存入缓存，更新逻辑过期时间后才能返回新数据。</p>
</blockquote>
<p><img src="/../assets/Redis%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86/image-20230804110145305.png" alt="image-20230804110145305"></p>
<h3 id="两种方案对比"><a href="#两种方案对比" class="headerlink" title="两种方案对比"></a>两种方案对比</h3><table>
<thead>
<tr>
<th>解决方案</th>
<th>优点</th>
<th>缺点</th>
</tr>
</thead>
<tbody><tr>
<td>互斥锁</td>
<td>没有额外的内存消耗，保证一致性，实现简单</td>
<td>线程需要等待，性能受影响，可能有死锁</td>
</tr>
<tr>
<td>逻辑过期</td>
<td>线程无需等待，性能较好</td>
<td>不保证一致性，有额外内存消耗，实现复杂</td>
</tr>
</tbody></table>
<h2 id="缓存与数据库保持一致问题"><a href="#缓存与数据库保持一致问题" class="headerlink" title="缓存与数据库保持一致问题"></a>缓存与数据库保持一致问题</h2><h3 id="先更新数据库，还是先更新缓存？"><a href="#先更新数据库，还是先更新缓存？" class="headerlink" title="先更新数据库，还是先更新缓存？"></a>先更新数据库，还是先更新缓存？</h3><ol>
<li>先更新数据库再更新缓存</li>
</ol>
<p><mark>会出现并发问题</mark></p>
<p><img src="/../assets/Redis%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86/image-20231031150644998.png" alt="先更新数据库再更新缓存"></p>
<ol start="2">
<li>先更新缓存再更新数据库</li>
</ol>
<p><mark>也会出现并发问题</mark></p>
<p><img src="/../assets/Redis%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86/image-20231031150609307.png" alt="先更新缓存再更新数据库"></p>
<p>所以，<strong>无论是「先更新数据库，再更新缓存」，还是「先更新缓存，再更新数据库」，这两个方案<mark>都存在并发问题</mark>，当两个请求并发更新同一条数据的时候，可能会出现缓存和数据库中的数据不一致的现象</strong>。</p>
<p>增加一些手段来解决这个问题，这里提供两种做法：</p>
<ul>
<li>在更新缓存前先加个<strong>分布式锁</strong>，保证同一时间只运行一个请求更新缓存，就会不会产生并发问题了，当然引入了锁后，对于写入的性能就会带来影响。</li>
<li>在更新完缓存时，给缓存加上较短的<strong>过期时间</strong>，这样即时出现缓存不一致的情况，缓存的数据也会很快过期，对业务还是能接受的。</li>
</ul>
<h3 id="先更新数据库，还是先删除缓存？"><a href="#先更新数据库，还是先删除缓存？" class="headerlink" title="先更新数据库，还是先删除缓存？"></a>先更新数据库，还是先删除缓存？</h3><p><strong>Cache Aside 策略</strong>：在更新数据时，不更新缓存，而是删除缓存中的数据。然后，到读取数据时，发现缓存中没了数据之后，再从数据库中读取数据，更新到缓存中。</p>
<p><img src="/../assets/Redis%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86/image-20231031151154103.png" alt="Cache Aside 策略"></p>
<p><strong>写策略的步骤：</strong></p>
<ul>
<li>更新数据库中的数据；</li>
<li>删除缓存中的数据。</li>
</ul>
<p><strong>读策略的步骤：</strong></p>
<ul>
<li>如果读取的数据命中了缓存，则直接返回数据；</li>
<li>如果读取的数据没有命中缓存，则从数据库中读取数据，然后将数据写入到缓存，并且返回给用户。</li>
</ul>
<ol>
<li>先删除缓存，再更新数据库</li>
</ol>
<p>假设某个用户的年龄是 20，请求 A 要更新用户年龄为 21，所以它会删除缓存中的内容。这时，另一个请求 B 要读取这个用户的年龄，它查询缓存发现未命中后，会从数据库中读取到年龄为 20，并且写入到缓存中，然后请求 A 继续更改数据库，将用户的年龄更新为 21。</p>
<p><img src="/../assets/Redis%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86/cc208c2931b4e889d1a58cb655537767.png" alt="先删除缓存再更新数据库"></p>
<p>最终，该用户年龄在缓存中是 20（旧值），在数据库中是 21（新值），缓存和数据库的数据不一致。</p>
<p>可以看到，<strong>先删除缓存，再更新数据库，在「读 + 写」并发的时候，还是会出现缓存和数据库的数据不一致的问题</strong>。</p>
<p>针对<strong>「先删除缓存，再更新数据库」</strong>方案在「读 + 写」并发请求而造成缓存不一致的解决办法是「<strong>延迟双删</strong>」。（对于上面那张图而言，延迟删除的时机就在<mark>请求B结束为止即可进行延迟删除</mark>）</p>
<p>延迟双删实现的伪代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">#删除缓存</span><br><span class="line">redis.delKey(X)</span><br><span class="line">#更新数据库</span><br><span class="line">db.update(X)</span><br><span class="line">#睡眠</span><br><span class="line">Thread.sleep(N)</span><br><span class="line">#再删除缓存</span><br><span class="line">redis.delKey(X)</span><br></pre></td></tr></table></figure>

<p>加了个睡眠时间，主要是为了确保请求 A 在睡眠的时候，请求 B 能够在这这一段时间完成「从数据库读取数据，再把缺失的缓存写入缓存」的操作，然后请求 A 睡眠完，再删除缓存。</p>
<p>所以，请求 A 的睡眠时间就需要大于请求 B 「从数据库读取数据 + 写入缓存」的时间。</p>
<p>但是具体睡眠多久其实是个<strong>玄学</strong>，很难评估出来，所以这个方案也只是<strong>尽可能</strong>保证一致性而已，极端情况下，依然也会出现缓存不一致的现象。</p>
<p>因此，还是比较建议用<strong>「先更新数据库，再删除缓存」</strong>的方案。</p>
<ol start="2">
<li>先更新数据库，再删除缓存</li>
</ol>
<p>假如某个用户数据在缓存中不存在，请求 A 读取数据时从数据库中查询到年龄为 20，在未写入缓存中时另一个请求 B 更新数据。它更新数据库中的年龄为 21，并且清空缓存。这时请求 A 把从数据库中读到的年龄为 20 的数据写入到缓存中。</p>
<p><img src="/../assets/Redis%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86/image-20231031152630816.png" alt="先更新数据库，再删除缓存"></p>
<p>理论上来讲这样先更新数据库再删除缓存也是会导致数据库缓存的不一致的，但是<mark>实际上发生这样的情况的几率很小</mark>，因为将写缓存的操作是要远远快于更新数据库的。</p>
<p>这个方案的基础上再加上对key做过期处理，就是一个可行的方案了，即使有一段时间的数据不一致，也会有过期策略来保底。</p>
<hr>
<p>但是上面的情况的前提是<strong>更新数据库</strong>和<strong>删除缓存</strong>这两件事是同时发生且都成功的情况下的，要做到同时发生，可以使用<code>lua</code>脚本进行原子性的操作，要做到都成功有以下两种方法：</p>
<ul>
<li>重试机制。</li>
<li>订阅 MySQL binlog，再操作缓存。</li>
</ul>
<ol>
<li>重试机制</li>
</ol>
<p>我们可以引入<strong>消息队列</strong>，将第二个操作（删除缓存）要操作的数据加入到消息队列，由消费者来操作数据。</p>
<ul>
<li>如果应用<strong>删除缓存失败</strong>，可以从消息队列中重新读取数据，然后再次删除缓存，这个就是<strong>重试机制</strong>。当然，如果重试超过的一定次数，还是没有成功，我们就需要向业务层发送报错信息了。</li>
<li>如果<strong>删除缓存成功</strong>，就要把数据从消息队列中移除，避免重复操作，否则就继续重试。</li>
</ul>
<p>举个例子，来说明重试机制的过程。</p>
<p><img src="/../assets/Redis%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86/image-20231031162859822.png" alt="消息队列重试机制"></p>
<ol start="2">
<li>订阅 MySQL binlog，再操作缓存</li>
</ol>
<p>「<strong>先更新数据库，再删缓存</strong>」的策略的第一步是更新数据库，那么更新数据库成功，就会产生一条变更日志，记录在 binlog 里。</p>
<p>于是我们就可以通过订阅 binlog 日志，拿到具体要操作的数据，然后再执行缓存删除，阿里巴巴开源的 Canal 中间件就是基于这个实现的。</p>
<p>Canal 模拟 MySQL 主从复制的交互协议，把自己伪装成一个 MySQL 的从节点，向 MySQL 主节点发送 dump 请求，MySQL 收到请求后，就会开始推送 Binlog 给 Canal，Canal 解析 Binlog 字节流之后，转换为便于读取的结构化数据，供下游程序订阅使用。</p>
<p>下图是 Canal 的工作原理：</p>
<p><img src="/../assets/Redis%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86/2ee2280e9f59b6b4879ebdec6eb0cf52.png" alt="图片"></p>
<p>所以，<strong>如果要想保证「先更新数据库，再删缓存」策略第二个操作能执行成功，我们可以使用「消息队列来重试缓存的删除」，或者「订阅 MySQL binlog 再操作缓存」，这两种方法有一个共同的特点，<mark>都是采用异步操作缓存</mark>。</strong></p>
<blockquote>
<p>为什么是删除缓存，而不是更新缓存呢？</p>
</blockquote>
<p>删除一个数据，相比更新一个数据更加轻量级，出问题的概率更小。</p>
<p>比如商品详情信息，在底层可能会关联商品表、价格表、库存表等，如果更新了一个价格字段，那么就要更新整个数据库，还要关联的去查询和汇总各个周边业务系统的数据，这个操作会非常耗时。 从另外一个角度，不是所有的缓存数据都是频繁访问的，更新后的缓存可能会长时间不被访问，所以说，从计算资源和整体性能的考虑，更新的时候删除缓存，等到下次查询命中再填充缓存，是一个更好的方案。</p>
<h3 id="🔴🟡🟢总结"><a href="#🔴🟡🟢总结" class="headerlink" title="🔴🟡🟢总结"></a>🔴🟡🟢总结</h3><p>先更新数据库，再删除缓存，搭配上消息队列和过期策略就是最好的方案。</p>
<blockquote>
<p>数据要求一致性不强的时候就延迟双删，要求强一致就读写锁，性能差。</p>
</blockquote>
<h2 id="分布式锁"><a href="#分布式锁" class="headerlink" title="分布式锁"></a>分布式锁</h2><h3 id="核心思想"><a href="#核心思想" class="headerlink" title="核心思想"></a>核心思想</h3><p>分布式锁的核心思想就是让大家共用同一把锁，那么我们就能锁住线程，不让线程进行，让程序串行执行，这就是分布式锁的核心思路。</p>
<p><img src="/../assets/Redis%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86/image-20230819135201384.png" alt="image-20230819135201384"></p>
<h3 id="实现代码"><a href="#实现代码" class="headerlink" title="实现代码"></a>实现代码</h3><ol>
<li>分布式锁</li>
</ol>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">SimpleRedisLock</span> <span class="keyword">implements</span> <span class="title class_">ILock</span> &#123;</span><br><span class="line">    <span class="comment">//锁的前缀</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="type">String</span> <span class="variable">KEY_PREFIX</span> <span class="operator">=</span> <span class="string">&quot;lock:&quot;</span>;</span><br><span class="line">    <span class="comment">//利用UUID增加复杂度</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="type">String</span> <span class="variable">ID_PREFIX</span> <span class="operator">=</span> UUID.randomUUID().toString(<span class="literal">true</span>) + <span class="string">&quot;-&quot;</span>;</span><br><span class="line">    <span class="comment">//具体业务名称，将前缀和业务名拼接之后当做Key</span></span><br><span class="line">    <span class="keyword">private</span> String name;</span><br><span class="line">    <span class="comment">//这里不需要@Autowired，因为该对象是我们使用构造函数手动new出来的</span></span><br><span class="line">    <span class="keyword">private</span> StringRedisTemplate stringRedisTemplate;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> DefaultRedisScript&lt;Long&gt; UNLOCK_SCRIPT;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">static</span> &#123;</span><br><span class="line">        UNLOCK_SCRIPT = <span class="keyword">new</span> <span class="title class_">DefaultRedisScript</span>();</span><br><span class="line">        UNLOCK_SCRIPT.setLocation(<span class="keyword">new</span> <span class="title class_">ClassPathResource</span>(<span class="string">&quot;unlock.lua&quot;</span>));</span><br><span class="line">        UNLOCK_SCRIPT.setResultType(Long.class);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">SimpleRedisLock</span><span class="params">(String name, StringRedisTemplate stringRedisTemplate)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.name = name;</span><br><span class="line">        <span class="built_in">this</span>.stringRedisTemplate = stringRedisTemplate;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="type">boolean</span> <span class="title function_">tryLock</span><span class="params">(<span class="type">long</span> timeoutSec)</span> &#123;</span><br><span class="line">        <span class="comment">//获取线程标识</span></span><br><span class="line">        <span class="type">String</span> <span class="variable">threadId</span> <span class="operator">=</span> ID_PREFIX + Thread.currentThread().getId();</span><br><span class="line">        <span class="comment">//获取锁，使用SETNX方法进行加锁，同时设置过期时间，防止死锁</span></span><br><span class="line">        <span class="type">Boolean</span> <span class="variable">success</span> <span class="operator">=</span> stringRedisTemplate.opsForValue().setIfAbsent(KEY_PREFIX + name, threadId, timeoutSec, TimeUnit.SECONDS);</span><br><span class="line">        <span class="comment">//自动拆箱可能会出现null，这样写更稳妥</span></span><br><span class="line">        <span class="keyword">return</span> Boolean.TRUE.equals(success);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">unlock</span><span class="params">()</span> &#123;</span><br><span class="line">        stringRedisTemplate.execute(UNLOCK_SCRIPT,</span><br><span class="line">                Collections.singletonList(KEY_PREFIX + name),</span><br><span class="line">                ID_PREFIX + Thread.currentThread().getId());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ol start="2">
<li>lua脚本</li>
</ol>
<figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 这里的KEYS[1]就是传入锁的key</span></span><br><span class="line"><span class="comment">-- 这里的ARGV[1]就是线程标识</span></span><br><span class="line"><span class="comment">-- 比较锁中的线程标识与线程标识是否一致</span></span><br><span class="line"><span class="keyword">if</span> (redis.call(<span class="string">&#x27;get&#x27;</span>, KEYS[<span class="number">1</span>]) == ARGV[<span class="number">1</span>]) <span class="keyword">then</span></span><br><span class="line">    <span class="comment">-- 一致则释放锁</span></span><br><span class="line">    <span class="keyword">return</span> redis.call(<span class="string">&#x27;del&#x27;</span>, KEYS[<span class="number">1</span>])</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="keyword">return</span> <span class="number">0</span></span><br></pre></td></tr></table></figure>

<ol start="3">
<li>使用锁</li>
</ol>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">SimpleRedisLock</span> <span class="variable">lock</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">SimpleRedisLock</span>(<span class="string">&quot;order:&quot;</span> + userId, stringRedisTemplate);</span><br><span class="line">        <span class="comment">//获取锁对象</span></span><br><span class="line">        <span class="type">boolean</span> <span class="variable">isLock</span> <span class="operator">=</span> lock.tryLock(<span class="number">1200</span>);</span><br><span class="line">        <span class="comment">//加锁失败</span></span><br><span class="line">        <span class="keyword">if</span> (!isLock) &#123;</span><br><span class="line">            <span class="keyword">return</span> Result.fail(<span class="string">&quot;不允许重复下单&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="comment">//获取代理对象(事务)</span></span><br><span class="line">            <span class="type">IVoucherOrderService</span> <span class="variable">proxy</span> <span class="operator">=</span> (IVoucherOrderService) AopContext.currentProxy();</span><br><span class="line">            <span class="keyword">return</span> proxy.createVoucherOrder(voucherId);</span><br><span class="line">        &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">            <span class="comment">//释放锁</span></span><br><span class="line">            lock.unlock();</span><br><span class="line">        &#125;</span><br></pre></td></tr></table></figure>



<h3 id="Redisson"><a href="#Redisson" class="headerlink" title="Redisson"></a>Redisson</h3><blockquote>
<p>上面实现的分布式锁存在不可重入，不可重试的问题，将使用redisson提供的框架来实现</p>
</blockquote>
<p>解释：</p>
<p>上面实现的分布式锁是采用key-value形式的锁，在判断key相同之后则会直接认为这把锁已经被占用了，所以获取锁失败，但是redisson使用的是hash类型的数据结构，在看到锁已经存在后，不是直接认定获取锁失败，而是判断锁的标识是否是自己，如果是则value加一，代表重入次数加一，最后要删除锁也是要等到value为0，即程序运行到最外层的时候才能释放。</p>
<p><img src="/../assets/Redis%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86/image-20230819144801293.png" alt="Redisson可重入锁原理"></p>
<p><img src="/../assets/Redis%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86/image-20230819160739146.png" alt="image-20230819160739146"></p>
<p><strong>重点：</strong></p>
<blockquote>
<p>使用lua脚本，等待重试，看门狗机制（用来续期锁）</p>
</blockquote>
<h2 id="关注推送"><a href="#关注推送" class="headerlink" title="关注推送"></a>关注推送</h2><p>使用推模式</p>
<p><img src="/../assets/Redis%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86/image-20230821152151166.png" alt="image-20230821152151166"></p>
<p>滚动分页查询</p>
<p>zset</p>
<h1 id="事务"><a href="#事务" class="headerlink" title="事务"></a>事务</h1><h2 id="定义-3"><a href="#定义-3" class="headerlink" title="定义"></a>定义</h2><p>Redis事务是一个单独的隔离操作：事务中的所有命令都会序列化、按顺序地执行。事务在执行的过程中，不会被其他客户端发送来的命令请求所打断。</p>
<p>Redis事务的主要作用就是<strong>串联多个命令</strong>防止别的命令插队。</p>
<h2 id="Multi、Exec、discard"><a href="#Multi、Exec、discard" class="headerlink" title="Multi、Exec、discard"></a>Multi、Exec、discard</h2><p>从输入Multi命令开始，输入的命令都会依次进入命令队列中，但不会执行，直到输入Exec后，Redis会将之前的命令队列中的命令依次执行。</p>
<p>组队的过程中可以通过discard来放弃组队。</p>
<p><img src="/../assets/Redis%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86/image-20231024153825141.png" alt="image-20231024153825141"></p>
<h2 id="事务的错误处理"><a href="#事务的错误处理" class="headerlink" title="事务的错误处理"></a>事务的错误处理</h2><ol>
<li>组队中某个命令出现了报告错误，执行时整个的所有队列都会被取消。</li>
</ol>
<p><img src="/../assets/Redis%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86/image-20231024154026128.png" alt="image-20231024154026128"></p>
<ol start="2">
<li>如果执行阶段某个命令报出了错误，则只有报错的命令不会被执行，而其他的命令都会执行，不会回滚。</li>
</ol>
<p><img src="/../assets/Redis%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86/image-20231024154101032.png" alt="image-20231024154101032"></p>
<h2 id="watch"><a href="#watch" class="headerlink" title="watch"></a>watch</h2><p>使用<code>WATCH</code>命令是一种<strong>手动实现乐观锁</strong>的方式，可以在多个事务之间防止竞态条件和数据不一致。如果不去使用<code>WATCH</code>，Redis<strong>默认不会自动</strong>阻止多个事务之间的冲突。</p>
<h2 id="Redis事务三特性"><a href="#Redis事务三特性" class="headerlink" title="Redis事务三特性"></a>Redis事务三特性</h2><ol>
<li><p>单独的隔离操作 </p>
<ul>
<li>事务中的所有命令都会序列化、按顺序地执行。事务在执行的过程中，不会被其他客户端发送来的命令请求所打断。</li>
</ul>
</li>
<li><p>没有隔离级别的概念 </p>
<ul>
<li>队列中的命令没有提交之前都不会实际被执行，因为事务提交前任何指令都不会被实际执行，因为Redis的事务是单机的，没有并发读写的问题</li>
</ul>
</li>
<li><p>不保证原子性 </p>
<ul>
<li>事务中如果有一条命令执行失败，其后的命令仍然会被执行，没有回滚</li>
</ul>
</li>
</ol>
<h1 id="持久化篇"><a href="#持久化篇" class="headerlink" title="持久化篇"></a>持久化篇</h1><h2 id="AOF"><a href="#AOF" class="headerlink" title="AOF"></a>AOF</h2><h3 id="AOF日志"><a href="#AOF日志" class="headerlink" title="AOF日志"></a>AOF日志</h3><p>Redis 每执行一条写操作命令，就<strong>把该命令以追加的方式写入到一个文件里</strong>，然后重启 Redis 的时候，先去读取这个文件里的命令，并且执行它，这就相当于恢复了缓存数据。</p>
<blockquote>
<p>注意只会记录写操作命令，读操作命令是不会被记录的，因为没意义</p>
</blockquote>
<p><img src="/../assets/Redis%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86/image-20231030203646649.png" alt="image-20231030203646649"></p>
<p>Redis 是<mark>先执行写操作命令后，才将该命令记录到 AOF 日志</mark>里的，这么做其实有两个好处。</p>
<ol>
<li>避免额外的检查开销</li>
</ol>
<p>因为如果先将写操作命令记录到 AOF 日志里，再执行该命令的话，如果当前的命令语法有问题，那么如果不进行命令语法检查，该错误的命令记录到 AOF 日志里后，Redis 在使用日志恢复数据时，就可能会出错。</p>
<p>而如果先执行写操作命令再记录日志的话，只有在该命令执行成功后，才将命令记录到 AOF 日志里，这样就不用额外的检查开销，保证记录在 AOF 日志里的命令都是可执行并且正确的。</p>
<ol start="2">
<li>不会阻塞当前写操作命令的执行</li>
</ol>
<p>因为当写操作命令执行成功后，才会将命令记录到 AOF 日志。</p>
<p>AOF的两种潜在风险</p>
<ol>
<li><p>执行写操作命令和记录日志是两个过程，那当 Redis 在还没来得及将命令写入到硬盘时，服务器发生宕机了，这个数据就会有<mark>丢失的风险</mark>。</p>
</li>
<li><p>由于写操作命令执行成功后才记录到 AOF 日志，所以不会阻塞当前写操作命令的执行，但是<mark>可能会给「下一个」命令带来阻塞风险</mark>。</p>
</li>
</ol>
<p>因为将命令写入到日志的这个操作也是在主进程完成的（执行命令也是在主进程），也就是说这两个操作是同步的。</p>
<p><img src="/../assets/Redis%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86/image-20231030205624444.png" alt="image-20231030205624444"></p>
<p>认真分析一下，其实这两个风险都有一个共性，都跟「 AOF 日志写回硬盘的时机」有关。</p>
<h3 id="三种写回策略"><a href="#三种写回策略" class="headerlink" title="三种写回策略"></a>三种写回策略</h3><p>Redis 写入 AOF 日志的过程，如下图：</p>
<p><img src="/../assets/Redis%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86/image-20231030211449584.png" alt="image-20231030211449584"></p>
<p>具体流程：</p>
<ol>
<li>Redis 执行完写操作命令后，会将命令追加到 <code>server.aof_buf</code> 缓冲区；</li>
<li>然后通过 write() 系统调用，将 aof_buf 缓冲区的数据写入到 AOF 文件，此时数据并没有写入到硬盘，而是拷贝到了内核缓冲区 page cache，等待内核将数据写入硬盘；</li>
<li>具体内核缓冲区的数据什么时候写入到硬盘，由内核决定。</li>
</ol>
<p>Redis 提供了 3 种写回硬盘的策略，控制的就是上面说的第三步的过程。</p>
<ul>
<li><strong>Always</strong>，这个单词的意思是「总是」，所以它的意思是每次写操作命令执行完后，<mark>同步</mark>将 AOF 日志数据写回硬盘；</li>
<li><strong>Everysec</strong>，这个单词的意思是「每秒」，所以它的意思是每次写操作命令执行完后，先将命令写入到 AOF 文件的内核缓冲区，然后<mark>每隔一秒将缓冲区里的内容写回到硬盘</mark>；</li>
<li><strong>No</strong>，意味着不由 Redis 控制写回硬盘的时机，转交给操作系统控制写回的时机，也就是每次写操作命令执行完后，先将命令写入到 AOF 文件的内核缓冲区，再由<mark>操作系统决定</mark>何时将缓冲区内容写回硬盘。</li>
</ul>
<p>这 3 种写回策略都无法能完美解决「主进程阻塞」和「减少数据丢失」的问题，因为两个问题是<mark>对立</mark>的，偏向于一边的话，就会要牺牲另外一边，原因如下：</p>
<ul>
<li>Always 策略的话，可以最大程度保证数据不丢失，但是由于它每执行一条写操作命令就同步将 AOF 内容写回硬盘，所以是不可避免会影响主进程的性能；</li>
<li>No 策略的话，是交由操作系统来决定何时将 AOF 日志内容写回硬盘，相比于 Always 策略性能较好，但是操作系统写回硬盘的时机是不可预知的，如果 AOF 日志内容没有写回硬盘，一旦服务器宕机，就会丢失不定数量的数据。</li>
<li>Everysec 策略的话，是折中的一种方式，避免了 Always 策略的性能开销，也比 No 策略更能避免数据丢失，当然如果上一秒的写操作命令日志没有写回到硬盘，发生了宕机，这一秒内的数据自然也会丢失。</li>
</ul>
<p>大家根据自己的业务场景进行选择：</p>
<ul>
<li>如果要高性能，就选择 No 策略；</li>
<li>如果要高可靠，就选择 Always 策略；</li>
<li>如果允许数据丢失一点，但又想性能高，就选择 Everysec 策略。</li>
</ul>
<p><img src="/../assets/Redis%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86/image-20231030211756839.png" alt="image-20231030211756839"></p>
<p>深入到源码后，就会发现这三种策略只是在控制 <code>fsync()</code> 函数的调用时机。</p>
<p>当应用程序向文件写入数据时，内核通常先将数据复制到内核缓冲区中，然后排入队列，然后由内核决定何时写入硬盘。</p>
<p><img src="/../assets/Redis%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86/image-20231030211900137.png" alt="image-20231030211900137"></p>
<p>如果想要应用程序向文件写入数据后，能立马将数据同步到硬盘，就可以调用 <code>fsync()</code> 函数，这样内核就会将内核缓冲区的数据直接写入到硬盘，等到硬盘写操作完成后，该函数才会返回。</p>
<ul>
<li>Always 策略就是每次写入 AOF 文件数据后，就执行 fsync() 函数；</li>
<li>Everysec 策略就会创建一个异步任务来执行 fsync() 函数；</li>
<li>No 策略就是永不执行 fsync() 函数；</li>
</ul>
<h3 id="AOF重写机制"><a href="#AOF重写机制" class="headerlink" title="AOF重写机制"></a>AOF重写机制</h3><p>当 AOF 文件的大小超过所设定的阈值后，Redis 就会启用 AOF 重写机制，来压缩 AOF 文件。</p>
<p>AOF 重写机制是在重写时，读取当前数据库中的所有键值对，然后将每一个键值对用一条命令记录到「新的 AOF 文件」，等到全部记录完后，就将新的 AOF 文件替换掉现有的 AOF 文件。</p>
<p>重写机制的<mark>妙处</mark>在于，尽管某个键值对被多条写命令反复修改，<strong>最终也只需要根据这个「键值对」当前的最新状态，然后用一条命令去记录键值对</strong>，代替之前记录这个键值对的多条命令，这样就减少了 AOF 文件中的命令数量。最后在重写工作完成后，将新的 AOF 文件覆盖现有的 AOF 文件。</p>
<blockquote>
<p>为什么重写 AOF 的时候，不直接复用现有的 AOF 文件？</p>
</blockquote>
<p>因为<strong>如果 AOF 重写过程中失败了，现有的 AOF 文件就会造成污染</strong>，可能无法用于恢复使用。</p>
<p>所以 AOF 重写过程，先重写到新的 AOF 文件，重写失败的话，就直接删除这个文件就好，不会对现有的 AOF 文件造成影响。</p>
<h3 id="⭐⭐⭐AOF后台重写"><a href="#⭐⭐⭐AOF后台重写" class="headerlink" title="⭐⭐⭐AOF后台重写"></a>⭐⭐⭐AOF后台重写</h3><p>AOF重写过程其实是很耗时的，所以重写的操作不能放在主进程里。</p>
<p>所以，Redis 的<strong>重写 AOF 过程是由后台子进程 bgrewriteaof来完成的</strong>，这么做可以达到两个好处：</p>
<ul>
<li>子进程进行 AOF 重写期间，主进程可以继续处理命令请求，从而避免阻塞主进程；</li>
<li>子进程带有主进程的数据副本，这里使用子进程而不是线程，因为如果是使用线程，多线程之间会共享内存，那么在修改共享内存数据的时候，需要通过加锁来保证数据的安全，而这样就会降低性能。而使用子进程，创建子进程时，父子进程是共享内存数据的，不过这个共享的内存只能以只读的方式，而当父子进程任意一方修改了该共享内存，就会发生「写时复制」，于是父子进程就有了独立的数据副本，就不用加锁来保证数据安全。</li>
</ul>
<p>子进程是怎么拥有主进程一样的数据副本的呢？</p>
<p>Redis主进程在通过 <code>fork</code> 系统调用生成 bgrewriteaof 子进程时，操作系统会把主进程的「<strong>页表</strong>」复制一份给子进程，这个<strong>页表记录着<mark>虚拟地址和物理地址映射关系</mark>，而不会复制物理内存，也就是说，两者的虚拟空间不同，但其对应的物理空间是同一个</strong>。</p>
<p><img src="/../assets/Redis%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86/5a1f2a90b5f3821c19bea3b7a5f27fa1.png" alt="img"></p>
<p>这样一来，子进程就共享了父进程的物理内存数据了，这样能够<strong>节约物理内存资源</strong>，页表对应的页表项的属性会标记该物理内存的权限为<strong>只读</strong>。</p>
<p>不过，当父进程或者子进程在向这个内存发起写操作时，CPU 就会触发<strong>写保护中断</strong>，这个写保护中断是由于违反权限导致的，然后操作系统会在「写保护中断处理函数」里进行<strong>物理内存的复制</strong>，并重新设置其内存映射关系，将父子进程的内存读写权限设置为<strong>可读写</strong>，最后才会对内存进行写操作，这个过程被称为「**写时复制(Copy On Write)**」。</p>
<p><img src="/../assets/Redis%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86/d4cfac545377b54dd035c775603b4936.png" alt="img"></p>
<p>写时复制顾名思义，<strong>在发生写操作的时候，操作系统才会去复制物理内存</strong>，这样是为了防止 fork 创建子进程时，由于物理内存数据的复制时间过长而导致父进程长时间阻塞的问题。</p>
<p>AOF后台重写阻塞情况：</p>
<ol>
<li>写时复制</li>
<li>信号处理函数</li>
<li>复制父进程的页表：创建子进程的途中，由于要复制父进程的页表等数据结构，阻塞的时间跟页表的大小有关，页表越大，阻塞的时间也越长，<strong>不过页表的大小相比实际的物理内存小很多，所以通常复制页表的过程是比较快的。</strong></li>
</ol>
<p>🔴🟡🟢<strong>重写期间，如果主进程修改了数据</strong>：</p>
<p>当在 Redis 中启用了写时复制技术，特别是在 AOF（Append Only File）重写期间，如果主进程修改了数据，整体流程如下：</p>
<ol>
<li><p><strong>主进程执行写操作</strong>：</p>
<ul>
<li>主进程收到客户端的写命令请求。</li>
<li>主进程执行命令并将命令追加到 AOF 缓冲区和 AOF 重写缓冲区。</li>
</ul>
</li>
<li><p><strong>执行 AOF 后台重写</strong>：</p>
<ul>
<li>在重写 AOF 期间，后台子进程（bgrewriteaof）负责扫描数据库并将数据库中的键值对转换为一条命令，然后将命令记录到新的 AOF 文件中。</li>
</ul>
</li>
<li><p><strong>主进程修改已存在的数据</strong>：</p>
<ul>
<li>如果主进程在 AOF 重写期间修改了已存在的数据，根据写时复制机制，<mark>只会复制发生了修改的物理内存数据，未修改的部分仍然与子进程共享</mark>。</li>
<li>修改的数据在主进程的物理内存中，但在子进程的内存数据中是不一致的。</li>
</ul>
</li>
<li><p><strong>AOF 重写子进程与主进程数据不一致问题</strong>：</p>
<ul>
<li>为了解决数据不一致的问题，Redis <mark>设置了 AOF 重写缓冲区</mark>，在创建 bgrewriteaof 子进程之后开始使用。</li>
<li>主进程执行的写命令会被同时追加到 AOF 缓冲区和 AOF 重写缓冲区。</li>
</ul>
</li>
<li><p><strong>子进程完成 AOF 重写</strong>：</p>
<ul>
<li>子进程完成 AOF 重写后，向主进程发送信号。</li>
<li>主进程接收信号后，调用信号处理函数，<mark>将 AOF 重写缓冲区的内容追加到新 AOF 文件中</mark>，使得新旧 AOF 文件保存的数据库状态一致。</li>
</ul>
</li>
</ol>
<p>在这整个流程中，写时复制技术确保了只有在主进程发生修改时才会对物理内存数据进行复制，减少不必要的复制，同时 AOF 重写缓冲区帮助解决了主进程与子进程数据不一致的问题，保障了 AOF 文件的一致性。</p>
<h2 id="RDB"><a href="#RDB" class="headerlink" title="RDB"></a>RDB</h2><p>RDB 快照就是记录某一个瞬间的内存数据，记录的是实际数据，而 AOF 文件记录的是命令操作的日志，而不是实际的数据。</p>
<p>因此在 Redis 恢复数据时， RDB 恢复数据的效率会比 AOF 高些，因为直接将 RDB 文件读入内存就可以，不需要像 AOF 那样还需要额外执行操作命令的步骤才能恢复数据。</p>
<h3 id="快照怎么用？"><a href="#快照怎么用？" class="headerlink" title="快照怎么用？"></a>快照怎么用？</h3><p>Redis 提供了两个命令来生成 RDB 文件，分别是 <code>save</code> 和 <code>bgsave</code>，他们的区别就在于是否在「主线程」里执行：</p>
<ul>
<li>执行了 save 命令，就会在主线程生成 RDB 文件，由于和执行操作命令在同一个线程，所以如果写入 RDB 文件的时间太长，<strong>会阻塞主线程</strong>；</li>
<li>执行了 bgsave 命令，会创建一个子进程来生成 RDB 文件，这样可以<strong>避免主线程的阻塞</strong>；</li>
</ul>
<p>Redis 的快照是<strong>全量快照</strong>，也就是说每次执行快照，都是把内存中的「所有数据」都记录到磁盘中。</p>
<p>所以可以认为，执行快照是一个比较重的操作，如果频率太频繁，可能会对 Redis 性能产生影响。如果频率太低，服务器故障时，丢失的数据会更多。</p>
<p>通常可能设置至少 5 分钟才保存一次快照，这时如果 Redis 出现宕机等情况，则意味着最多可能丢失 5 分钟数据。</p>
<p>这就是 RDB 快照的缺点，在服务器发生故障时，丢失的数据会比 AOF 持久化的方式更多，因为 RDB 快照是全量快照的方式，因此执行的频率不能太频繁，否则会影响 Redis 性能，而 AOF 日志可以以秒级的方式记录操作命令，所以丢失的数据就相对更少。</p>
<h3 id="⭐⭐⭐执行快照时，数据能被修改吗？"><a href="#⭐⭐⭐执行快照时，数据能被修改吗？" class="headerlink" title="⭐⭐⭐执行快照时，数据能被修改吗？"></a>⭐⭐⭐执行快照时，数据能被修改吗？</h3><p>执行 bgsave 过程中，Redis 依然<strong>可以继续处理操作命令</strong>的，也就是数据是能被修改的。</p>
<p>技术依然是使用的写时复制技术，但是并不会像AOF那样还建立一个重写缓冲区，最后再通过信号函数重新追加命令到新的AOF文件中。</p>
<p>因为通过写时复制技术后，主进程和子进程所对应的那一块数据的内存区域就不一样了，所以子进程所记录的RDB文件中是<mark>不包含记录过程中新加入或修改的新数据的</mark>。</p>
<h3 id="RDB-和-AOF-合体"><a href="#RDB-和-AOF-合体" class="headerlink" title="RDB 和 AOF 合体"></a>RDB 和 AOF 合体</h3><p>尽管 RDB 比 AOF 的数据恢复速度快，但是快照的频率不好把握：</p>
<ul>
<li>如果频率太低，两次快照间一旦服务器发生宕机，就可能会比较多的数据丢失；</li>
<li>如果频率太高，频繁写入磁盘和创建子进程会带来额外的性能开销。</li>
</ul>
<p>那有没有什么方法不仅有 RDB 恢复速度快的优点和，又有 AOF 丢失数据少的优点呢？</p>
<p>当然有，那就是将 RDB 和 AOF 合体使用，这个方法是在 Redis 4.0 提出的，该方法叫<strong>混合使用 AOF 日志和内存快照</strong>，也叫混合持久化。</p>
<p>当开启了混合持久化时，在 <mark>AOF 重写日志时</mark>，<code>fork</code> 出来的重写子进程会先将与主线程共享的内存数据以 RDB 方式写入到 AOF 文件，然后主线程处理的操作命令会被记录在<mark>重写缓冲区</mark>里，重写缓冲区里的增量命令会以 AOF 方式写入到 AOF 文件，写入完成后通知主进程将新的含有 RDB 格式和 AOF 格式的 AOF 文件替换旧的的 AOF 文件。</p>
<p>也就是说，使用了混合持久化，AOF 文件的<strong>前半部分是 RDB 格式的全量数据，后半部分是 AOF 格式的增量数据</strong>。</p>
<p><img src="/../assets/Redis%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86/image-20231030213846575.png" alt="image-20231030213846575"></p>
<p>这样的好处在于，重启 Redis 加载数据的时候，由于前半部分是 RDB 内容，这样<strong>加载的时候速度会很快</strong>。</p>
<p>加载完 RDB 的内容后，才会加载后半部分的 AOF 内容，这里的内容是 Redis 后台子进程重写 AOF 期间，主线程处理的操作命令，可以使得<strong>数据更少的丢失</strong>。</p>
<h2 id="Redis-大-Key-对持久化有什么影响？"><a href="#Redis-大-Key-对持久化有什么影响？" class="headerlink" title="Redis 大 Key 对持久化有什么影响？"></a>Redis 大 Key 对持久化有什么影响？</h2><h3 id="大-Key-对-AOF-日志的影响"><a href="#大-Key-对-AOF-日志的影响" class="headerlink" title="大 Key 对 AOF 日志的影响"></a>大 Key 对 AOF 日志的影响</h3><p>当使用 <strong>Always</strong> 策略的时候，如果写入是一个大 Key，主线程在执行 fsync() 函数的时候，<mark>阻塞的时间会比较久</mark>，因为当写入的数据量很大的时候，数据同步到硬盘这个过程是很耗时的。</p>
<p>当使用 <strong>Everysec</strong> 策略的时候，由于是异步执行 fsync() 函数，所以大 Key 持久化的过程（数据同步磁盘）<mark>不会影响主线程</mark>。</p>
<p>当使用 <strong>No</strong> 策略的时候，由于永不执行 fsync() 函数，所以大 Key 持久化的过程不会影响主线程。</p>
<h3 id="大-Key-对-AOF-重写和-RDB-的影响"><a href="#大-Key-对-AOF-重写和-RDB-的影响" class="headerlink" title="大 Key 对 AOF 重写和 RDB 的影响"></a>大 Key 对 AOF 重写和 RDB 的影响</h3><ol>
<li>复制页表期间：</li>
</ol>
<p>随着 Redis 存在越来越多的大 Key，那么 Redis 就会占用很多内存，对应的页表就会越大。</p>
<p>Redis主进程在通过 <code>fork()</code> 函数创建子进程的时候，虽然不会复制父进程的物理内存，但是<strong>内核会把父进程的页表复制一份给子进程，如果页表很大，那么这个复制过程是会很耗时的，那么在执行 fork 函数的时候就会发生阻塞现象</strong>。</p>
<ol start="2">
<li>写时复制期间：</li>
</ol>
<p>如果创建完子进程后，<strong>父进程对共享内存中的大 Key 进行了修改，那么内核就会发生写时复制，会把物理内存复制一份，由于大 Key 占用的物理内存是比较大的，那么在复制物理内存这一过程中，也是比较耗时的，于是父进程（主线程）就会发生阻塞</strong>。</p>
<h1 id="高可用篇✏️"><a href="#高可用篇✏️" class="headerlink" title="高可用篇✏️"></a>高可用篇✏️</h1><h2 id="主从复制"><a href="#主从复制" class="headerlink" title="主从复制"></a>主从复制</h2><p>主服务器写，从服务器读，在从机上写数据会报错</p>
<p><img src="/../assets/Redis%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86/image-20231031212316265.png" alt="主从复制图"></p>
<h3 id="复制原理"><a href="#复制原理" class="headerlink" title="复制原理"></a>复制原理</h3><ol>
<li>当从服务器连接上主服务器之后，从服务器向主服务发送进行数据同步消息</li>
<li>主服务器接到从服务器发送过来同步消息，把主服务器数据进行持久化<code>rdb</code>文件，把<code>rdb</code>文件发送从服务器，从服务器拿到<code>rdb</code>文件进行读取</li>
</ol>
<blockquote>
<p>🌈补充：</p>
<p><strong>主服务器在下面这三个时间间隙中将收到的写操作命令，写入到 replication buffer 缓冲区里</strong>：</p>
<ul>
<li>主服务器生成 RDB 文件期间；</li>
<li>主服务器发送 RDB 文件给从服务器期间；</li>
<li>「从服务器」加载 RDB 文件期间；</li>
</ul>
<p>当完成 RDB 的载入后，主服务器将 replication buffer 缓冲区里所记录的写操作命令发送给从服务器，从服务器执行来自主服务器 replication buffer 缓冲区里发来的命令，这时主从服务器的数据就一致了。</p>
<p>至此，主从服务器的<mark>第一次同步</mark>的工作就完成了。</p>
</blockquote>
<ol start="3">
<li>每次主服务器进行写操作之后，和从服务器进行数据同步，<mark><strong>基于长连接的命令传播</strong></mark></li>
</ol>
<blockquote>
<p>🌈补充：</p>
<p>主从服务器完成第一次数据同步后，TCP网络连接会一直维持着，后续主服务器可以通过这个连接继续将写操作命令传播给从服务器，然后从服务器执行该命令，使得与主服务器的数据库状态相同。</p>
</blockquote>
<ol start="4">
<li>当发生网络波动问题导致基于长连接的命令传播断开时：</li>
</ol>
<p>在 Redis 2.8 之前，如果主从服务器在命令同步时出现了网络断开又恢复的情况，从服务器就会和主服务器重新进行一次全量复制，很明显这样的开销太大了，必须要改进一波。</p>
<p>所以，从 Redis 2.8 开始，网络断开又恢复后，从主从服务器会采用<mark><strong>增量复制</strong></mark>的方式继续同步，也就是只会把网络断开期间主服务器接收到的写操作命令，同步给从服务器。</p>
<p><strong>主服务器怎么知道要将哪些增量数据发送给从服务器呢？</strong></p>
<p>答案藏在这两个东西里：</p>
<ul>
<li><strong>repl_backlog_buffer</strong>，是一个「<strong>环形</strong>」缓冲区，用于主从服务器断连后，从中找到差异的数据；</li>
<li><strong>replication offset</strong>，标记上面那个缓冲区的同步进度，主从服务器都有各自的<mark>偏移量</mark>，主服务器使用 master_repl_offset 来记录自己「<em>写</em>」到的位置，从服务器使用 slave_repl_offset 来记录自己「<em>读</em>」到的位置。</li>
</ul>
<p>那 repl_backlog_buffer 缓冲区是什么时候写入的呢？</p>
<p>在主服务器进行命令传播时，不仅会将写命令发送给从服务器，还会将写命令写入到 repl_backlog_buffer 缓冲区里，因此 这个缓冲区里会保存着最近传播的写命令。</p>
<p>网络断开后，当从服务器重新连上主服务器时，从服务器会通过 psync 命令将自己的复制偏移量 slave_repl_offset 发送给主服务器，主服务器根据自己的 master_repl_offset 和 slave_repl_offset 之间的差距，然后来决定对从服务器执行哪种同步操作：</p>
<ul>
<li>如果判断出从服务器要读取的数据还在 repl_backlog_buffer 缓冲区里，那么主服务器将采用<strong>增量同步</strong>的方式；</li>
<li>相反，如果判断出从服务器要读取的数据已经不存在 repl_backlog_buffer 缓冲区里，那么主服务器将采用<strong>全量同步</strong>的方式。</li>
</ul>
<p>当主服务器在 repl_backlog_buffer 中找到主从服务器差异（增量）的数据后，就会将增量的数据写入到 replication buffer 缓冲区，这个缓冲区我们前面也提到过，它是缓存将要传播给从服务器的命令。</p>
<p><img src="/../assets/Redis%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86/2db4831516b9a8b79f833cf0593c1f12.png" alt="图片"></p>
<p>repl_backlog_buffer 缓行缓冲区的默认大小是 1M，并且由于它是一个<mark>环形缓冲区</mark>，所以当缓冲区写满后，主服务器继续写入的话，就会覆盖之前的数据。因此，<strong>当主服务器的写入速度远超于从服务器的读取速度，缓冲区的数据一下就会被覆盖。</strong></p>
<p>那么在网络恢复时，如果从服务器想读的数据已经被覆盖了，主服务器就会采用全量同步，这个方式比增量同步的性能损耗要大很多。</p>
<p>因此，<strong>为了避免在网络恢复时，主服务器频繁地使用全量同步的方式，我们应该调整下 repl_backlog_buffer 缓冲区大小，<mark>尽可能的大一些</strong></mark>。</p>
<h3 id="复制延迟"><a href="#复制延迟" class="headerlink" title="复制延迟"></a>复制延迟</h3><p>由于所有的写操作都是先在Master上操作，然后同步更新到Slave上，所以从Master同步到Slave机器有一定的延迟，当系统很繁忙的时候，延迟问题会更加严重，Slave机器数量的增加也会使这个问题更加严重。</p>
<h3 id="一主二仆"><a href="#一主二仆" class="headerlink" title="一主二仆"></a>一主二仆</h3><p>当一台从服务器挂了之后，此时在这个期间主服务器写入数据，此时再将该挂掉了的从服务器重新启动，此时这台服务器已经不再是从服务器了，即与原来的主服务器失去了主从关系，它现在变成了一个独立的主服务器，再让该服务器去与原来的主服务器去建立联系，那么就会将主服务器的当前的所有内容（<mark>即包括在其挂掉的那期间的数据</mark>）全部复制到从服务器上。</p>
<p>当主服务器挂掉之后，剩下的从服务器不会发生改变，依然认为原来的主服务器是主服务器，并不会自己成为新的主服务器，等到原来的主服务器重启后，一切恢复正常。</p>
<h3 id="级联复制"><a href="#级联复制" class="headerlink" title="级联复制"></a>级联复制</h3><p>其实就是像个链表一样，将数据同步的方式由一台主服务器给多台服务器传达，转变为A-&gt;B-&gt;C这样的模式。</p>
<ul>
<li><p>优点：通过这种方式，<strong>主服务器生成 RDB 和传输 RDB 的<mark>压力</mark>可以<mark>分摊</mark>到充当经理角色的从服务器</strong>。</p>
</li>
<li><p><del>缺点：B作为C的主服务器，那么B服务器就可以进行写操作了，但B服务器却是A服务器的从服务器，B服务器如果写了数据那么A服务器是无法进行同步的，这就出现了数据的不同步问题。</del></p>
</li>
<li><p>一般不会出现B服务器主动写的操作，B服务器的写操作只是继承自A服务器的数据而去写到C服务器。</p>
</li>
</ul>
<p><img src="/../assets/Redis%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86/image-20231031222351693.png" alt="薪火相传"></p>
<h3 id="小林coding面试题-1"><a href="#小林coding面试题-1" class="headerlink" title="小林coding面试题"></a>小林coding面试题</h3><ol>
<li>Redis主从节点时长连接还是短连接？</li>
</ol>
<blockquote>
<p>长连接</p>
</blockquote>
<ol start="2">
<li>怎么判断 Redis 某个节点是否正常工作？</li>
</ol>
<blockquote>
<p>Redis 判断节点是否正常工作，基本都是通过互相的 ping-pong <mark>心态检测机制</mark>，如果<mark>有一半以上的节点去 ping 一个节点的时候没有 pong 回应</mark>，集群就会认为这个节点挂掉了，会断开与这个节点的连接。</p>
</blockquote>
<ol start="3">
<li>主从复制架构中，过期key如何处理？</li>
</ol>
<blockquote>
<p>主节点处理了一个key或者通过淘汰算法淘汰了一个key，这个时间<mark>主节点模拟一条del命令发送给从节点</mark>，从节点收到该命令后，就进行删除key的操作。</p>
</blockquote>
<ol start="4">
<li>Redis 是同步复制还是异步复制？</li>
</ol>
<blockquote>
<p>Redis 主节点每次收到写命令之后，先写到内部的缓冲区，然后异步发送给从节点。</p>
</blockquote>
<ol start="5">
<li>主从复制中两个 Buffer(replication buffer 、repl backlog buffer)有什么区别？</li>
</ol>
<blockquote>
<p>replication buffer 、repl backlog buffer 区别如下：</p>
<ul>
<li>出现的阶段不一样：</li>
<li>repl backlog buffer 是在增量复制阶段出现，<strong>一个主节点只分配一个 repl backlog buffer</strong>；</li>
<li>replication buffer 是在全量复制阶段和增量复制阶段都会出现，<strong>主节点会给每个新连接的从节点，分配一个 replication buffer</strong>；</li>
<li>这两个 Buffer 都有大小限制的，当缓冲区满了之后，发生的事情不一样：</li>
<li>当 repl backlog buffer 满了，因为是环形结构，会直接<strong>覆盖起始位置数据</strong>;</li>
<li>当 replication buffer 满了，会导致连接断开，删除缓存，从节点重新连接，<strong>重新开始全量复制</strong>。</li>
</ul>
</blockquote>
<ol start="6">
<li>如何应对主从数据不一致？</li>
</ol>
<blockquote>
<p><strong>主从节点间的命令复制是异步进行的</strong>，所以无法实现强一致性保证（主从数据时时刻刻保持一致）。</p>
<p>第一种方法，尽量保证主从节点间的网络连接状况良好，避免主从节点在不同的机房。</p>
<p>第二种方法，可以开发一个外部程序来监控主从节点间的复制进度。如果监控到某个从节点总是很大程度上的，很长时间段的不一致，可以让客户端不再和这个从节点连接进行数据读取，这样就可以减少读到不一致数据的情况。</p>
</blockquote>
<ol start="7">
<li>主从切换如何减少数据丢失？</li>
</ol>
<blockquote>
<p>主从切换过程中，产生数据丢失的情况有两种：</p>
<ul>
<li>异步复制同步丢失</li>
<li>集群产生脑裂数据丢失</li>
</ul>
<p>我们不可能保证数据完全不丢失，只能做到使得尽量少的数据丢失。</p>
<p>待补充。。。。。</p>
</blockquote>
<ol start="8">
<li>主从如何做到故障自动切换？</li>
</ol>
<blockquote>
<p>Redis 哨兵机制可以实现：哨兵在发现主节点出现故障时，由哨兵自动完成故障发现和故障转移，并通知给应用方，从而实现高可用性。</p>
</blockquote>
<h2 id="哨兵模式"><a href="#哨兵模式" class="headerlink" title="哨兵模式"></a>哨兵模式</h2><p>🔴🟡🟢一句话总结：</p>
<blockquote>
<p>能够自动后台监控主机是否故障，如果故障了根据投票数自动将从库转换为主库。当从服务器切换为新的主服务器后，原来的主服务器就变成了其的从服务器。</p>
</blockquote>
<p><img src="/../assets/Redis%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86/image-20231101101453322.png" alt="哨兵模式"></p>
<p>哨兵节点主要负责三件事情：<strong>监控、选主、通知</strong>。</p>
<h3 id="如何判断主节点真的故障了？"><a href="#如何判断主节点真的故障了？" class="headerlink" title="如何判断主节点真的故障了？"></a>如何判断主节点真的故障了？</h3><p>哨兵会每隔 1 秒给所有主从节点发送 PING 命令，当主从节点收到 PING 命令后，会发送一个响应命令给哨兵，这样就可以判断它们是否在正常运行。</p>
<p>如果主节点或者从节点没有在规定的时间内响应哨兵的 PING 命令，哨兵就会将它们标记为「<strong>主观下线</strong>」。</p>
<p><mark>客观下线只适用于主节点。</mark></p>
<p>之所以针对「主节点」设计「主观下线」和「客观下线」两个状态，是因为有可能「主节点」其实并没有故障，可能只是因为主节点的系统压力比较大或者网络发送了拥塞，导致主节点没有在规定时间内响应哨兵的 PING 命令。</p>
<p>所以，为了减少误判的情况，哨兵在部署的时候不会只部署一个节点，而是用多个节点部署成<strong>哨兵集群</strong>（<em>最少需要三台机器来部署哨兵集群</em>），<strong>通过多个哨兵节点一起判断，就可以就可以<mark>避免单个哨兵因为自身网络状况不好，而误判</mark>主节点下线的情况</strong>。同时，多个哨兵的网络同时不稳定的概率较小，由它们一起做决策，误判率也能降低。</p>
<p>具体是怎么判定主节点为「客观下线」的呢？</p>
<p>当一个哨兵判断主节点为「主观下线」后，就会向其他哨兵发起命令，其他哨兵收到这个命令后，就会根据自身和主节点的网络状况，做出赞成投票或者拒绝投票的响应。</p>
<p><img src="/../assets/Redis%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86/13e4361407ba46979e802eaa654dcf67.png" alt="img"></p>
<p>当这个哨兵的赞同票数达到哨兵配置文件中的 quorum 配置项设定的值后，这时主节点就会被该哨兵标记为「客观下线」。</p>
<p>例如，现在有 3 个哨兵，quorum 配置的是 2，那么一个哨兵需要 2 张赞成票，就可以标记主节点为“客观下线”了。这 2 张赞成票包括哨兵自己的一张赞成票和另外两个哨兵的赞成票。</p>
<p>PS：quorum 的值一般设置为哨兵个数的二分之一加 1，例如 3 个哨兵就设置 2。</p>
<p>哨兵判断完主节点客观下线后，哨兵就要开始在多个「从节点」中，选出一个从节点来做新主节点。</p>
<p>🔴🟡🟢<strong>总结</strong>：</p>
<blockquote>
<p>其实就是通过哨兵集群，超过半数的哨兵节点认为主服务器故障，那么就认为其真的故障了。</p>
</blockquote>
<h3 id="由哪个哨兵进行主从故障转移？"><a href="#由哪个哨兵进行主从故障转移？" class="headerlink" title="由哪个哨兵进行主从故障转移？"></a>由哪个哨兵进行主从故障转移？</h3><p>哨兵是以哨兵集群的方式存在的，需要在哨兵集群中选出一个 leader，让 leader 来执行主从切换。</p>
<p>哪个哨兵节点判断主节点为「客观下线」，这个哨兵节点就是候选者，所谓的候选者就是想当 Leader 的哨兵。</p>
<p>那么在投票过程中，任何一个「候选者」，要<mark>满足两个条件</mark>：</p>
<ul>
<li>第一，拿到半数以上的赞成票；</li>
<li>第二，拿到的票数同时还需要大于等于哨兵配置文件中的 quorum 值。</li>
</ul>
<p>哨兵节点至少要有 3 个，而且是奇数，且quorum 的值建议设置为哨兵个数的二分之一加 1。</p>
<h3 id="主从故障转移的过程是怎样的？"><a href="#主从故障转移的过程是怎样的？" class="headerlink" title="主从故障转移的过程是怎样的？"></a>主从故障转移的过程是怎样的？</h3><ol>
<li>选出新主节点</li>
</ol>
<p><img src="/../assets/Redis%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86/image-20231101101607619.png" alt="执行流程图"></p>
<ul>
<li>优先级在redis.conf中默认：slave-priority 100，值越小优先级越高</li>
<li>偏移量是指获得原主机数据最全的</li>
<li>每个redis实例启动后都会随机生成一个40位的runid</li>
</ul>
<ol start="2">
<li>从节点指向新主节点</li>
</ol>
<p>当新主节点出现之后，哨兵 leader 下一步要做的就是，让已下线主节点属下的所有「从节点」指向「新主节点」</p>
<ol start="3">
<li>通知客户的主节点已更换</li>
</ol>
<p>通过 Redis 的发布者&#x2F;订阅者机制来实现</p>
<ol start="4">
<li>将旧主节点变为从节点</li>
</ol>
<p>故障转移操作最后要做的是，继续监视旧主节点，当旧主节点重新上线时，哨兵集群就会向它发送 <code>SLAVEOF</code> 命令，让它成为新主节点的从节点。</p>
<h3 id="哨兵集群是如何组成的？"><a href="#哨兵集群是如何组成的？" class="headerlink" title="哨兵集群是如何组成的？"></a>哨兵集群是如何组成的？</h3><p>在主从集群中，主节点上有一个名为<code>__sentinel__:hello</code>的频道，不同哨兵就是通过它来相互发现，实现互相通信的。</p>
<p>在下图中，哨兵 A 把自己的 IP 地址和端口的信息发布到<code>__sentinel__:hello</code> 频道上，哨兵 B 和 C 订阅了该频道。那么此时，哨兵 B 和 C 就可以从这个频道直接获取哨兵 A 的 IP 地址和端口号。然后，哨兵 B、C 可以和哨兵 A 建立网络连接。</p>
<p><img src="/../assets/Redis%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86/a6286053c6884cf58bf397d01674fe80.png" alt="img"></p>
<p>通过这个方式，哨兵 B 和 C 也可以建立网络连接，这样一来，哨兵集群就形成了。</p>
<blockquote>
<p>哨兵集群会对「从节点」的运行状态进行监控，那哨兵集群如何知道「从节点」的信息？</p>
</blockquote>
<p>主节点知道所有「从节点」的信息，<strong>所以哨兵会每 10 秒一次的频率向主节点发送 INFO 命令来获取所有「从节点」的信息。</strong></p>
<p>如下图所示，哨兵 B 给主节点发送 INFO 命令，主节点接受到这个命令后，就会把从节点列表返回给哨兵。接着，哨兵就可以根据从节点列表中的连接信息，和每个从节点建立连接，并在这个连接上持续地对从节点进行监控。哨兵 A 和 C 可以通过相同的方法和从节点建立连接。</p>
<p><img src="/../assets/Redis%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86/fdd5f695bb3643258662886f9fba0aab.png" alt="img"></p>
<p>正是通过 <mark>Redis 的发布者&#x2F;订阅者机制</mark>，哨兵之间可以相互感知，然后组成集群，同时，哨兵又通过 INFO 命令，在主节点里获得了所有从节点连接信息，于是就能和从节点建立连接，并进行监控了。</p>
<h2 id="集群"><a href="#集群" class="headerlink" title="集群"></a>集群</h2><p>待补充。。。。。。</p>
<h3 id="集群脑裂导致数据丢失怎么办？"><a href="#集群脑裂导致数据丢失怎么办？" class="headerlink" title="集群脑裂导致数据丢失怎么办？"></a>集群脑裂导致数据丢失怎么办？</h3><blockquote>
<p>什么是脑裂？</p>
</blockquote>
<p>先来理解集群的脑裂现象，这就好比一个人有两个大脑，那么到底受谁控制呢？</p>
<p>那么在 Redis 中，集群脑裂产生数据丢失的现象是怎样的呢？</p>
<p>在 Redis 主从架构中，部署方式一般是「一主多从」，主节点提供写操作，从节点提供读操作。 如果主节点的网络突然发生了问题，它与所有的从节点都失联了，但是此时的主节点和客户端的网络是正常的，这个客户端并不知道 Redis 内部已经出现了问题，还在照样的向这个失联的主节点写数据（过程A），此时这些数据被旧主节点缓存到了缓冲区里，因为主从节点之间的网络问题，这些数据都是无法同步给从节点的。</p>
<p>这时，哨兵也发现主节点失联了，它就认为主节点挂了（但实际上主节点正常运行，只是网络出问题了），于是哨兵就会在「从节点」中选举出一个 leader 作为主节点，这时集群就有两个主节点了 —— <strong>脑裂出现了</strong>。</p>
<p>然后，网络突然好了，哨兵因为之前已经选举出一个新主节点了，它就会把旧主节点降级为从节点（A），然后从节点（A）会向新主节点请求数据同步，<strong>因为第一次同步是全量同步的方式，此时的从节点（A）会清空掉自己本地的数据，然后再做全量同步。所以，之前客户端在过程 A 写入的数据就会丢失了，也就是集群产生脑裂数据丢失的问题</strong>。</p>
<blockquote>
<p>🔴🟢🟡总结一句话就是：由于网络问题，集群节点之间失去联系。主从数据不同步；重新平衡选举，产生两个主服务。等网络恢复，旧主节点会降级为从节点，再与新主节点进行同步复制的时候，由于会从节点会清空自己的缓冲区，所以导致之前客户端写入的数据丢失了。</p>
</blockquote>
<p>**解决方案:**其实都是<mark>限制</mark>主库不再接收客户端的写请求</p>
<h1 id="功能篇"><a href="#功能篇" class="headerlink" title="功能篇"></a>功能篇</h1><h2 id="过期删除策略"><a href="#过期删除策略" class="headerlink" title="过期删除策略"></a>过期删除策略</h2><h3 id="如何判定-key-已过期了？"><a href="#如何判定-key-已过期了？" class="headerlink" title="如何判定 key 已过期了？"></a>如何判定 key 已过期了？</h3><blockquote>
<p>🔴🟢🟡一句话总结：设置过期时间会将该key带上过期时间存入过期字典（哈希表），在里面根据key找不到就是没设置过期时间，找到了就与系统当前时间进行比较。</p>
</blockquote>
<p>每当我们对一个 key 设置了过期时间时，Redis 会把该 key 带上过期时间存储到一个<mark><strong>过期字典</strong></mark>（expires dict）中，也就是说「过期字典」保存了数据库中所有 key 的过期时间。</p>
<p>过期字典存储在 redisDb 结构中，如下：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">redisDb</span> &#123;</span></span><br><span class="line">    dict *dict;    <span class="comment">/* 数据库键空间，存放着所有的键值对 */</span></span><br><span class="line">    dict *expires; <span class="comment">/* 键的过期时间 */</span></span><br><span class="line">    ....</span><br><span class="line">&#125; redisDb;</span><br></pre></td></tr></table></figure>

<p>过期字典数据结构结构如下：</p>
<ul>
<li>过期字典的 <strong>key</strong> 是一个指针，指向某个键对象；</li>
<li>过期字典的 <strong>value</strong> 是一个 long long 类型的整数，这个整数保存了 key 的过期时间；</li>
</ul>
<p><img src="/../assets/Redis%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86/image-20231107084229499.png" alt="image-20231107084229499"></p>
<hr>
<p>字典实际上是<mark>哈希表</mark>，哈希表的最大好处就是让我们可以用 O(1) 的时间复杂度来快速查找。当我们查询一个 key 时，Redis 首先检查该 key 是否存在于过期字典中：</p>
<ul>
<li>如果不在，则正常读取键值；</li>
<li>如果存在，则会获取该 key 的过期时间，然后与当前系统时间进行比对，如果比系统时间大，那就没有过期，否则判定该 key 已过期。</li>
</ul>
<p><img src="/../assets/Redis%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86/image-20231106220549674.png" alt="流程图"></p>
<h3 id="过期删除策略有哪些？"><a href="#过期删除策略有哪些？" class="headerlink" title="过期删除策略有哪些？"></a>过期删除策略有哪些？</h3><ol>
<li>定时删除</li>
</ol>
<p>定时删除策略的做法是，<strong>在设置 key 的过期时间时，同时创建一个定时事件，当时间到达时，由事件处理器自动执行 key 的删除操作。</strong></p>
<p>定时删除策略的<strong>优点</strong>：</p>
<ul>
<li>可以保证过期 key 会被尽快删除，也就是内存可以被尽快地释放。因此，定时删除对内存是最友好的。</li>
</ul>
<p>定时删除策略的<strong>缺点</strong>：</p>
<ul>
<li>在过期 key 比较多的情况下，删除过期 key 可能会占用相当一部分 CPU 时间，在内存不紧张但 CPU 时间紧张的情况下，将 CPU 时间用于删除和当前任务无关的过期键上，无疑会对服务器的响应时间和吞吐量造成影响。所以，定时删除策略对 CPU 不友好。</li>
</ul>
<ol start="2">
<li>惰性删除</li>
</ol>
<p>惰性删除策略的做法是，<strong>不主动删除过期键，每次从数据库访问 key 时，都检测 key 是否过期，如果过期则删除该 key。</strong></p>
<ul>
<li>惰性删除策略的<strong>优点</strong>：</li>
</ul>
<p>因为每次访问时，才会检查 key 是否过期，所以此策略只会使用很少的系统资源，因此，惰性删除策略对 CPU 时间最友好。</p>
<ul>
<li>惰性删除策略的<strong>缺点</strong>：</li>
</ul>
<p>如果一个 key 已经过期，而这个 key 又仍然保留在数据库中，那么只要这个过期 key 一直没有被访问，它所占用的内存就不会释放，造成了一定的内存空间浪费。所以，惰性删除策略对内存不友好。</p>
<ol start="3">
<li>定期删除</li>
</ol>
<p>定期删除策略的做法是，<strong>每隔一段时间「随机」从数据库中取出一定数量的 key 进行检查，并删除其中的过期key。</strong></p>
<blockquote>
<p>特别强调下，每次检查数据库并<mark>不是遍历过期字典</mark>中的所有 key，而是从<mark>数据库中随机抽取</mark>一定数量的 key 进行过期检查。</p>
</blockquote>
<p>定期删除策略的<strong>优点</strong>：</p>
<ul>
<li>通过限制删除操作执行的时长和频率，来减少删除操作对 CPU 的影响，同时也能删除一部分过期的数据减少了过期键对空间的无效占用。</li>
</ul>
<p>定期删除策略的<strong>缺点</strong>：</p>
<ul>
<li>内存清理方面没有定时删除效果好，同时没有惰性删除使用的系统资源少。</li>
<li>难以确定删除操作执行的时长和频率。如果执行的太频繁，定期删除策略变得和定时删除策略一样，对CPU不友好；如果执行的太少，那又和惰性删除一样了，过期 key 占用的内存不会及时得到释放。</li>
</ul>
<p>🌈补充：</p>
<p>Redis会设置一个定时任务serverCron()，按照server.hz的频率来执行过期key清理，模式为SLOW</p>
<p>Redis的每个事件循环前会调用beforesleep()函数，执行过期key清理，模式为FAST</p>
<p>SLow模式规则:</p>
<ol>
<li>执行频率受server.hz影响，默认为10，即每秒执行10次，每个执行周期100ms。</li>
<li>执行清理耗时不超过一次执行周期的25%</li>
<li>逐个遍历db，逐个遍历db中的bucket，抽取20个key判断是否过期</li>
<li>如果没达到时间上限 (25ms)并且过期key比例大于10%，再进行一次抽样，否则结束</li>
</ol>
<p>FAST模式规则(过期key比例小于10%不执行):</p>
<ol>
<li>执行频率受beforesleep()调用频率影响，但两次FAST模式间隔不低于2ms</li>
<li>执行清理耗时不超过1ms</li>
<li>逐个遍历db，逐个遍历db中的bucket，抽取20个key判断是否过期</li>
<li>如果没达到时间上限(1ms)并且过期key比例大于10%，再进行一次抽样，否则结束</li>
</ol>
<h3 id="Redis-过期删除策略是什么？"><a href="#Redis-过期删除策略是什么？" class="headerlink" title="Redis 过期删除策略是什么？"></a>Redis 过期删除策略是什么？</h3><p><strong>Redis 选择<mark>「惰性删除+定期删除」</mark>这两种策略配和使用</strong>，以求在合理使用 CPU 时间和避免内存浪费之间取得平衡。</p>
<h2 id="内存淘汰策略"><a href="#内存淘汰策略" class="headerlink" title="内存淘汰策略"></a>内存淘汰策略</h2><p>当 Redis 的运行内存已经超过 Redis 设置的最大内存之后，则会使用内存淘汰策略删除符合条件的 key</p>
<h3 id="Redis-内存淘汰策略有哪些？"><a href="#Redis-内存淘汰策略有哪些？" class="headerlink" title="Redis 内存淘汰策略有哪些？"></a>Redis 内存淘汰策略有哪些？</h3><p>Redis支持8种不同策略来选择要删除的key：</p>
<ol>
<li><p>noeviction： 不淘汰任何key，但是内存满时不允许写入新数据，默认就是这种策略。</p>
</li>
<li><p>volatile-ttl： 对设置了TTL的key，比较key的剩余TTL值，TTL越小越先被淘汰</p>
</li>
</ol>
<blockquote>
<p>第2点补充：当运行内存超过最大设置内存时，不淘汰任何数据，但新增操作会报错。</p>
</blockquote>
<ol start="3">
<li><p>allkeys-random：对全体key ，随机进行淘汰。也就是直接从db-&gt;dict中随机挑选</p>
</li>
<li><p>volatile-random：对设置了TTL的key ，随机进行淘汰。也就是从db-&gt;expires中随机挑选。</p>
</li>
<li><p>allkeys-lru： 对全体key，基于LRU算法进行淘汰</p>
</li>
<li><p>volatile-lru： 对设置了TTL的key，基于LRU算法进行淘汰</p>
</li>
<li><p>allkeys-lfu： 对全体key，基于LFU算法进行淘汰</p>
</li>
<li><p>volatile-lfu： 对设置了TTL的key，基于LFU算法进行淘汰</p>
</li>
</ol>
<p>淘汰策略流程：</p>
<p><img src="/../assets/Redis%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86/image-20231107112532443.png" alt="淘汰策略流程"></p>
<h3 id="LRU-算法和-LFU-算法有什么区别？"><a href="#LRU-算法和-LFU-算法有什么区别？" class="headerlink" title="LRU 算法和 LFU 算法有什么区别？"></a>LRU 算法和 LFU 算法有什么区别？</h3><p>🔴🟢🟡一句话总结：</p>
<p>LRU：最后一次访问时间隔得越久，这个淘汰优先级越高</p>
<p>LFU：最少频率使用，频率越低，淘汰优先级越高</p>
<hr>
<p>Redis 对象头中的 lru 字段，在 LRU 算法下和 LFU 算法下使用方式并不相同。</p>
<p><strong>在 LRU 算法中</strong>，Redis 对象头的 24 bits 的 lru 字段是用来记录 key 的访问时间戳，因此在 LRU 模式下，Redis可以根据对象头中的 lru 字段记录的值，来比较最后一次 key 的访问时间长，从而淘汰最久未被使用的 key。</p>
<p><strong>在 LFU 算法中</strong>，Redis对象头的 24 bits 的 lru 字段被分成两段来存储，高 16bit 存储 ldt(Last Decrement Time)，低 8bit 存储 logc(Logistic Counter)。</p>
<p><img src="/../assets/Redis%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86/lru%E5%AD%97%E6%AE%B5.png" alt="img"></p>
<ul>
<li>ldt 是用来记录 key 的访问时间戳；</li>
<li>logc 是用来记录 key 的访问频次，它的值越小表示使用频率越低，越容易淘汰，每个新加入的 key 的logc 初始值为 5。</li>
</ul>
<p>注意，logc 并不是单纯的访问次数，而是访问频次（访问频率），因为 <strong>logc 会随时间推移而衰减的</strong>。</p>
<p>在每次 key 被访问时，会先对 logc 做一个衰减操作，衰减的值跟前后访问时间的差距有关系，如果上一次访问的时间与这一次访问的时间差距很大，那么衰减的值就越大，这样实现的 LFU 算法是根据<strong>访问频率</strong>来淘汰数据的，而不只是访问次数。访问频率需要考虑 key 的访问是多长时间段内发生的。key 的先前访问距离当前时间越长，那么这个 key 的访问频率相应地也就会降低，这样被淘汰的概率也会更大。</p>
<p>对 logc 做完衰减操作后，就开始对 logc 进行增加操作，增加操作并不是单纯的 + 1，而是根据概率增加，如果 logc 越大的 key，它的 logc 就越难再增加。</p>
<p>所以，Redis 在访问 key 时，对于 logc 是这样变化的：</p>
<ol>
<li>先按照上次访问距离当前的时长，来对 logc 进行衰减；</li>
<li>然后，再按照一定概率增加 logc 的值</li>
</ol>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="https://PlanBBBBB.github.io">PlanB</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="https://planbbbbb.github.io/2023/08/03/Study-Redis%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86/">https://planbbbbb.github.io/2023/08/03/Study-Redis%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://PlanBBBBB.github.io" target="_blank">PlanB's Blog</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/Redis/">Redis</a></div><div class="post_share"><div class="social-share" data-image="/../img/redis.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2023/07/28/Study-Linux%E5%AD%A6%E4%B9%A0%E5%B9%B6%E9%83%A8%E7%BD%B2%E9%A1%B9%E7%9B%AE/"><img class="prev-cover" src="/../img/linux.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">Linux学习并部署项目</div></div></a></div><div class="next-post pull-right"><a href="/2023/08/27/Study-JVM/"><img class="next-cover" src="/../img/jvm.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">JVM</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/2024/01/08/%E9%9D%A2%E8%AF%95-Redis%E7%9B%B8%E5%85%B3%E9%9D%A2%E8%AF%95%E9%A2%98/" title="Redis相关面试题"><img class="cover" src="/../img/redis.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-01-08</div><div class="title">Redis相关面试题</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/./img/%E5%A4%B4%E5%83%8F.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">PlanB</div><div class="author-info__description">欢迎来到PlanB的博客</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">45</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">16</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">5</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/PlanBBBBB"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/PlanBBBBB" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:2741718884@qq.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">欢迎来到PlanB的博客！</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content is-expand"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%86%99%E5%9C%A8%E5%89%8D%E9%9D%A2"><span class="toc-number">1.</span> <span class="toc-text">写在前面</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Redis%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86"><span class="toc-number">2.</span> <span class="toc-text">Redis基础知识</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88%E4%BD%BF%E7%94%A8Redis"><span class="toc-number">2.1.</span> <span class="toc-text">为什么使用Redis</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Redis-%E5%92%8C-Memcached-%E6%9C%89%E4%BB%80%E4%B9%88%E5%8C%BA%E5%88%AB%EF%BC%9F"><span class="toc-number">2.2.</span> <span class="toc-text">Redis 和 Memcached 有什么区别？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88%E7%94%A8Redis%E5%81%9AMySQL%E7%9A%84%E7%BC%93%E5%AD%98%EF%BC%9F"><span class="toc-number">2.3.</span> <span class="toc-text">为什么用Redis做MySQL的缓存？</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Redis%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B"><span class="toc-number">3.</span> <span class="toc-text">Redis网络模型</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%94%E7%A7%8DIO%E6%A8%A1%E5%9E%8B"><span class="toc-number">3.1.</span> <span class="toc-text">五种IO模型</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%98%BB%E5%A1%9EIO"><span class="toc-number">3.1.1.</span> <span class="toc-text">阻塞IO</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%9D%9E%E9%98%BB%E5%A1%9EIO"><span class="toc-number">3.1.2.</span> <span class="toc-text">非阻塞IO</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E2%AD%90%E2%AD%90%E2%AD%90%E5%A4%9A%E8%B7%AFIO%E5%A4%8D%E7%94%A8"><span class="toc-number">3.1.3.</span> <span class="toc-text">⭐⭐⭐多路IO复用</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#select"><span class="toc-number">3.1.3.1.</span> <span class="toc-text">select</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#poll"><span class="toc-number">3.1.3.2.</span> <span class="toc-text">poll</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#epoll"><span class="toc-number">3.1.3.3.</span> <span class="toc-text">epoll</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B8%89%E7%A7%8D%E6%A8%A1%E5%BC%8F%E7%9A%84%E5%AF%B9%E6%AF%94%E4%B8%8E%E6%80%BB%E7%BB%93"><span class="toc-number">3.1.3.4.</span> <span class="toc-text">三种模式的对比与总结</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BA%8B%E4%BB%B6%E9%80%9A%E7%9F%A5%E6%9C%BA%E5%88%B6"><span class="toc-number">3.1.3.5.</span> <span class="toc-text">事件通知机制</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%9F%BA%E4%BA%8Eepoll%E7%9A%84%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%AB%AF%E6%B5%81%E7%A8%8B"><span class="toc-number">3.1.3.6.</span> <span class="toc-text">基于epoll的服务器端流程</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BF%A1%E5%8F%B7%E9%A9%B1%E5%8A%A8IO"><span class="toc-number">3.1.4.</span> <span class="toc-text">信号驱动IO</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%BC%82%E6%AD%A5IO"><span class="toc-number">3.1.5.</span> <span class="toc-text">异步IO</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AF%B9%E6%AF%94"><span class="toc-number">3.1.6.</span> <span class="toc-text">对比</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%B0%8F%E6%9E%97coding%E9%9D%A2%E8%AF%95%E9%A2%98"><span class="toc-number">3.2.</span> <span class="toc-text">小林coding面试题</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Redis-%E6%98%AF%E5%8D%95%E7%BA%BF%E7%A8%8B%E5%90%97%EF%BC%9F"><span class="toc-number">3.2.1.</span> <span class="toc-text">Redis 是单线程吗？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Redis-%E5%8D%95%E7%BA%BF%E7%A8%8B%E6%A8%A1%E5%BC%8F%E6%98%AF%E6%80%8E%E6%A0%B7%E7%9A%84%EF%BC%9F"><span class="toc-number">3.2.2.</span> <span class="toc-text">Redis 单线程模式是怎样的？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Redis-%E9%87%87%E7%94%A8%E5%8D%95%E7%BA%BF%E7%A8%8B%E4%B8%BA%E4%BB%80%E4%B9%88%E8%BF%98%E8%BF%99%E4%B9%88%E5%BF%AB%EF%BC%9F"><span class="toc-number">3.2.3.</span> <span class="toc-text">Redis 采用单线程为什么还这么快？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Redis-6-0-%E4%B9%8B%E5%89%8D%E4%B8%BA%E4%BB%80%E4%B9%88%E4%BD%BF%E7%94%A8%E5%8D%95%E7%BA%BF%E7%A8%8B%EF%BC%9F"><span class="toc-number">3.2.4.</span> <span class="toc-text">Redis 6.0 之前为什么使用单线程？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Redis-6-0-%E4%B9%8B%E5%90%8E%E4%B8%BA%E4%BB%80%E4%B9%88%E5%BC%95%E5%85%A5%E4%BA%86%E5%A4%9A%E7%BA%BF%E7%A8%8B%EF%BC%9F"><span class="toc-number">3.2.5.</span> <span class="toc-text">Redis 6.0 之后为什么引入了多线程？</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Redis%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B"><span class="toc-number">4.</span> <span class="toc-text">Redis数据类型</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#String"><span class="toc-number">4.1.</span> <span class="toc-text">String</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84"><span class="toc-number">4.1.1.</span> <span class="toc-text">数据结构</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BC%96%E7%A0%81%E7%B1%BB%E5%9E%8B"><span class="toc-number">4.1.2.</span> <span class="toc-text">编码类型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4"><span class="toc-number">4.1.3.</span> <span class="toc-text">常用命令</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF"><span class="toc-number">4.1.4.</span> <span class="toc-text">应用场景</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#List"><span class="toc-number">4.2.</span> <span class="toc-text">List</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E7%BC%96%E7%A0%81%E7%B1%BB%E5%9E%8B"><span class="toc-number">4.2.1.</span> <span class="toc-text">数据结构&amp;&amp;编码类型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4-1"><span class="toc-number">4.2.2.</span> <span class="toc-text">常用命令</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF-1"><span class="toc-number">4.2.3.</span> <span class="toc-text">应用场景</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Set"><span class="toc-number">4.3.</span> <span class="toc-text">Set</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E7%BC%96%E7%A0%81%E7%B1%BB%E5%9E%8B-1"><span class="toc-number">4.3.1.</span> <span class="toc-text">数据结构&amp;&amp;编码类型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4-2"><span class="toc-number">4.3.2.</span> <span class="toc-text">常用命令</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF-2"><span class="toc-number">4.3.3.</span> <span class="toc-text">应用场景</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Hash"><span class="toc-number">4.4.</span> <span class="toc-text">Hash</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E7%BC%96%E7%A0%81%E7%B1%BB%E5%9E%8B-2"><span class="toc-number">4.4.1.</span> <span class="toc-text">数据结构&amp;&amp;编码类型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4-3"><span class="toc-number">4.4.2.</span> <span class="toc-text">常用命令</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF-3"><span class="toc-number">4.4.3.</span> <span class="toc-text">应用场景</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#ZSet"><span class="toc-number">4.5.</span> <span class="toc-text">ZSet</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E7%BC%96%E7%A0%81%E7%B1%BB%E5%9E%8B-3"><span class="toc-number">4.5.1.</span> <span class="toc-text">数据结构&amp;&amp;编码类型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4-4"><span class="toc-number">4.5.2.</span> <span class="toc-text">常用命令</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF-4"><span class="toc-number">4.5.3.</span> <span class="toc-text">应用场景</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#BitMap"><span class="toc-number">4.6.</span> <span class="toc-text">BitMap</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-1"><span class="toc-number">4.6.1.</span> <span class="toc-text">数据结构</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF-5"><span class="toc-number">4.6.2.</span> <span class="toc-text">应用场景</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#HyperLogLog"><span class="toc-number">4.7.</span> <span class="toc-text">HyperLogLog</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF-6"><span class="toc-number">4.7.1.</span> <span class="toc-text">应用场景</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#GEO"><span class="toc-number">4.8.</span> <span class="toc-text">GEO</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-2"><span class="toc-number">4.8.1.</span> <span class="toc-text">数据结构</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF-7"><span class="toc-number">4.8.2.</span> <span class="toc-text">应用场景</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#stream"><span class="toc-number">4.9.</span> <span class="toc-text">stream</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%80%9A%E7%94%A8%E5%91%BD%E4%BB%A4"><span class="toc-number">4.10.</span> <span class="toc-text">通用命令</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Redis%E5%BA%95%E5%B1%82%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84"><span class="toc-number">5.</span> <span class="toc-text">Redis底层数据结构</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#SDS"><span class="toc-number">5.1.</span> <span class="toc-text">SDS</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#C%E5%AD%97%E7%AC%A6%E4%B8%B2%E7%9A%84%E7%BC%BA%E7%82%B9"><span class="toc-number">5.1.1.</span> <span class="toc-text">C字符串的缺点</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#SDS%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84"><span class="toc-number">5.1.2.</span> <span class="toc-text">SDS数据结构</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%87%AA%E5%8A%A8%E6%89%A9%E5%AE%B9"><span class="toc-number">5.1.3.</span> <span class="toc-text">自动扩容</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%8A%82%E7%9C%81%E5%86%85%E5%AD%98%E7%A9%BA%E9%97%B4"><span class="toc-number">5.1.4.</span> <span class="toc-text">节省内存空间</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8F%8C%E5%90%91%E9%93%BE%E8%A1%A8"><span class="toc-number">5.2.</span> <span class="toc-text">双向链表</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%93%BE%E8%A1%A8%E7%9A%84%E4%BC%98%E5%8A%BF%E4%B8%8E%E7%BC%BA%E9%99%B7"><span class="toc-number">5.2.1.</span> <span class="toc-text">链表的优势与缺陷</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AF%B9%E6%AF%94%E6%95%B0%E7%BB%84%E5%92%8C%E9%93%BE%E8%A1%A8"><span class="toc-number">5.2.2.</span> <span class="toc-text">对比数组和链表</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8E%8B%E7%BC%A9%E5%88%97%E8%A1%A8"><span class="toc-number">5.3.</span> <span class="toc-text">压缩列表</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BB%93%E6%9E%84%E8%AE%BE%E8%AE%A1"><span class="toc-number">5.3.1.</span> <span class="toc-text">结构设计</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%BF%9E%E9%94%81%E6%9B%B4%E6%96%B0"><span class="toc-number">5.3.2.</span> <span class="toc-text">连锁更新</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BC%BA%E9%99%B7"><span class="toc-number">5.3.3.</span> <span class="toc-text">缺陷</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%93%88%E5%B8%8C%E8%A1%A8"><span class="toc-number">5.4.</span> <span class="toc-text">哈希表</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BB%93%E6%9E%84"><span class="toc-number">5.4.1.</span> <span class="toc-text">结构</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%93%88%E5%B8%8C%E5%86%B2%E7%AA%81"><span class="toc-number">5.4.2.</span> <span class="toc-text">哈希冲突</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#rehash"><span class="toc-number">5.4.3.</span> <span class="toc-text">rehash</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%B7%B3%E8%A1%A8"><span class="toc-number">5.5.</span> <span class="toc-text">跳表</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BB%93%E6%9E%84-1"><span class="toc-number">5.5.1.</span> <span class="toc-text">结构</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88%E7%94%A8%E8%B7%B3%E8%A1%A8%E8%80%8C%E4%B8%8D%E6%98%AF%E5%B9%B3%E8%A1%A1%E6%A0%91"><span class="toc-number">5.5.2.</span> <span class="toc-text">为什么用跳表而不是平衡树</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%95%B4%E6%95%B0%E9%9B%86%E5%90%88"><span class="toc-number">5.6.</span> <span class="toc-text">整数集合</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%B4%E6%95%B0%E9%9B%86%E5%90%88%E7%BB%93%E6%9E%84%E8%AE%BE%E8%AE%A1"><span class="toc-number">5.6.1.</span> <span class="toc-text">整数集合结构设计</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8D%87%E7%BA%A7%E6%9C%BA%E5%88%B6"><span class="toc-number">5.6.2.</span> <span class="toc-text">升级机制</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%9F%A5%E8%AF%A2%E6%96%B9%E5%BC%8F"><span class="toc-number">5.6.3.</span> <span class="toc-text">查询方式</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#quicklist"><span class="toc-number">5.7.</span> <span class="toc-text">quicklist</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BB%93%E6%9E%84-2"><span class="toc-number">5.7.1.</span> <span class="toc-text">结构</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#listpack"><span class="toc-number">5.8.</span> <span class="toc-text">listpack</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#listpack-%E7%BB%93%E6%9E%84%E8%AE%BE%E8%AE%A1"><span class="toc-number">5.8.1.</span> <span class="toc-text">listpack 结构设计</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BF%AE%E6%94%B9%E5%90%8E%E4%B8%8D%E4%BC%9A%E5%BD%B1%E5%93%8D%E9%81%8D%E5%8E%86%E5%90%97"><span class="toc-number">5.8.2.</span> <span class="toc-text">修改后不会影响遍历吗</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#RedisObject"><span class="toc-number">5.9.</span> <span class="toc-text">RedisObject</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Redis%E5%BA%94%E7%94%A8"><span class="toc-number">6.</span> <span class="toc-text">Redis应用</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%BC%93%E5%AD%98%E7%A9%BF%E9%80%8F"><span class="toc-number">6.1.</span> <span class="toc-text">缓存穿透</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%9A%E4%B9%89"><span class="toc-number">6.1.1.</span> <span class="toc-text">定义</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%B8%B8%E8%A7%81%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88"><span class="toc-number">6.1.2.</span> <span class="toc-text">常见解决方案</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%BC%93%E5%AD%98%E9%9B%AA%E5%B4%A9"><span class="toc-number">6.2.</span> <span class="toc-text">缓存雪崩</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%9A%E4%B9%89-1"><span class="toc-number">6.2.1.</span> <span class="toc-text">定义</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%B8%B8%E8%A7%81%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88-1"><span class="toc-number">6.2.2.</span> <span class="toc-text">常见解决方案</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%BC%93%E5%AD%98%E5%87%BB%E7%A9%BF"><span class="toc-number">6.3.</span> <span class="toc-text">缓存击穿</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%9A%E4%B9%89-2"><span class="toc-number">6.3.1.</span> <span class="toc-text">定义</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%B8%B8%E8%A7%81%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88-2"><span class="toc-number">6.3.2.</span> <span class="toc-text">常见解决方案</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%A4%E7%A7%8D%E6%96%B9%E6%A1%88%E5%AF%B9%E6%AF%94"><span class="toc-number">6.3.3.</span> <span class="toc-text">两种方案对比</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%BC%93%E5%AD%98%E4%B8%8E%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BF%9D%E6%8C%81%E4%B8%80%E8%87%B4%E9%97%AE%E9%A2%98"><span class="toc-number">6.4.</span> <span class="toc-text">缓存与数据库保持一致问题</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%85%88%E6%9B%B4%E6%96%B0%E6%95%B0%E6%8D%AE%E5%BA%93%EF%BC%8C%E8%BF%98%E6%98%AF%E5%85%88%E6%9B%B4%E6%96%B0%E7%BC%93%E5%AD%98%EF%BC%9F"><span class="toc-number">6.4.1.</span> <span class="toc-text">先更新数据库，还是先更新缓存？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%85%88%E6%9B%B4%E6%96%B0%E6%95%B0%E6%8D%AE%E5%BA%93%EF%BC%8C%E8%BF%98%E6%98%AF%E5%85%88%E5%88%A0%E9%99%A4%E7%BC%93%E5%AD%98%EF%BC%9F"><span class="toc-number">6.4.2.</span> <span class="toc-text">先更新数据库，还是先删除缓存？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%F0%9F%94%B4%F0%9F%9F%A1%F0%9F%9F%A2%E6%80%BB%E7%BB%93"><span class="toc-number">6.4.3.</span> <span class="toc-text">🔴🟡🟢总结</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81"><span class="toc-number">6.5.</span> <span class="toc-text">分布式锁</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A0%B8%E5%BF%83%E6%80%9D%E6%83%B3"><span class="toc-number">6.5.1.</span> <span class="toc-text">核心思想</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%9E%E7%8E%B0%E4%BB%A3%E7%A0%81"><span class="toc-number">6.5.2.</span> <span class="toc-text">实现代码</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Redisson"><span class="toc-number">6.5.3.</span> <span class="toc-text">Redisson</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%85%B3%E6%B3%A8%E6%8E%A8%E9%80%81"><span class="toc-number">6.6.</span> <span class="toc-text">关注推送</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%BA%8B%E5%8A%A1"><span class="toc-number">7.</span> <span class="toc-text">事务</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AE%9A%E4%B9%89-3"><span class="toc-number">7.1.</span> <span class="toc-text">定义</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Multi%E3%80%81Exec%E3%80%81discard"><span class="toc-number">7.2.</span> <span class="toc-text">Multi、Exec、discard</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%8B%E5%8A%A1%E7%9A%84%E9%94%99%E8%AF%AF%E5%A4%84%E7%90%86"><span class="toc-number">7.3.</span> <span class="toc-text">事务的错误处理</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#watch"><span class="toc-number">7.4.</span> <span class="toc-text">watch</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Redis%E4%BA%8B%E5%8A%A1%E4%B8%89%E7%89%B9%E6%80%A7"><span class="toc-number">7.5.</span> <span class="toc-text">Redis事务三特性</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%8C%81%E4%B9%85%E5%8C%96%E7%AF%87"><span class="toc-number">8.</span> <span class="toc-text">持久化篇</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#AOF"><span class="toc-number">8.1.</span> <span class="toc-text">AOF</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#AOF%E6%97%A5%E5%BF%97"><span class="toc-number">8.1.1.</span> <span class="toc-text">AOF日志</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%89%E7%A7%8D%E5%86%99%E5%9B%9E%E7%AD%96%E7%95%A5"><span class="toc-number">8.1.2.</span> <span class="toc-text">三种写回策略</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#AOF%E9%87%8D%E5%86%99%E6%9C%BA%E5%88%B6"><span class="toc-number">8.1.3.</span> <span class="toc-text">AOF重写机制</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E2%AD%90%E2%AD%90%E2%AD%90AOF%E5%90%8E%E5%8F%B0%E9%87%8D%E5%86%99"><span class="toc-number">8.1.4.</span> <span class="toc-text">⭐⭐⭐AOF后台重写</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#RDB"><span class="toc-number">8.2.</span> <span class="toc-text">RDB</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%BF%AB%E7%85%A7%E6%80%8E%E4%B9%88%E7%94%A8%EF%BC%9F"><span class="toc-number">8.2.1.</span> <span class="toc-text">快照怎么用？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E2%AD%90%E2%AD%90%E2%AD%90%E6%89%A7%E8%A1%8C%E5%BF%AB%E7%85%A7%E6%97%B6%EF%BC%8C%E6%95%B0%E6%8D%AE%E8%83%BD%E8%A2%AB%E4%BF%AE%E6%94%B9%E5%90%97%EF%BC%9F"><span class="toc-number">8.2.2.</span> <span class="toc-text">⭐⭐⭐执行快照时，数据能被修改吗？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#RDB-%E5%92%8C-AOF-%E5%90%88%E4%BD%93"><span class="toc-number">8.2.3.</span> <span class="toc-text">RDB 和 AOF 合体</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Redis-%E5%A4%A7-Key-%E5%AF%B9%E6%8C%81%E4%B9%85%E5%8C%96%E6%9C%89%E4%BB%80%E4%B9%88%E5%BD%B1%E5%93%8D%EF%BC%9F"><span class="toc-number">8.3.</span> <span class="toc-text">Redis 大 Key 对持久化有什么影响？</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A4%A7-Key-%E5%AF%B9-AOF-%E6%97%A5%E5%BF%97%E7%9A%84%E5%BD%B1%E5%93%8D"><span class="toc-number">8.3.1.</span> <span class="toc-text">大 Key 对 AOF 日志的影响</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A4%A7-Key-%E5%AF%B9-AOF-%E9%87%8D%E5%86%99%E5%92%8C-RDB-%E7%9A%84%E5%BD%B1%E5%93%8D"><span class="toc-number">8.3.2.</span> <span class="toc-text">大 Key 对 AOF 重写和 RDB 的影响</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E9%AB%98%E5%8F%AF%E7%94%A8%E7%AF%87%E2%9C%8F%EF%B8%8F"><span class="toc-number">9.</span> <span class="toc-text">高可用篇✏️</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6"><span class="toc-number">9.1.</span> <span class="toc-text">主从复制</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A4%8D%E5%88%B6%E5%8E%9F%E7%90%86"><span class="toc-number">9.1.1.</span> <span class="toc-text">复制原理</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A4%8D%E5%88%B6%E5%BB%B6%E8%BF%9F"><span class="toc-number">9.1.2.</span> <span class="toc-text">复制延迟</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%80%E4%B8%BB%E4%BA%8C%E4%BB%86"><span class="toc-number">9.1.3.</span> <span class="toc-text">一主二仆</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BA%A7%E8%81%94%E5%A4%8D%E5%88%B6"><span class="toc-number">9.1.4.</span> <span class="toc-text">级联复制</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%B0%8F%E6%9E%97coding%E9%9D%A2%E8%AF%95%E9%A2%98-1"><span class="toc-number">9.1.5.</span> <span class="toc-text">小林coding面试题</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%93%A8%E5%85%B5%E6%A8%A1%E5%BC%8F"><span class="toc-number">9.2.</span> <span class="toc-text">哨兵模式</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A6%82%E4%BD%95%E5%88%A4%E6%96%AD%E4%B8%BB%E8%8A%82%E7%82%B9%E7%9C%9F%E7%9A%84%E6%95%85%E9%9A%9C%E4%BA%86%EF%BC%9F"><span class="toc-number">9.2.1.</span> <span class="toc-text">如何判断主节点真的故障了？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%94%B1%E5%93%AA%E4%B8%AA%E5%93%A8%E5%85%B5%E8%BF%9B%E8%A1%8C%E4%B8%BB%E4%BB%8E%E6%95%85%E9%9A%9C%E8%BD%AC%E7%A7%BB%EF%BC%9F"><span class="toc-number">9.2.2.</span> <span class="toc-text">由哪个哨兵进行主从故障转移？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%BB%E4%BB%8E%E6%95%85%E9%9A%9C%E8%BD%AC%E7%A7%BB%E7%9A%84%E8%BF%87%E7%A8%8B%E6%98%AF%E6%80%8E%E6%A0%B7%E7%9A%84%EF%BC%9F"><span class="toc-number">9.2.3.</span> <span class="toc-text">主从故障转移的过程是怎样的？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%93%A8%E5%85%B5%E9%9B%86%E7%BE%A4%E6%98%AF%E5%A6%82%E4%BD%95%E7%BB%84%E6%88%90%E7%9A%84%EF%BC%9F"><span class="toc-number">9.2.4.</span> <span class="toc-text">哨兵集群是如何组成的？</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%9B%86%E7%BE%A4"><span class="toc-number">9.3.</span> <span class="toc-text">集群</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%9B%86%E7%BE%A4%E8%84%91%E8%A3%82%E5%AF%BC%E8%87%B4%E6%95%B0%E6%8D%AE%E4%B8%A2%E5%A4%B1%E6%80%8E%E4%B9%88%E5%8A%9E%EF%BC%9F"><span class="toc-number">9.3.1.</span> <span class="toc-text">集群脑裂导致数据丢失怎么办？</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%8A%9F%E8%83%BD%E7%AF%87"><span class="toc-number">10.</span> <span class="toc-text">功能篇</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%BF%87%E6%9C%9F%E5%88%A0%E9%99%A4%E7%AD%96%E7%95%A5"><span class="toc-number">10.1.</span> <span class="toc-text">过期删除策略</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A6%82%E4%BD%95%E5%88%A4%E5%AE%9A-key-%E5%B7%B2%E8%BF%87%E6%9C%9F%E4%BA%86%EF%BC%9F"><span class="toc-number">10.1.1.</span> <span class="toc-text">如何判定 key 已过期了？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%BF%87%E6%9C%9F%E5%88%A0%E9%99%A4%E7%AD%96%E7%95%A5%E6%9C%89%E5%93%AA%E4%BA%9B%EF%BC%9F"><span class="toc-number">10.1.2.</span> <span class="toc-text">过期删除策略有哪些？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Redis-%E8%BF%87%E6%9C%9F%E5%88%A0%E9%99%A4%E7%AD%96%E7%95%A5%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F"><span class="toc-number">10.1.3.</span> <span class="toc-text">Redis 过期删除策略是什么？</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%86%85%E5%AD%98%E6%B7%98%E6%B1%B0%E7%AD%96%E7%95%A5"><span class="toc-number">10.2.</span> <span class="toc-text">内存淘汰策略</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Redis-%E5%86%85%E5%AD%98%E6%B7%98%E6%B1%B0%E7%AD%96%E7%95%A5%E6%9C%89%E5%93%AA%E4%BA%9B%EF%BC%9F"><span class="toc-number">10.2.1.</span> <span class="toc-text">Redis 内存淘汰策略有哪些？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#LRU-%E7%AE%97%E6%B3%95%E5%92%8C-LFU-%E7%AE%97%E6%B3%95%E6%9C%89%E4%BB%80%E4%B9%88%E5%8C%BA%E5%88%AB%EF%BC%9F"><span class="toc-number">10.2.2.</span> <span class="toc-text">LRU 算法和 LFU 算法有什么区别？</span></a></li></ol></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2024/06/01/Study-Java%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/" title="Java并发编程"><img src="/../img/juc.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Java并发编程"/></a><div class="content"><a class="title" href="/2024/06/01/Study-Java%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/" title="Java并发编程">Java并发编程</a><time datetime="2024-06-01T03:50:48.051Z" title="发表于 2024-06-01 11:50:48">2024-06-01</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/05/30/%E9%9D%A2%E7%BB%8F-%E6%AC%A2%E8%81%9A%E6%97%B6%E4%BB%A3%E9%9D%A2%E8%AF%95/" title="欢聚时代面试"><img src="/../img/Joyy-Logo.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="欢聚时代面试"/></a><div class="content"><a class="title" href="/2024/05/30/%E9%9D%A2%E7%BB%8F-%E6%AC%A2%E8%81%9A%E6%97%B6%E4%BB%A3%E9%9D%A2%E8%AF%95/" title="欢聚时代面试">欢聚时代面试</a><time datetime="2024-05-30T07:25:33.663Z" title="发表于 2024-05-30 15:25:33">2024-05-30</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/05/21/Work-%E6%95%B0%E6%8D%AE%E6%9D%83%E9%99%90/" title="数据权限"><img src="/./img/num3.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="数据权限"/></a><div class="content"><a class="title" href="/2024/05/21/Work-%E6%95%B0%E6%8D%AE%E6%9D%83%E9%99%90/" title="数据权限">数据权限</a><time datetime="2024-05-21T02:28:21.591Z" title="发表于 2024-05-21 10:28:21">2024-05-21</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/05/14/Study-%E5%88%86%E5%B8%83%E5%BC%8F/" title="分布式"><img src="/./img/num3.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="分布式"/></a><div class="content"><a class="title" href="/2024/05/14/Study-%E5%88%86%E5%B8%83%E5%BC%8F/" title="分布式">分布式</a><time datetime="2024-05-14T02:46:04.005Z" title="发表于 2024-05-14 10:46:04">2024-05-14</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/05/06/%E9%9D%A2%E7%BB%8F-%E4%B8%83%E7%89%9B%E4%BA%91%E7%AC%94%E8%AF%95/" title="七牛云笔试"><img src="/../img/%E7%89%9B%E5%AE%A2.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="七牛云笔试"/></a><div class="content"><a class="title" href="/2024/05/06/%E9%9D%A2%E7%BB%8F-%E4%B8%83%E7%89%9B%E4%BA%91%E7%AC%94%E8%AF%95/" title="七牛云笔试">七牛云笔试</a><time datetime="2024-05-06T13:49:33.892Z" title="发表于 2024-05-06 21:49:33">2024-05-06</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2022 - 2024 By PlanB</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div><div class="footer_custom_text">Hi, welcome to my <a href="https://PlanBBBBB.github.io">blog</a>!</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="translateLink" type="button" title="简繁转换">简</button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div></div></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.min.js"></script><script src="/js/search/local-search.js"></script><div class="js-pjax"></div><script async src="/js/title.js"></script><script id="click-show-text" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/click-show-text.min.js" data-mobile="true" data-text="0基础,学IT" data-fontsize="15px" data-random="false" async="async"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><!-- hexo injector body_end start --><script data-pjax>
    function butterfly_categories_card_injector_config(){
      var parent_div_git = document.getElementById('recent-posts');
      var item_html = '<style>li.categoryBar-list-item{width:32.3%;}.categoryBar-list{max-height: 190px;overflow:auto;}.categoryBar-list::-webkit-scrollbar{width:0!important}@media screen and (max-width: 650px){.categoryBar-list{max-height: 160px;}}</style><div class="recent-post-item" style="height:auto;width:100%;padding:0px;"><div id="categoryBar"><ul class="categoryBar-list"><li class="categoryBar-list-item" style="background:url(./img/project.png);"> <a class="categoryBar-list-link" href="categories/Project/">Project</a><span class="categoryBar-list-count">5</span><span class="categoryBar-list-descr">Poject</span></li><li class="categoryBar-list-item" style="background:url(./img/study.png);"> <a class="categoryBar-list-link" href="categories/Study/">Study</a><span class="categoryBar-list-count">19</span><span class="categoryBar-list-descr">Study</span></li><li class="categoryBar-list-item" style="background:url(./img/面试.png);"> <a class="categoryBar-list-link" href="categories/Work/">Work</a><span class="categoryBar-list-count">4</span><span class="categoryBar-list-descr">面试</span></li><li class="categoryBar-list-item" style="background:url(./img/面经.png);"> <a class="categoryBar-list-link" href="categories/面经/">面经</a><span class="categoryBar-list-count">5</span><span class="categoryBar-list-descr">面经</span></li><li class="categoryBar-list-item" style="background:url(./img/work.png);"> <a class="categoryBar-list-link" href="categories/面试/">面试</a><span class="categoryBar-list-count">12</span><span class="categoryBar-list-descr">Work</span></li></ul></div></div>';
      console.log('已挂载butterfly_categories_card')
      parent_div_git.insertAdjacentHTML("afterbegin",item_html)
      }
    if( document.getElementById('recent-posts') && (location.pathname ==='/'|| '/' ==='all')){
    butterfly_categories_card_injector_config()
    }
  </script><script data-pjax>
  function butterfly_swiper_injector_config(){
    var parent_div_git = document.getElementById('recent-posts');
    var item_html = '<div class="recent-post-item" style="height: auto;width: 100%"><div class="blog-slider swiper-container-fade swiper-container-horizontal" id="swiper_container"><div class="blog-slider__wrp swiper-wrapper" style="transition-duration: 0ms;"><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2023/08/27/Study-JVM/" alt=""><img width="48" height="48" src="../img/jvm.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2023-08-27</span><a class="blog-slider__title" href="2023/08/27/Study-JVM/" alt="">JVM</a><div class="blog-slider__text">JVM学习</div><a class="blog-slider__button" href="2023/08/27/Study-JVM/" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2023/01/05/Study-MySQL高级部分学习/" alt=""><img width="48" height="48" src="../img/mysql.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2023-01-05</span><a class="blog-slider__title" href="2023/01/05/Study-MySQL高级部分学习/" alt="">MySQL高级部分学习</a><div class="blog-slider__text">用于学习MySQL后续的进阶部分</div><a class="blog-slider__button" href="2023/01/05/Study-MySQL高级部分学习/" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2023/08/03/Study-Redis相关知识/" alt=""><img width="48" height="48" src="../img/redis.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2023-08-03</span><a class="blog-slider__title" href="2023/08/03/Study-Redis相关知识/" alt="">Redis相关知识</a><div class="blog-slider__text">用于学习Redis相关知识</div><a class="blog-slider__button" href="2023/08/03/Study-Redis相关知识/" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2023/09/05/Study-Java集合/" alt=""><img width="48" height="48" src="../img/java集合.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2023-09-05</span><a class="blog-slider__title" href="2023/09/05/Study-Java集合/" alt="">Java集合</a><div class="blog-slider__text">Java集合底层实现原理学习</div><a class="blog-slider__button" href="2023/09/05/Study-Java集合/" alt="">详情   </a></div></div></div><div class="blog-slider__pagination swiper-pagination-clickable swiper-pagination-bullets"></div></div></div>';
    console.log('已挂载butterfly_swiper')
    parent_div_git.insertAdjacentHTML("afterbegin",item_html)
    }
  var elist = 'undefined'.split(',');
  var cpage = location.pathname;
  var epage = '/';
  var flag = 0;

  for (var i=0;i<elist.length;i++){
    if (cpage.includes(elist[i])){
      flag++;
    }
  }

  if ((epage ==='all')&&(flag == 0)){
    butterfly_swiper_injector_config();
  }
  else if (epage === cpage){
    butterfly_swiper_injector_config();
  }
  </script><script defer src="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper.min.js"></script><script defer data-pjax src="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper_init.js"></script><div class="js-pjax"><script async="async">var arr = document.getElementsByClassName('recent-post-item');
for(var i = 0;i<arr.length;i++){
    arr[i].classList.add('wow');
    arr[i].classList.add('animate__bounceInLeft');
    arr[i].setAttribute('data-wow-duration', '800ms');
    arr[i].setAttribute('data-wow-delay', '0ms');
    arr[i].setAttribute('data-wow-offset', '100');
    arr[i].setAttribute('data-wow-iteration', '1');
  }</script><script async="async">var arr = document.getElementsByClassName('card-widget');
for(var i = 0;i<arr.length;i++){
    arr[i].classList.add('wow');
    arr[i].classList.add('animate__bounceInRight');
    arr[i].setAttribute('data-wow-duration', '');
    arr[i].setAttribute('data-wow-delay', '');
    arr[i].setAttribute('data-wow-offset', '');
    arr[i].setAttribute('data-wow-iteration', '');
  }</script></div><script defer src="https://npm.elemecdn.com/hexo-butterfly-wowjs/lib/wow.min.js"></script><script defer src="https://npm.elemecdn.com/hexo-butterfly-wowjs/lib/wow_init.js"></script><!-- hexo injector body_end end --></body></html>